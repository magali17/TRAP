---
title: 'Aim 1: Survival Analysis'
author: "Magali Blanco"
date: ' `r Sys.Date()` '
output:
  pdf_document:
    toc: yes
    toc_depth: '3'
editor_options:
  chunk_output_type: console
---
```{r, echo=F}
#NOTES
##4. merge with github. always do these 4 steps all together. enter the following into the Terminal (does not work any other way for some reason)
###a. git pull origin master #do this before start editing & before you're read to upload changes again
###b. git add A1.1_Survival.Rmd 
###c. git commit -m "my commit message in parentheses" 
###d. git push origin master

#plot multiple saved plots 
#grid.arrange(plot.interact, plot.complex, ncol = 2)

```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, cache=T, cache.comments = F, message = F, warning = F, tidy.opts=list(width.cutoff=60), tidy=TRUE 
                      #fig.height = 8
                      )  

set.seed(1)

# Clear workspace of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
  res <- suppressWarnings(
    lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
      detach, character.only=TRUE, unload=TRUE, force=TRUE))
}

pacman::p_load(survival, haven, tidyverse, knitr, Hmisc, EnvStats, lubridate, glmnet,
               survminer
               )  #Himsc: describe(); EnvStats: summaryFull(); survminer: ggflexsurvplot()  

#To open doc:/home/gradstudent/magali/a. TRAP Project/R TRAP Project/data/issue_001.sas7bdat 

# dem0 <- read_sas(file.path("~", "a. TRAP Project", "R TRAP Project", "data", "issue_001.sas7bdat"), NULL)

source("A1.0.2_Var&Fns.R")

dem0.0 <- read_sas(file.path("Data", "Aim 1", "issue_001.sas7bdat"), NULL)

#remove SAS labels
labelled::var_label(dem0.0) <- NULL

#data that can be used for all analyses 
dem0.1 <- dem0.0 %>% 
  filter(
    #drop PM10 predictions
    pollutant %in% c("no2", "pm25")
    ) %>%
  select(
    study_id,
    birthdt,
    intakedt,
    last_visit,
    birth_cohort,
    corrected_onsetdate,
    onsetage,
    #"corrected_" = final decision on outcome
    corrected_anydementia,  
    corrected_dsmivdx,
    final_nindx,
    
    #M1, 6, sensitivity analyses
    exposure_year:exp_mos_coverage20_yr, 
    
    #M2
    apoe,
    male,
    education, degree,
    tr_med_inc_hshld, 
    race,
    
    #M3
    smoke, pack_years, 
    exercise, exercise_reg,
    
    #M4a
    Hypertension, Diabetes,
    CV_DIS, #indicates whether subject has ever reported having stroke, TIA, or CEA.
    Heart_Dis, #indicates whether subject has ever reported having an MI, Angina, CABG, or Angioplasty.
    bmi, bmi4,
    
    #M4b
    casi_irt, casi_valid,
    #address exactness
    exact_coverage01_yr:exact_coverage20_yr
    ) %>%
  
  #create/clean up variables
  mutate(
    #rename updated variables for correct outcomes
    nindx = final_nindx,
    dsmivdx = corrected_dsmivdx,
    anydementia = corrected_anydementia,
    onsetdate = corrected_onsetdate,
    
    age_intake = round(as.numeric(intakedt - birthdt)/365, 3),  
    age_last_visit = round(as.numeric(last_visit - birthdt)/365, 3),  
    #traditional definition used by ACT for follow-up time for cases and controls
    age_onset = round(as.numeric(onsetdate - birthdt)/365, 3),
    age_act = round(ifelse(!is.na(age_onset), age_onset, age_last_visit), 3),
    #collapse earliest & latest cohorts since there are few ppl here 
    birth_cohort = factor(ifelse(birth_cohort <= 1905, 1895,
                           ifelse(birth_cohort >= 1935, 1935, birth_cohort))),
    # update anydementia. Unless someone was suspected of dementia and was evaluated for it, the ANYDEMENTIA (as well as DSMIVDX, ANYAD, NINDX, etc.) field will be blank. Think of ‘0’ as a confirmation of no dementia, while blank as a presumption of no dementia.
    anydementia = ifelse(is.na(anydementia), 0, anydementia),
    dsmivdx = ifelse(is.na(dsmivdx), 0, dsmivdx),
    nindx = ifelse(is.na(nindx), 0, nindx),
     #Time-varying covariates
     ##starting age is age on Jan 1st of a given year if participant was enrolled, or on intake date, whichever came later
    age_start_exposure = round(ifelse(format(intakedt, "%Y") == exposure_year,
                                as.numeric(intakedt-birthdt)/365,
                                as.numeric(as.Date(paste0(exposure_year, "-01-01")) - birthdt)/365), 3),
    ##ending age is age at end of year or last visit date, whichever came first 
    age_end_exposure = round(ifelse(format(last_visit, "%Y") == exposure_year,
                                as.numeric(last_visit - birthdt)/365,
                                as.numeric(as.Date(paste0(exposure_year, "-12-31")) - birthdt)/365), 3),
    ### need to change age_last_visit to age_act for sensitivity analyses
    dementia_now = ifelse(age_end_exposure < age_last_visit, 0, anydementia),
    
    ad_nincds = ifelse(nindx %in% c(1,2), 1, 0),
    ad_now = ifelse(age_end_exposure < age_last_visit, 0, ad_nincds),
    
    ## filter out invalid casi scores 
    casi_irt = ifelse(casi_valid ==1, casi_irt, NA),
    income_cat = ifelse(tr_med_inc_hshld < 35000, 1, #tr_med_inc_hshld >= 20000 & 
                                      ifelse(tr_med_inc_hshld >= 35000 & tr_med_inc_hshld < 50000, 2,
                                             ifelse(tr_med_inc_hshld >= 50000 & tr_med_inc_hshld < 75000, 3, 4)
                                             )), #),
    race_white = ifelse(race == 1, 1, 0),
    # make unknown degree=9 an "other" to avoid creating more NAs
    degree = ifelse(degree != 9, degree, 6)
    ) %>%
  select(
    study_id,
    birthdt, birth_cohort, intakedt, onsetdate, last_visit, 
    age_intake, age_act, age_last_visit, 
    
    anydementia, dsmivdx, nindx, ad_nincds,
    dementia_now, ad_now,
    
    age_start_exposure, age_end_exposure,
    #enrollment_yr,
    exposure_year, pollutant, exp_avg01_yr:exp_mos_coverage20_yr,
    
    apoe:degree, tr_med_inc_hshld, income_cat,race, race_white, smoke:bmi4, casi_irt, 
    
    exposure_year:exp_mos_coverage20_yr, 
  ) 
 
#how long have participants been followed? 
yr <- dem0.1 %>%
  group_by(study_id) %>%
  mutate(
    intake_yr = as.numeric(min(format(intakedt, "%Y"))),
    last_visit_yr = as.numeric(min(format(last_visit, "%Y"))),
    fu_yrs = last_visit_yr - intake_yr +1
    ) %>%
  select(
    study_id, intake_yr, last_visit_yr, fu_yrs #yr_n  #pollutant
  ) %>%
  unique()

# 1 row per follow-up/exposure year
enrollment_yrs <-rep(yr$study_id, yr$fu_yrs) %>%
  as.data.frame() %>%
  rename(study_id = ".") %>%
  left_join(yr) %>%
  group_by(study_id) %>%
  mutate(
    #use min() b/c need 1 value and all vector values are same
    enrollment_yr = seq(1:min(fu_yrs)),
    exposure_year = seq(from=min(intake_yr), to=min(last_visit_yr))) %>%
  select(study_id, fu_yrs, enrollment_yr, exposure_year) %>%
  as.data.frame()

#data that can be used for all analyses 
dem0.1 <-  dem0.1 %>% 
  #keep all enrollment years
  right_join(enrollment_yrs) %>%
  select(
    study_id:age_end_exposure,
    fu_yrs,
    enrollment_yr,
    exposure_year:casi_irt
  )


# #proportion of observations with at least 95% of months in 10-year period; for NO2 and PM2.5
# prop.table(table(dem0.1$exp_mos_coverage10_yr>0.95)) %>% round(2)

#data for primary and some secondary analyses 
dem1 <- dem0.1 %>% 
  filter(
    #drop exposure predictions after the last visit when individuals are no longer "at risk" of the terminating event. 
    ## --> note: when using act_age, have to change last_visit to onsetdate
    exposure_year <= as.numeric(format(last_visit, "%Y")),
  ) %>%
  mutate(
     #only keep predictions w/ at least x% coverage
    exp_avg01_yr = ifelse(exp_mos_coverage01_yr >= min.pct, exp_avg01_yr, NA),
    exp_avg05_yr = ifelse(exp_mos_coverage05_yr >= min.pct, exp_avg05_yr, NA),
    exp_avg10_yr = ifelse(exp_mos_coverage10_yr >= min.pct, exp_avg10_yr, NA),
    exp_avg20_yr = ifelse(exp_mos_coverage20_yr >= min.pct, exp_avg10_yr, NA),
    exp_avg10_yr10yrlag = ifelse(exp_mos_coverage10_yr10yrlag >= min.pct, exp_avg10_yr10yrlag, NA),
    exp_avg10_yr20yrlag = ifelse(exp_mos_coverage10_yr20yrlag >= min.pct, exp_avg10_yr20yrlag, NA),
    )   

#make wide format
no2 <- dem1 %>% 
  filter(pollutant == "no2") %>%
  select(-pollutant) %>%
  rename(
    no2_1yr = exp_avg01_yr,
    no2_5yr = exp_avg05_yr,
    no2_10yr = exp_avg10_yr,
    no2_20yr = exp_avg20_yr,
    no2_10yr10yrlag = exp_avg10_yr10yrlag,
    no2_10yr20yrlag = exp_avg10_yr20yrlag,
    no2_coverage_1yr = exp_mos_coverage01_yr,
    no2_coverage_5yr = exp_mos_coverage05_yr,
    no2_coverage_10yr = exp_mos_coverage10_yr,
    no2_coverage_20yr = exp_mos_coverage20_yr,
    no2_coverage_10yr10yrlag = exp_mos_coverage10_yr10yrlag,
    no2_coverage_10yr20yrlag = exp_mos_coverage10_yr20yrlag
    ) 

pm25 <- dem1 %>% 
  filter(pollutant == "pm25") %>%
  select(-pollutant) %>%
  rename(
    pm25_1yr = exp_avg01_yr,
    pm25_5yr = exp_avg05_yr,
    pm25_10yr = exp_avg10_yr,
    pm25_20yr = exp_avg20_yr,
    pm25_10yr10yrlag = exp_avg10_yr10yrlag,
    pm25_10yr20yrlag = exp_avg10_yr20yrlag,
    pm25_coverage_1yr = exp_mos_coverage01_yr,
    pm25_coverage_5yr = exp_mos_coverage05_yr,
    pm25_coverage_10yr = exp_mos_coverage10_yr,
    pm25_coverage_20yr = exp_mos_coverage20_yr,
    pm25_coverage_10yr10yrlag = exp_mos_coverage10_yr10yrlag,
    pm25_coverage_10yr20yrlag = exp_mos_coverage10_yr20yrlag
    )   
dem.w <- full_join(no2, pm25)

#add indicator for whether rows are used in model 2. Do this after creating dem.w, otherwise in_m2 value results in duplicate rows w/ NAs.
dem1 <- dem1 %>%
  mutate(
    in_m2 = (pollutant == "no2" & !is.na(exp_avg10_yr) & !is.na(male) & !is.na(degree) & !is.na(race_white) & !is.na(income_cat) & !is.na(birth_cohort) & !is.na(apoe))
  )

dem.w <- dem.w %>% 
  mutate(
    in_m2 = (!is.na(no2_10yr) & !is.na(male) & !is.na(degree) & !is.na(race_white) & !is.na(income_cat) & !is.na(birth_cohort) & !is.na(apoe)),
    #model weights, use 1 since unweighted
    model_wt = 1
  )

```

```{r}
fixed.covariates <- dem.w %>%
  select(
    study_id:ad_nincds,
    apoe:casi_irt
    ) %>% 
  #make all variables numeric; code has values starting at 0, whereas as.numeric() starts at 1, subtract 1 to fix
  mutate(
    birth_cohort = as.numeric(birth_cohort),
    birth_yr = as.numeric(format(birthdt, "%Y")),
    intake_yr = as.numeric(format(intakedt, "%Y")),
    onset_yr = as.numeric(format(onsetdate, "%Y")),
    last_visit_yr = as.numeric(format(last_visit, "%Y"))
    ) %>%
  #drop dates, which are not "numeric" 
  select(
    -birthdt, -intakedt, -onsetdate, -last_visit
  ) %>%
  #one row per individual
  unique() 

```


# Quality Control

Make sure age variables make sense.

```{r}
#check that ages make sense ages
table(round(dem.w$age_intake, 1) <= round(dem.w$age_act, 1))  
#View(dem.w[which(dem.w$age_intake > dem.w$age_act),]) 
table(dem.w$age_intake <= dem.w$age_last_visit)
#View(dem.w[which(dem.w$age_intake > dem.w$age_last_visit),]) #study_id: 4647 has wrong last_visit/intakedt? last_visit is correct. "Will be updated in next freeze"
table(dem.w$age_act <= dem.w$age_last_visit)

#dementia 
dementia_counts <- dem.w %>% 
  group_by(study_id) %>%
  dplyr::summarize(
    #study_id = mean(study_id),
    #number of times each patient has dementia_now==1 (should be max 1)
    anydementia = mean(anydementia),
    dem_now_n = sum(dementia_now==1)
  ) 

##check that individuals who have anydementia=1 also have dementia_now=1 & those who don't don't  
dementia_counts %>%
  with(., table(anydementia, dem_now_n))

##check that individuals only have 1 dementia_now
dementia_counts %>%
  with(., table(dem_now_n <= 1))
#View(dem.w[which(dem.w$age_intake > dem.w$age_last_visit),]) 
#study_id 1027 has 2 dementia_now's b/c last visit age vs end of year age, which rounded to same thing
#View(dem.w[dem.w$study_id==1027,]) 

#AD 
ad_counts <- dem.w %>% 
  group_by(study_id) %>%
  dplyr::summarize(
    ad_nincds = mean(ad_nincds),
    ad_now_n = sum(ad_now==1)
  ) 
##check that individuals who have ad_nincds=1 also have ad_now=1 & those who don't don't #looks good
ad_counts %>%
  with(., table(ad_nincds, ad_now_n))

##check that individuals only have 1 ad_now
ad_counts %>%
  with(., table(ad_now_n <= 1))

```

# Descriptive Statistics   
## Sample size  

```{r, echo=T}
#sample size 
##no. in cohort 
cohort_ids <- dem.w %>%
  select(study_id) %>%
  unique() 

n_cohort <- length(cohort_ids$study_id)

##no of cases
cases_ids <- dem.w %>%
  filter(anydementia==1) %>%
  select(study_id) %>%
  unique() 

n_cases <- length(cases_ids$study_id)

## no. noncases
non_cases_ids <-dem.w %>%
  filter(anydementia==0) %>%
  select(study_id) %>%
  unique()  

n_noncases <- length(non_cases_ids$study_id)

case_proportion <- round(n_cases/n_cohort, 2)
  
n_personyears <- nrow(dem.w)

data.frame(cohort = n_cohort, 
          cases = n_cases, 
          non_cases =n_noncases,
          case_proportion = case_proportion,
                total_person_years = n_personyears
           ) %>%
  kable(caption = "Sample size")
 
```

## Dementia incidence over time   
### --> why does 1st plot show no cases in 1995 but second does? 

```{r dementia}

#enrolled participants & dementia incidence over time
dem.w %>%
  mutate(dementia_now = factor(dementia_now, levels = c(1,0))) %>%
  ggplot(aes(x= exposure_year, 
             fill= dementia_now)) + 
  geom_bar() + 
  labs(title = "enrolled participants",
       fill = "dementia incidence"
       ) + 
  scale_y_log10()


#dementia incidence over time
dem.w %>%
  filter(dementia_now==1) %>%
  ggplot(aes(x= exposure_year)) + 
  geom_bar() + 
  labs(title= "number of dementia incident cases over time")

```

## Table 2: Exposure Table

Statistics calculated for individuals for whom we know at least `r min.pct*100`% of their past residential address (e.g., 114/120 months for 10-year avg).

Using NO2 (ppb) and PM2.5 (µg/m3) concentration at baseline.

#### --> Do at least 1+ matrix of exposure. “where is the structure of AP based on dataset”? 

AP ~ Calendar yr…age…birth cohort 
could do ANOVA: How much of the variability due to calendar yr vs age vs birth cohort 

```{r exposure}
#participants in M2 at any time point
m2.participants <- dem1 %>%
  filter(in_m2 == TRUE) %>%
  select(study_id) %>%
  unique()  
m2.participants <- m2.participants$study_id

dem.bsl <- dem1 %>%
  filter(
    #1st year of enrollment (baseline)
    enrollment_yr == 1
    ) %>%
  mutate(
    #in_m2 as long as Any rows (years) used (thus this count is greater than in_m2 variable)
    m2_id = study_id %in% m2.participants
  )


#exposure at baseline stratified by year of entry
 no2.all.yrs <- dem1 %>%
  #1st year of enrollment 
  filter(enrollment_yr == 1,
         pollutant == "no2") %>% 
  expo.distrib.fn(dt = ., years.description = "all") 

no2.yr1 <- dem1 %>%
  #1st year of enrollment 
  filter(enrollment_yr == 1,
         pollutant == "no2",
         exposure_year < 2002) %>% 
  expo.distrib.fn(dt = ., years.description = "1994-2001") 

no2.yr2 <- dem1 %>%
  #1st year of enrollment 
  filter(enrollment_yr == 1,
         pollutant == "no2",
         exposure_year >= 2002,
         exposure_year < 2010) %>% 
  expo.distrib.fn(dt = ., years.description = "2002-2009") 

no2.yr3 <- dem1 %>%
  #1st year of enrollment 
  filter(enrollment_yr == 1,
         pollutant == "no2",
         exposure_year >= 2010) %>% 
  expo.distrib.fn(dt = ., years.description = "2010+") 

no2.by.yrs <- rbind(no2.all.yrs, no2.yr1, no2.yr2, no2.yr3) 
no2.by.yrs %>% kable(., digits = 0,
        caption = "Air Pollution Levels at Enrollment (N = subjects)")


# exposure over time for everyone in cohort 
no2.all.yrs.py <- dem1 %>%
  #1st year of enrollment 
  filter(pollutant == "no2") %>% 
  expo.distrib.fn(dt = ., years.description = "all") 

no2.yr1.py <- dem1 %>%
  #1st year of enrollment 
  filter(pollutant == "no2",
         exposure_year < 2002) %>% 
  expo.distrib.fn(dt = ., years.description = "1994-2001") 

no2.yr2.py <- dem1 %>%
  #1st year of enrollment 
  filter(pollutant == "no2",
         exposure_year >= 2002,
         exposure_year < 2010) %>% 
  expo.distrib.fn(dt = ., years.description = "2002-2009") 

no2.yr3.py <- dem1 %>%
  #1st year of enrollment 
  filter(pollutant == "no2",
         exposure_year >= 2010) %>% 
  expo.distrib.fn(dt = ., years.description = "2010+") 

no2.by.yrs.py <- rbind(no2.all.yrs.py, no2.yr1.py, no2.yr2.py, no2.yr3.py) 
no2.by.yrs.py %>% kable(., digits = 0,
        caption = "Air Pollution Levels Over Time for Everyone in Cohort (N = person-yrs)")


```

 
#### --> are those that entered later in life less likely to have addresses for 65 yr?

```{r}

```

 
 
## Distribution of key covariates.    

Do any have less than ~50 individuals?

```{r}

#histograms
fixed.covariates %>% 
  mutate(birth_cohort = as.numeric(birth_cohort)) %>%
  gather(key = "variable",  value = "value", -study_id) %>%   
  ggplot(aes(x=value)) + 
  geom_histogram() +
    facet_wrap(~variable, scales = "free")

fixed.covariates %>%
  select(
    birth_cohort,
    apoe,
    male,
    degree,
    income_cat,
    race_white,
    smoke,
    exercise_reg,
    Hypertension,
    Diabetes,
    CV_DIS,
    Heart_Dis,
    bmi4,
    #casi_irt
  ) %>%
  mutate(
    apoe = factor(apoe),
    male = factor(male),
    race_white = factor(race_white),
    exercise_reg = factor(exercise_reg),
    Hypertension = factor(Hypertension),
    Diabetes = factor(Diabetes),
    CV_DIS = factor(CV_DIS),
    Heart_Dis = factor(Heart_Dis),
    bmi4 = factor(bmi4)
    ) %>%
  describe()
  
#fixed.covariates %>% summaryFull(digit.type = "round")  

#Individuals in each birth Cohort and birth year. Some 5-year cohorts have few only 1 individual
with(fixed.covariates, table(dem=anydementia, birth_cohort=birth_cohort))

#Degree
with(fixed.covariates, table(dem=anydementia, degree = degree))

#Income  
with(fixed.covariates, table(dem=anydementia, income_cat = income_cat))

```

Data is for all individuals with NO2 and/or PM2.5 predictions.    
 
#### --> make hist of # missign observations for variables in our models  

```{r}



```

## Table 1
Participant baseline characteristics. Percents are calculated based on the number of individuals with available data (missing values removed). Some participants did not have baseline exposure estimates and are thus excluded from above/below median columns. 
 
How others have stratified:   
-most proivde a table for the entire cohort (? & don't state which went into models?)   
- entire cohort vs dementia cases (chen 2017)   
- by exposure quartiles at baseline (baseline was during same time period, e.g., 1993-1995) (Oudin 2016; Chang 2014) ["baseline" was same time period for cohort]   
- mean personal AP  

#### --> ? stratify by APOE+, APOE-, APOE missing 

```{r}
#characteristics for entire cohort 
t1.all <- dem.bsl %>% 
#1 row per participant
  filter(pollutant == "no2") %>%
  unique() %>%
  t1.fn(data=.)

kable(t1.all, caption = "Cohort Baseline Characteristics")

#characteristics by dementia status
t1.dem.case <- dem.bsl %>%
  #1 row per participant
  filter(pollutant == "no2") %>%
  filter(anydementia == 1) %>%
  t1.fn(data = ., column.name = "Dementia")

t1.dem.noncase <- dem.bsl %>%
  #1 row per participant
  filter(pollutant == "no2") %>%
  filter(anydementia == 0) %>%
  t1.fn(data = ., column.name = "No Dementia")

t1.by.anydementia <- cbind(t1.dem.case, t1.dem.noncase)

kable(t1.by.anydementia, caption = "Cohort Characteristics by Dementia Outcome")

#characteristics by AD status
t1.ad.case <- dem.bsl %>%
  #1 row per participant
  filter(pollutant == "no2") %>%
  filter(ad_nincds == 1) %>%
  t1.fn(data = ., column.name = "AD")

t1.ad.noncase <- dem.bsl %>%
  #1 row per participant
  filter(pollutant == "no2") %>%
  filter(ad_nincds == 0) %>%
  t1.fn(data = ., column.name = "No AD")

t1.by.ad <- cbind(t1.ad.case, t1.ad.noncase)

kable(t1.by.ad, caption = "Cohort Characteristics by AD Outcome")

#characteristics by those in M2
t1.in.m2 <- dem.bsl %>%
  #1 row per participant
  filter(pollutant == "no2") %>%
  filter(in_m2 == T) %>%
  t1.fn(data = ., column.name = "In M2")

t1.not.in.m2 <- dem.bsl %>%
  #1 row per participant
  filter(pollutant == "no2") %>%
  filter(in_m2 == F) %>%
  t1.fn(data = ., column.name = "Not in M2")


t1.m2 <- cbind(t1.in.m2, t1.not.in.m2)

kable(t1.m2, caption = "Cohort Characteristics by whether subjects were included in Model 2")

```

## Correlations of variables in models     

```{r}
#dataset with model variables of interest for descriptive purposes (similar dataset generated in models.fn())
model.vars <- dem.w %>%
  select(
    #m1 & sensitivity
    no2_1yr:no2_20yr ,
    #m2
    apoe,
    male,
    race_white,
    income = income_cat,
    edu = degree,
    birth_cohort,
    #m3
    smoke,
    exercise_reg,
    #m4
    Hypertension,
    Diabetes, 
    CV_DIS,
    Heart_Dis,
    bmi = bmi4,
    #m6
    pm25_1yr:pm25_20yr,
    #pm25_10yr
    ) %>%
  mutate(
  #make factors
    income = factor(income),
    edu = factor(edu),
    birth_cohort = factor(birth_cohort),
    smoke = factor(smoke),
    
    #make 10 ppb units
    no2_10ppb_1yr = no2_1yr/my.no2.units,
    no2_10ppb_5yr = no2_5yr/my.no2.units,
    no2_10ppb_10yr = no2_10yr/my.no2.units,
    no2_10ppb_20yr = no2_20yr/my.no2.units,
    no2_10ppb_10yr10yrlag = no2_10yr10yrlag/my.no2.units,
    no2_10ppb_10yr20yrlag = no2_10yr20yrlag/my.no2.units,
    
    #make 5 mg/m3
    pm25_1ugm3_1yr = pm25_1yr/my.pm25.units,
    pm25_1ugm3_5yr = pm25_5yr/my.pm25.units,
    pm25_1ugm3_10yr = pm25_10yr/my.pm25.units,
    pm25_1ugm3_20yr = pm25_20yr/my.pm25.units,
    pm25_1ugm3_10yr10yrlag = pm25_10yr10yrlag/my.pm25.units,
    pm25_1ugm3_10yr20yrlag = pm25_10yr20yrlag/my.pm25.units,
   ) %>%
  #drop these columns to avoid confusion, since using 10 ppb for NO2 and 5 ug/m3 for pm2.5
  select(-c(no2_1yr:no2_20yr, 
            pm25_1yr:pm25_20yr)) 

```


See high correlatin (R^2) between NO2 and PM2.5. Results may be confounded by PM2.5.

```{r}
#plots
model.vars %>% 
  mutate(
    #make numeric for cor() fn
    income = as.numeric(income),
    edu = as.numeric(edu),
    birth_cohort = as.numeric(birth_cohort),
    smoke = as.numeric(smoke)
    ) %>%
  #select(apoe:bmi) %>%
  cor(method = "pearson",
      use ="complete.obs") %>%
  corrplot::corrplot(method="color")
 
r <- model.vars %>% 
  mutate(
    #make numeric for cor() fn
    income = as.numeric(income),
    edu = as.numeric(edu),
    birth_cohort = as.numeric(birth_cohort),
    smoke = as.numeric(smoke)
    ) %>%
    select(no2_10ppb_1yr:pm25_1ugm3_10yr20yrlag) %>%
  cor(method = "pearson",
      use ="complete.obs")  

r2 <- r^2

kable(r2, caption = "R2", digits = 3)


# just 10 yr R2
(no2_pm25_10yr_r2 <- with(dem.w, 
                         cor(no2_10yr, pm25_10yr,
                             method = "pearson",
                             use = "complete.obs")^2))


```


# Inferential Statistics

## Weights 














## Primary Analysis, Redued & Extended Models

"Hazard of dementia incidence is __% higher for every additional 10 ppb of NO2 exposure in the past 10 years.

### Dementia Incidence 

#### --> do IPW for all models b/c imp variable & we’re missing a lot. 
#### --> use dataset w/ missing values (not filled in dataset)?
### --> make diff.exposures.fn() only calc diff exposure periods for M2 - so can see if model warning msgs are relevant 


```{r }
#run all models, all exposure windows
dem.results <- diff.exposures.fn(mydata.2 = dem.w,
                   surv.time2.2 = "age_end_exposure", 
                   surv.event.2 = "dementia_now", 
                   outcome.text.2 = "Dementia")

#table of all HRs for all times & models
 dem.results$HRs %>% 
   filter(
    exposure == "10yr" | Model == "2. Primary"
    #hr <12
         ) %>% 
   arrange(Model) %>%
   kable(caption = "Dementia HRs")

#plot of all HRs for all times & models
dem.results$HRs %>%
  filter(
    exposure == "10yr" | Model == "2. Primary"
    #hr <12
         ) %>%
  hr.plot(., outcome.var = "Dementia")   

# example of raw model output
print("10 yr exposure model")
dem.results$model.output$`10yr` 
dem.results$model.output$`1yr`$model2
dem.results$model.output$`5yr`$model2
dem.results$model.output$`10yr10yrlag`$model2
dem.results$model.output$`10yr20yrlag`$model2
dem.results$model.output$`20yr`$model2

#survival object
#dem.results$survival.object

# --> this is for 10yr20yrlag yr exposure?
#dataset w/ renamed column names
#dem.results$renamed_df

```


## Other Sensitivity Analyses    
### AD Incidence      

### --> see what models warning msgs are coming from

```{r}
#run all models, all exposure windows
ad.results <- diff.exposures.fn(mydata.2 = dem.w,
                   surv.time2.2 = "age_end_exposure", 
                   surv.event.2 = "ad_now", 
                   outcome.text.2 = "AD")

#table of all HRs for all times & models
ad.results$HRs %>% 
   filter(
    exposure == "10yr" | Model == "2. Primary"
         ) %>% 
   arrange(Model) %>%
   kable(caption = "AD HRs")

#plot of all HRs for all times & models
#### --> large CI for 20 yr copollutant model
ad.results$HRs %>% 
   filter(
    exposure == "10yr" | Model == "2. Primary"
         ) %>% 
  hr.plot(., outcome.var = "AD")   

# example of raw model output
print("10 yr exposure model")
ad.results$model.output$`10yr`
ad.results$model.output$`1yr`$model2
ad.results$model.output$`5yr`$model2
ad.results$model.output$`10yr10yrlag`$model2
ad.results$model.output$`10yr20yrlag`$model2
ad.results$model.output$`20yr`$model2

```

### Redefine dementia onset to match ACT study definition

```{r}
##when using ONSET AGE (age_act), need to drop exposure predictions after age_act. filter(age_at_exposure <= age_act) & dementia_now = ifelse(age_at_exposure < age_act, 0, anydementia),


```



### Cox model assumptions and inference validity    
1. Proportional hazards Assumption    
a) Schoenfeld residuals. If the proportional hazards model is correctly specified, there should be no trend in the residuals over time (uncorrelated, with mean zero across event times)

```{r}
m2 <- dem.results$model.output$`10yr`$model2

```

```{r}
## ?? interpretation of schenresid matrix?
schoenresid = residuals(m2, type = "scaledsch")

time = as.numeric(rownames(schoenresid))

# link no2_10yr & "times" column
cbind(resid=schoenresid[,1], time) %>%
  as.data.frame() %>%
  ggplot(aes(x=time, y=resid)) + 
  geom_point() + 
  geom_smooth() + 
  labs(y = "scaled Schoenfeld residuals for NO2 coefficient",
       x = "failure time (age at dementia incidence)")

```

b. formally test. using cox.zph(). if global p-val is significant, assumption is violated   
-assumption is not violated 

```{r}
cox.zph(m2)

```

2. linear relationship between continuous covariates and log hazard of the outcome    
If a correct model is used, these residuals are uncorrelated and have mean nearly zero.

### --> ?update "in_m2" - ?dropping ppl w/ only bsl obs ???

Martingale residuals are used to check if the functional form of the covariate is okay (eg. linear vs quadratic terms). 

```{r, eval=F}
##??
martingalesid = residuals(m2, type = "martingale", data = dem.w) %>%
  as.data.frame() %>%
  #df rows used in M2
  rownames_to_column(.) 
names(martingalesid)[names(martingalesid) %in% "."] <- "martingaleresid" 
  
#only keep rows used in M2. 
dem.w.m2 <- dem.w[martingalesid$rowname,] 

plot.martingaleresid <- cbind(resid=martingalesid$martingaleresid, no2_10yr=dem.w.m2$no2_10yr) %>%
  as.data.frame() 

plot.martingaleresid %>%
  ggplot(aes(x=no2_10yr, y=resid)) +
  geom_point(alpha=0.3) +
  geom_smooth() +
  labs(y = "Martingale residuals",
       x = "NO2 (ppb), 10 yr avg"
      )

#mean, +-SD  # looks good, mean is close to 0?
print("mean, SD")
mean_sd(plot.martingaleresid$resid)

```

3. no outliers or influential observations, $\triangle \beta$

### --> calculate standardized delta Bs? ?how far away ß[-i]'s are from original ß[all observations]? 

 
```{r, eval=T, fig.height=10}
# B537 L3, slide 125

dfbetas <- residuals(m2, type="dfbeta") 
#rename columns
colnames(dfbetas) <- names(coef(m2))

dfbetas %>%  
  as.data.frame() %>%
  #get rows used in model
  rownames_to_column(var = "ind") %>%
  mutate(ind = as.numeric(ind)) %>%
  #make long format
  gather(covariate, value, -ind) %>%
  as.data.frame() %>%
  #plot
  ggplot(aes(x=ind, y=value)) +
  geom_point() +
  facet_wrap(~covariate, scales="free") + 
  labs(x="observation index",
       y= "delta beta")


```



### Restrict Analysis to individuals for whom we have high quality data

now, using everyone   
...get rid of PO boxes 

```{r}
#describe address covrage over time?


```

### Adjust for baseline CASI score 

```{r}

```

### Adjust for ACT cohort 

```{r}

```

### IPW for missing APOE

##### --> change to: M2 w/o IPW
 
#### --> fix glmnet() issue (rmarkdown won't knit).  
#### --> update selected variables from Lasso 

```{r}
# see B540 L7-8
#1. fill in missing values with their most likely option (mean for continuous, mode for categorical variables)
#2. use selection model (e.g. lasso for glm) to select predictors of whether or now we have APOE values for people: apoe_available (in apoe.w)
# 3. fit logistic model to determine probability of observing an observation given predictors: glm(apoe_available ~ [predictors]). use model w/ dataset to get predicted values (probability of being observed), 
# 4. take the inverse of probabilities to calculate "weights", use these weights in coxph(, weights = c()) 

apoe <- fixed.covariates %>%
  mutate(
    apoe_available = !is.na(apoe)
  ) %>% 
  #don't inclue race_white b/c it's calculated from race (already in df)
  select(-apoe, 
         -race_white
         ) 

#1. replace missing values w/ most likely outcome  
##variables w/ missing values  
with.nas <- names(which(colSums(is.na(apoe)) > 0))
#1 = TRUE, 0 = FALSE
mynumeric = c(1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0)
  
#replace  missing values w/ mean (if numeric) or mode (if factor)
for (i in seq_along(with.nas)) {
  #vector w/ missing values 
  myvar <- with.nas[i]  
  apoe[[myvar]] <- replace.nas.fn(apoe[[myvar]], 
                                  numeric = mynumeric[i])
  }

#check that there are no more NAs #looks good
#describe(apoe) 
#table(is.na(apoe))
 
#2. Use Lasso to select variables most predictive of APOE being present
apoe <- apoe %>%
  mutate(
#factor variables for correct use with model.matrix()
    degree = factor(degree),
    income_cat = factor(income_cat),
    race = factor(race),
    smoke = factor(smoke),
    #exercise_reg = factor(exercise_reg),
    bmi4 = factor(bmi4)
  )

#create categorical dummy variables
x <- model.matrix(apoe_available~., apoe)[,-1]
y <- as.numeric(apoe$apoe_available)

#select lambda through CV
cv.out <- cv.glmnet(x = x, 
                    y = y, 
                    alpha=1, 
                    family= "binomial")

bestlam <- cv.out$lambda.min

lasso.m <- glmnet(x = x, 
                  y = y, 
                 alpha = 1, 
                 family= "binomial")

lasso.coef <- predict(lasso.m, 
                      type= "coefficients", 
                      s= bestlam)[1:(ncol(x)+1),]

#coefficients chosen by Lasso w/ bestlam that are not 0
lasso.vars <- lasso.coef[lasso.coef != 0]
print("variables selected via Lasso")
names(lasso.vars)[names(lasso.vars) != "(Intercept)"]
 
lasso.m.vars <- apoe %>%
  select(
    study_id,
     #y
    apoe_available,
    #categories selected via Lasso 
    #x's
    age_intake, age_last_visit, intake_yr,
    dsmivdx, ad_nincds, 
    male, 
    race,
    smoke,
    exercise_reg,
    Heart_Dis,
    bmi4,
    casi_irt
    )  

#3. model to predict APOE variable being present
apoe.m <- lasso.m.vars %>%
  select(-study_id) %>%
  glm(apoe_available ~ .,
  family = "binomial",
  data = .
  ) 

apoe.m %>% summary()

##probability of APOE being present
lasso.m.vars$apoe_available_prob <- predict(apoe.m, type = "response") 
 
#check that this is the same as using glm()  
apoe.male.m <- lasso.m.vars %>%
  glm(apoe_available ~ male,
  family = "binomial",
  data = .) 
#summary(apoe.male.m)

lasso.m.vars$apoe_male_prob <- predict(apoe.male.m, type = "response") 

lasso.m.vars <- lasso.m.vars %>% 
  mutate(model_wt = apoe_male_prob/apoe_available_prob)
  
# 4. take the inverse of probabilities to calculate "weights", use these weights in coxph(, weights = c()) 
dem.w.wts <- dem.w %>% 
  #drop weight = 1
  select(-model_wt) %>%
  #add stabilized weights  
  left_join(lasso.m.vars[c("study_id", "model_wt")])

dem.wts.results <- dem.w.wts %>%
  #run all models, all exposure windows
  diff.exposures.fn(mydata.2 = ., 
                   surv.time2.2 = "age_end_exposure", 
                   surv.event.2 = "dementia_now", 
                   outcome.text.2 = "Dementia" #
                   )

#table of all HRs for all times & models
dem.wts.results$HRs %>% 
   filter(
    exposure == "10yr" | Model == "2. Primary"
         ) %>% 
   arrange(Model) %>%
   kable(caption = "Dementia HRs - using IPW")

#plot of all HRs for all times & models
#### --> large CI for PM25 20 yr model
dem.wts.results$HRs %>% 
   filter(
    exposure == "10yr" | Model == "2. Primary"
         ) %>% 
  hr.plot(., outcome.var = "Dementia (IPW)")   

```


 

### M2 w/ IPW but using diff dataset (w/ or w/o NAs)


```{r}

```


#### --> update code

```{r}
#compare unweighted to weighted results #they look a little diff
hr.comp <-dem.results$HRs[c("Model", "exposure", "hr")]
hr.comp <- hr.comp %>%
  rename(unweighted_hr = hr) %>%
  mutate(weighted_hr = dem.wts.results$HRs$hr) %>%
  filter(
    exposure == "10yr" | Model == "2. Primary"
         ) 

hr.comp %>%
  comp.x.y.plot.fn(data.wide =., 
                   x.variable = "unweighted_hr", 
                   y.variable = "weighted_hr", 
                   mycolour.var = "Model", 
                   rmse.digits = 2, 
                   r2.digits = 2) 
 

```


### keep exposure observations if address available at least 75% of time 

Currently using 95% as our threshold.

```{r}

```

### Optional 

1. finer adjustments for confounders
2. Model "1b" w/ APOE stratification
3. calculate IPW weights based on the probability that All of the M2 predictors (not just APOE) are observed (e.g., all_covs_available ~ [predictors])

```{r}


```


 
