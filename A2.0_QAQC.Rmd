---
title: 'Aim 2: QAQC - Instrument Readings'
author: "Magali Blanco"
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: yes
    df_print: paged
    toc: yes
    toc_depth: '3'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: console
---

```{r}
# ---> TO DO:
# ---> ? how to drop very low/high UFP & BC readings?
### --> keep DiscMini

```

```{r, echo=F}
# notes
#BC = 880 nm (IR); 625 nm (Red); 528 nm (Green); 470 nm (Blue); and 375 nm (UV);  
# missingness
## 2019-07-17_R07 - PTRAKS had issues, no/little data collected
## 2019-07-17_R07	- PTRAKS not started on time & had issues, no/little data collected

```

# Summary of Script

**All data**   

* keep only BC and PTRAK readings, current MM stops (drop old stops)
* relabeled incorrectly labeled instruments
* split up data into UFP & BC datasets 

**UFP** 

* drop erroneous UFP instrument readings due to wick/other PTRAK issues
	+ < ~300 data points were dropped from 2 periods where PTRAKs appeared to have failed - concentrations were at or near zero and very different than concentrations immediately before/after
	+ these readings did not correlate well to measures from other particle measurement instruments

**BC** 

* perform ONA correction   
* estimate BC from 880 nm (IR) wavelength 

**All data** 

* compare co-located instruments to make sure readings are similar
  + PTRAK - PTRAK   
	+ NanoScan - NanoScan    
	+ PTRAK - NanoScan (< ptrak limit)   
    - used NanoScan particle counts comparable to PTRAK (subtracted counts for particles < 20 nm)   

# Analyses  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,  
                      cache=T, cache.comments = F, 
                      message = F, warning = F, 
                      tidy.opts=list(width.cutoff=60), tidy=TRUE,
                      fig.height = 5, fig.width = 10
                      )  

# Clear workspace of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
  res <- suppressWarnings(
    lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
           detach, character.only=TRUE, unload=TRUE, force=TRUE))
}

# load packages 
pacman::p_load(tidyverse, 
               # tables
               knitr, kableExtra,
               # dates
               chron, lubridate,
               # statistics
               Hmisc
               )   

# source global variables & functions
source("0.Global_Fns.R")
source(file.path("A2.0.1_Var&Fns.R"))

#read in data
mm_full0 <- readRDS(file.path("Data", "Aim 2", "Mobile Monitoring", "mm_raw_2020-03-17.rda"))

### --> why do these runs have missing variable/value? 2019-05-14_R03, 2019-07-17_R07	

site_ids <- read.csv(file.path("Data", "Aim 2", "Mobile Monitoring", "locations_190715.csv")) %>%
  select(site_id) %>%
  #drop Roosevelt garage stop; drop site w/ only 1 observation - stopped sampling here & added MS0601
  filter(!site_id %in% c("MS0000", "MS0398")) %>%
  unique()

mm_full <- mm_full0 %>%
  # --> why do 2 runs have missing values??
  select(-duration_sec) %>%
  drop_na(value) %>%
  filter(!variable %in% c("ufp_disc_ct_cm3",
                         "ufp_disc_med_size_nm", 
                         "ufp_pt_screen_ct_cm3"
                         )) %>%
  mutate(variable = recode_factor(factor(variable),  
                              "ufp_pt_noscreen_ct_cm3" = "ptrak_pt_cm3")) %>%
  # not sure why there are repeated identical rows for ufp_scan_11_5_ct_cm3
  unique()

#unique(mm_full$variable)

#drop old stops 
mm_full <- left_join(site_ids, mm_full)

#relabel instruments that were incorrectly labeled
mm_full <- mm_full %>%
  mutate(instrument_id = ifelse(instrument_id == "BC_0063", "BC_63",
                                #ifelse(instrument_id == "CO_2", "CO_3",
                                       ifelse(instrument_id == "PMSCAN_1", "PMSCAN_3",
                                              instrument_id))
         )

#Create NanoScan counts (20-420 nm) similar to ptraks: 20-1000 nm)
ns <- mm_full %>%
  #look at variables from NanoScan
  filter(grepl("scan", variable)) %>%
  #not sure why there are repeated identical rows for ufp_scan_11_5_ct_cm3
  unique() %>%
  #make wide format to calculate the difference
  spread(variable, value) %>%
  # dropping ufp_scan_20_5_ct_cm3 counts (17.8-23.7 nm) since PTRAK-NS comparison looks slightly better without these counts.
  mutate(scan_20_420_pt_cm3 = ufp_scan_ct_cm3 - ufp_scan_11_5_ct_cm3 - ufp_scan_15_4_ct_cm3 - ufp_scan_20_5_ct_cm3
         ) %>%
  select(-c(ufp_scan_11_5_ct_cm3, # 10.0-13.3 nm
            ufp_scan_15_4_ct_cm3, # 13.3-17.8 nm
            ufp_scan_20_5_ct_cm3, # 17.8-23.7 nm
            ufp_scan_ct_cm3)) %>%
  #dplyr::rename(scan_10_420_pt_cm3 = ufp_scan_ct_cm3) #%>%
  #make back to long format
  gather("variable", "value", scan_20_420_pt_cm3)

# replace old nanoscan calculations w/ new ones similar to PTRAK
mm_full <- mm_full %>%
  filter(!grepl("scan", variable)) %>%
  rbind(ns) %>%
  arrange(time)   

# create new temporal variables, arrival time and date
mm_full <- mm_full %>%
  dplyr::group_by(runname, site_id) %>%
  #set time to arrival time
  dplyr::mutate(arrival_time = min(time)) %>%
  mutate(date = as.Date(substr(arrival_time, 1,10))) %>%
  ungroup()

```

upload zero

```{r}
my_tz <- "America/Los_Angeles"

# PTRAKS
my_path <- file.path("Data", "Aim 2", "Zero Checks", "ptrak")
lab_ptrak_zero <- read_directory_files(folder_path = my_path, instrument = "ptrak") %>%
  #only 2 daytes have filter start/end times. keep all readings for rest
  filter(
    # these days do not have notes on start/end filter times
    (time > ymd_hms("2019-03-13 13:39:30", tz = my_tz) & time < ymd_hms("2019-03-13 13:45:00", tz = my_tz)) |
    (time > ymd_hms("2019-10-22 16:34:00", tz = my_tz) & time < ymd_hms("2019-10-22 16:44:00", tz = my_tz)) |
    
    # NOT DOING THIS - these days have notes on start/end filter times. added 2 min to start/end
    (time > ymd_hms("2019-10-02 13:53:19", tz = my_tz)  & time < ymd_hms("2019-10-02 14:04:00", tz = my_tz)) |
    (time > ymd_hms("2019-11-21 11:05:50", tz = my_tz)  & time < ymd_hms("2019-11-21 11:18:20", tz = my_tz) )
    ) #%>%
  # mutate(
  #   zero_check = ifelse(
  #     (time > ymd_hms("2019-10-02 13:53:19", tz = my_tz)  & time < ymd_hms("2019-10-02 14:04:00", tz = my_tz)) |
  #   (time > ymd_hms("2019-11-21 11:05:50", tz = my_tz)  & time < ymd_hms("2019-11-21 11:18:20", tz = my_tz)), TRUE, NA)
  #   )

ptrak_zero_start_end <- ymd_hms(
  "2019-10-02 13:53:19",
  "2019-10-02 14:04:00",
  
  "2019-11-21 11:05:50",
  "2019-11-21 11:18:20",
  
  #file not found?
  #"2019-11-21 11:07:10", 
  tz = "America/Los_Angeles"
)

```

```{r}
# BC
my_path <- file.path("Data", "Aim 2", "Zero Checks", "bc")
lab_bc_zero <- read_directory_files(folder_path = my_path, instrument = "bc") %>%
  #only 2 daytes have filter start/end times. keep all readings for rest
  filter(
    # these days do not have notes on start/end filter times  
    ##  16:25:00 - 16:30:00 ??
    (time > ymd_hms("2019-10-22 16:20:00", tz = my_tz) & time < ymd_hms("2019-10-22 16:35:00", tz = my_tz)) |

    # NOT DOING THIS : these days have notes on start/end filter times. added 2 min to start/end
    (time > ymd_hms("2019-10-02 14:07:30", tz = my_tz)  & time < ymd_hms("2019-10-02 14:27:00", tz = my_tz)) |
    (time > ymd_hms("2019-11-21 11:09:16", tz = my_tz)  & time < ymd_hms("2019-11-21 11:21:45", tz = my_tz) )
    ) # %>%
  # mutate(
  #   zero_check = ifelse(
  #     (time > ymd_hms("2019-10-02 14:07:30", tz = my_tz)  & time < ymd_hms("2019-10-02 14:27:00", tz = my_tz)) |
  #   (time > ymd_hms("2019-11-21 11:09:16", tz = my_tz)  & time < ymd_hms("2019-11-21 11:21:45", tz = my_tz)), TRUE, NA)
  #   )

bc_zero_start_end <- ymd_hms(
  "2019-10-02 14:07:30",
  "2019-10-02 14:27:00",
  
  "2019-11-21 11:09:16",
  "2019-11-21 11:21:45",
  
  tz = "America/Los_Angeles")


# lab_ptrak_zero %>%
#   ggplot(aes(x=time, y= Conc_pt_cm3, col=instrument_id, shape=location)) + 
#   geom_point() + 
#   geom_vline(xintercept = ptrak_zero_start_end, col="red") +
#   geom_hline(yintercept = 0, col="black") +
#   scale_y_log10() +
#   facet_wrap(~date(time), scales = "free") + 
#   labs(
#     title = "P-TRAK Zero checks",
#     y = "UFP (pt/cm3)",
#     col = "Instrument ID",
#     shape = "Location"
#   )
# 
# lab_bc_zero %>%
#   ggplot(aes(x=time, y= ir_bc, col=instrument_id, shape=location)) + 
#   geom_point() + 
#   geom_vline(xintercept = bc_zero_start_end, col="red") +
#   geom_hline(yintercept = 0, col="black") +
#   scale_y_log10() +
#   facet_wrap(~date(time), scales = "free") + 
#   labs(
#     title = "Aethalometer (IR) Zero checks",
#     y = "Raw BC reading (ng/m3)",
#     col = "Instrument ID",
#     shape = "Location"
#   )

```

upload lab collocations 

```{r}
# PTRAKS
my_path <- file.path("Data", "Aim 2", "Lab Collocations", "ptrak")
lab_ptrak_collos <- read_directory_files(folder_path = my_path, instrument = "ptrak") %>%
  dplyr::rename(value = Conc_pt_cm3) %>%
  #only keep these times, PMPT_94 had weird readings before - setup issues?
  filter(time > ymd_hms("2019-04-18 12:30:00",tz = my_tz)) 

# BC
my_path <- file.path("Data", "Aim 2", "Lab Collocations", "bc")
lab_bc_collos <- read_directory_files(folder_path = my_path, instrument = "bc") %>%
  dplyr::rename(value = ir_bc) %>%
  select(-ir_atten) %>%
  # round to nearest 10s to align readings from different instruments
  mutate(time_round = round_date(time, unit = "10s"))  
 
```

Instruments Used.

Note: the last day of sampling in 2020 before COVID-19 may have impacted traffic and air pollution patterns was ~ 3/5. Cutting data off here would still give us 12-months of data (though with fewer than the number of desired samples at some locations).

```{r}
#instrument used each day
mm_full %>%
  filter(grepl("ptrak|scan|ir_bc", variable)) %>%
  select(instrument_id, time, variable) %>%
  label_pollutant(var = "variable") %>%
  mutate(date = date(time)) %>%
  unique() %>%
  ggplot(aes(x=date, y=instrument_id, colour = variable)) + 
  geom_point(alpha=0.5) + 
  theme(legend.position = "bottom") + 
  labs(title = "Instruments used",
       x = "Date",
       y = "Instrument ID"
       ) 
 
```

Sample size: total & per instrument 

```{r}
mm_full %>%
  filter(grepl("ptrak|ir_bc", variable)) %>%
  group_by(variable) %>%
  dplyr::summarize(
    no_sampling_days = length(unique(runname)),
    no_samples = n(),
    start_date = min(date),
    end_date = max(date)
    ) %>%
  kable(caption = "Total samples per pollutant") %>% 
  kable_styling()
  
```

```{r}
mm_full %>% 
  dplyr::filter(grepl("ptrak|ir_bc", variable)) %>%
  group_by(variable) %>%
  mutate(
    N = n()) %>%
group_by(variable, instrument_id) %>%
  dplyr::summarize(
    instrument_samples = n(),
    instrument_sampling_days = length(unique(runname)),
    start_date = min(date),
    end_date = max(date),
    instrument_prop = round(instrument_samples/N[1], 2)) %>%
  kable(caption = "Samples per instrument") %>% 
  kable_styling()

```

Drop PTRAK readings from instruments PMPT_2 and PMPT_4 since these were barely used and never on their own. Drop PMPT_1 since it was never collocated, it was only used on its own for 5 days in 2019, and we have resampled these 5 days in 2020. 
 
```{r}
mm_full <- mm_full %>%
  filter(!instrument_id %in% c("PMPT_1", 
                               "PMPT_2", "PMPT_4"
                               ))
```

```{r}
#instrument used each day
mm_full %>%
  filter(grepl("ptrak|ir_bc", variable)) %>%
  select(instrument_id, time, variable) %>%
  label_pollutant(var = "variable") %>%
  mutate(date = date(time)) %>%
  unique() %>%
  ggplot(aes(x=date, y=instrument_id, colour = variable)) + 
  geom_point(alpha=0.5) + 
  theme(legend.position = "bottom") + 
  labs(title = "UFP and BC Instruments Used",
       x = "Date",
       y = "Instrument ID"
       ) 
```


Distribution of raw data 

```{r}
mm_full %>%
  filter(grepl("ptrak|ir_bc", variable)) %>%
  group_by(variable) %>%
  distribution.table(var.string = "value") %>%
  mutate(variable =recode_factor(factor(variable),
                                  "ptrak_pt_cm3" = "P-TRAK UFP (pt/cm3)",
                                  "ma200_ir_bc1" = "MA200 BC (ng/m3)")) %>%
  rename(Pollutant = variable) %>% 
  kable(caption = "Distribution of raw data",
        align = "r") %>%
  kable_styling()

```

Set up common variables 

```{r, echo=T}
max_bc_limit <- 1e6 #ng/m3
bc_factor <-10 

ptrak_lim <- 5e5 
low_ufp_lvl <- 300

# how many plots to print/page when using paginate
plots_per_page <- 12

```

# Distribution of Raw Aethalometer Readings 

Readings from all wavelengths are similar? All have negative readings.

```{r}
mm_full %>%
  filter(grepl("_bc1", variable)) %>%
  ggplot(aes(x=value, fill=variable)) + 
  geom_density(alpha=0.3) + 
  geom_vline(xintercept = 0, col = "red") +
  labs(
    title = "Distribution of raw aethalometer readings from each wavelength"
  )

```

```{r}
mm_full %>%
  filter(grepl("_bc1", variable)) %>%
  group_by(variable) %>%
  distribution.table(var.string = "value") %>%
  kable(caption = "Distribution of raw aethalometer readings from each wavelength") %>%
  kable_styling()
  
```

Look at instrument attenuations. Instruments may be less sensitive at detecting change above 50%. Everything looks good.

```{r}
mm_full %>%
  filter(grepl("_atn", variable)) %>%
  ggplot(aes(x=value, fill=variable)) + 
  geom_density(alpha=0.3) + 
  geom_vline(xintercept = 50, col = "red") +
  labs(
    title = "Distribution of wavelength attenuation",
    x = "Attenuation (%)"
  )

```

# Correct BC readings using the Optimized Noise-Reduction Algorithm (ONA) 

```{r}
## could pick a diff attenuation if corrections are still noisy. the default is 5%

# this does not need to be done separatebly by instrument, results are the same. May be related to different tape positions for differnet instruments, which is already taken into account?
bc.w <- mm_full %>%
  filter(grepl("ma200", variable)) %>%
  # one column per MA200 column (like instrument output file)
  spread(variable, value) %>%
  ONA() 

bc <- bc.w %>%
  #only keep ONA-corrected values
  select(site_id:date, 
        ona_bc = ona_ir,
        ma200_bc = ma200_ir_bc1) %>%
  gather("variable", "value", contains("bc")) %>%
  # BC_63 has a few missing values during a 2.5-minute period
  drop_na(value)
  
```

Distribution of raw & ONA-corrected BC readings. We still see some negative values, but there are fewer and they are less extreme. The highest values are a bit lower than the raw values.

```{r}
bc %>%
  label_pollutant(.) %>%
  group_by(BC = variable) %>%
  distribution.table(var.string = "value") %>%
  # mutate(BC = recode_factor(factor(BC),
  #                            ma200_bc = "Raw",
  #                            ona_bc = "ONA-Corrected")) %>%
  kable(caption = "Distribution of raw and ONA-corrected 10-sec aethalometer readings (BC ng/m3)") %>%
  kable_styling()

```


```{r}
plot_min <- min(bc$value)
plot_max <- max(bc$value)

#BC/IR
bc %>%
  spread(variable, value) %>%
  ggplot(aes(x= ma200_bc, y = ona_bc)) + 
  geom_point(aes(col = route)) + 
  geom_abline(intercept = 0, slope = 1) +
  geom_hline(yintercept = 0, linetype = "dashed", col = "red") +
  geom_vline(xintercept = 0, linetype = "dashed", col = "red") +
  geom_smooth() + 
  xlim(plot_min, plot_max) +
  ylim(plot_min, plot_max) +
  labs(title = "IR (880 nm, black carbon) concentrations before and after ONA correction",
      x = "Raw aethalometer Reading (ng/m3)",
      y = "ONA-Corrected Reading (ng/m3)"
       )
```

Only keep desired aethalometer readings (raw & ONA corrected IR, 880 nm)  

```{r}
mm_full <- mm_full %>%
  #drop old, raw MA readings
  filter(!grepl("ma200", variable)) %>%
  # attach only the MA readings desired (raw & ONA IR)
  rbind(bc) %>%
  mutate(variable = droplevels(variable))

```

# Zero Checks

Days with vertical red lines are those with documented filter on/off times. Other days do not have notes.

## UFP

Readings are mostly 0, with the exception of 10/2/19 where there are some elevated counts

```{r}

lab_ptrak_zero %>%
  ggplot(aes(x=time, y= Conc_pt_cm3, col=instrument_id, shape=location)) + 
  geom_point() + 
  geom_smooth() +
  geom_vline(xintercept = ptrak_zero_start_end, col="red") +
  geom_hline(yintercept = 0, col="black") +
  scale_y_log10() +
  facet_wrap(~date(time), scales = "free") + 
  labs(
    title = "P-TRAK Zero checks",
    y = "UFP (pt/cm3)",
    col = "Instrument ID",
    shape = "Location"
  )

```

Zero check summary table.

```{r}
lab_ptrak_zero %>%
  group_by(Date = date(time)) %>%
  distribution.table(var.string = "Conc_pt_cm3") %>%
  kable(caption = "Distribution of P-TRAK readings (pt/cm3) during zeroc checks") %>%
  kable_styling()

```


## BC

Raw aethalemter readings are noisy very.

```{r}
lab_bc_zero %>%
  ggplot(aes(x=time, y= ir_bc, col=instrument_id, shape=location)) + 
  geom_point() +
  geom_smooth() +
  geom_vline(xintercept = bc_zero_start_end, col="red") +
  geom_hline(yintercept = 0, col="black") +
  #scale_y_log10() +
  facet_wrap(~date(time), scales = "free") + 
  labs(
    title = "Aethalometer (IR) Zero checks",
    y = "Raw BC reading (ng/m3)",
    col = "Instrument ID",
    shape = "Location"
  )

```

```{r}
lab_bc_zero %>%
  group_by(Date = date(time)) %>%
  drop_na(ir_bc) %>%
  distribution.table(var.string = "ir_bc") %>%
  kable(caption = "Distribution of Aethalometer readings (ng/m3) during zeroc checks") %>%
  kable_styling()
```


# Low instrument readings 

## UFP - PTRAKS 

very low concentrations: Elena (MOVUP Study) excluded UPF < `r low_ufp_lvl` b/c: a) had very few samples that were less than 100 (less then 1%), b) they did not correlate to low measures on other particle measurement instruments, c) these values also resulted in extreme values on some the ratio metrics.

```{r}

# mm_full %>% 
#   filter(grepl("ptrak", variable)) %>%
#   #group_by(instrument_id) %>%
#   #rename("Instrument ID" = instrument_id) %>%
# distribution.table(., var.string = "value") %>%
#   kable(caption = "summary of 1 sec PTRAK distribution (all data)") %>%
#   kable_styling()

```

Time series plots of runs with very low instrument readings. Plots are labeled by runname (date_route) and site ID.

```{r}

low_ptrak <- mm_full %>%
  filter(grepl("ptrak", variable),
         value < low_ufp_lvl) %>%
  select(runname, site_id, instrument_id) %>% 
  unique()

```


```{r, fig.height=8}

y_max <- 5000

## Plot of entire day.
# # don't show for now?
# mm_full %>%
#   mutate(value = ifelse(grepl("bc", variable), value*bc_factor, value)) %>%
#   filter(runname %in% low_ptrak$runname) %>%
#   time_series_plots(., mytitle = paste0("time series for sites with PTRAK concentrations < ", low_ufp_lvl, " pt/cm3"),
#                     hline_value = low_ufp_lvl, 
#                     ymax = y_max) +
#   labs(subtitle = paste0("only showing concentrations up to", y_max, " pt/cm3"))

```

Zoomed in to sites with low readings.        
* 3-22-2019: low alc noted. has unstable readings most of the stop     
* 7-13-2019: low alc noted. has clear wick issues in the middle and readings seem too stable immediately before and after.  
* 1-4-2020: no notes on alc issues. has low readings at nearby stops MS0176 also has low BC readings. MS0177 has some low BC readings, but not all. readings seem too stable. Sign of wick issues?

```{r, fig.height=8}
df <- data.frame()

#only keep observations for sites with low readings 
for (i in 1:nrow(low_ptrak)) {
  one_site <- mm_full %>%
    filter(runname == low_ptrak$runname[i] &
             site_id == low_ptrak$site_id[i])
  
  df <- rbind(df, one_site)
}

df %>%
  mutate(value = ifelse(grepl("bc", variable), value*bc_factor, value)) %>% 
  label_pollutant(., var = "variable") %>%
  time_series_plots(., mytitle = paste0("time series for sites with PTRAK concentrations < ", low_ufp_lvl, " pt/cm3"),
                    hline_value = low_ufp_lvl) + 
  facet_wrap(~runname+site_id, 
             scales = "free_x") + 
  labs(col = "")

```

```{r}
# Total PTRAK readings before dropping any values
total_ptrak_readings <- mm_full %>%
  filter(grepl("ptrak", variable)) %>%
  nrow()

```

Dropping sites obsrvations with low UFP readings (< `r low_ufp_lvl` pt/cm3) that may be indicative of:
* low alcohol wick issues   
* instrument error (MOV-UP study used 100 pt/cm3; Kerckhoffs et al. 2017 MM study & Kompmaker et al. 2015 used 500 pt/cm3 & cites other studies that used this criteria)

```{r}
# drop observations for sites with low readings 
for (i in 1:nrow(low_ptrak)) {
  mm_full <- mm_full %>%
    filter(!(runname == low_ptrak$runname[i] &
             site_id == low_ptrak$site_id[i] &
             instrument_id == low_ptrak$instrument_id[i]))
}

```

PTRAK readings dropped, n (%)

```{r}
remaining_ptrak_readings <- mm_full %>%
  filter(grepl("ptrak", variable)) %>%
  nrow()

ptrak_dropped_n <- total_ptrak_readings - remaining_ptrak_readings
ptrak_dropped_pct <- round(ptrak_dropped_n/total_ptrak_readings*100, 2)

paste0(ptrak_dropped_n, " (", ptrak_dropped_pct, "%)")

```

Distribution of remaining PTRAK readings.

```{r}

mm_full %>% 
  filter(grepl("ptrak", variable)) %>%
  group_by(instrument_id) %>%
  distribution.table(., var.string = "value") %>%
  kable(caption = "summary of 1 sec PTRAK distribution after dropping low instrument readings", 
         ) %>%
  kable_styling()
 
```

## BC 

Time series plots of runs with very low instrument readings **for ONA-corrected BC readings**.

```{r}
low_bc_quant <- 0.001
low_bc_lvl <- 0 #quantile(mm_full$value[mm_full$variable== "bc_ng_m3"], low_bc_quant)[[1]]

low_bc <- mm_full %>%
  filter(grepl("ona_bc", variable),
         value <= low_bc_lvl) %>%
  select(runname, site_id, instrument_id) %>% 
  unique()

```

```{r}
# # SQL query for notes of low BC times
# low_bc_sql <- low_bc %>%
#   mutate(query = paste0("(runname = '", runname, "' AND upper(site_id) = '", site_id, "')")) %>%
#   dplyr::summarize(query = paste(query, collapse = " OR ")) %>%
#   as.character()

```

```{r, fig.height=8}
y_max <- 3000

## Plot of entire day.
# # don't show for now?
unique_low_bc_runs <- unique(low_bc$runname)  
# 
# bc_day_plots <- mm_full %>%
#   mutate(value = ifelse(grepl("bc", variable), value*bc_factor, value)) %>%
#   filter(runname %in% unique_low_bc_runs) %>%
#   time_series_plots(., mytitle = paste0("time series for runs with BC concentrations < ", low_bc_lvl, " pt/cm3"),
#                     hline_value = low_bc_lvl, 
#                     ymax = y_max, 
#                     facet_runname = F) + 
#   labs(subtitle = paste0("only showing concentrations up to ", y_max, " pt/cm3"))
# 
# 
# plot on separate pages since there are many
# need this many pages if plot 9 plots/page
page_no <- ceiling(length(unique_low_bc_runs)/plots_per_page)
# 
# for (i in seq(page_no)) {
#   
#   myplot <- bc_day_plots +
#     ggforce::facet_wrap_paginate(~runname, 
#                              nrow = 3, ncol = 3, 
#                              page = i, 
#                              scales = "free")  
#   
#   print(myplot)
# }

```

zoom in on specific sites   
* no site-specific note associated with low BC readings  

```{r, fig.height=8}
df <- data.frame()

#only keep observations for sites with low readings 
for (i in 1:nrow(low_bc)) {
  one_site <- mm_full %>%
    filter(runname == low_bc$runname[i] &
             site_id == low_bc$site_id[i])
  
  df <- rbind(df, one_site)
}

bc_site_plots <- df %>%
  mutate(value = ifelse(grepl("bc", variable), value*bc_factor, value)) %>%
  label_pollutant(.) %>%
  time_series_plots(., plot_bc_factor = bc_factor, 
                    mytitle = paste0("time series for sites with BC concentrations <= ", low_bc_lvl, " pt/cm3"),
                    hline_value = low_bc_lvl, 
                    #ymax = y_max, 
                    facet_runname = F) + 
  labs(subtitle = paste0("only showing concentrations up to ", y_max, " pt/cm3"))

# plot on separate pages since there are many
# page_no <- ceiling(length(unique_low_bc_runs)/9)

for (i in seq(page_no)) {
  #i=1  #i=3 has 9/21 plot
  
  myplot <- bc_site_plots +
    ggforce::facet_wrap_paginate(~runname + site_id, 
                             nrow = 3, ncol = 4, 
                             page = i, 
                             scales = "free")  
  
  print(myplot)
}

```

Example of a few stops with low BC readings (for dissertation example)

```{r}
bc_site_plots +
    ggforce::facet_wrap_paginate(~runname + site_id, 
                             nrow = 2, ncol = 2, 
                             page = 9, 
                             scales = "free") + 
  labs(title = "Example of a few stops with low BC readings")

```

The number of zero & negative (<= 0) 10-sec BC readings is very low for ONA-corrected values, but higher for raw values. 

```{r}
# proportion of negative BC readings
mm_full %>%
  filter(grepl("bc", variable)) %>%
  label_pollutant(.) %>%
  group_by(variable) %>%
  dplyr::summarize(
    total_readings = nrow(.),
    at_or_below_0 = sum(value<=0),
    prop_at_or_below_0 = at_or_below_0/total_readings
  ) %>% 
  kable(caption = "Readings at or below 0 ng/m3", 
        col.names = c("BC", "All Readings", "No.", "Proportion"), 
        digits = 3
        ) %>%
  kable_styling()

```

Keeping all BC values for now since some of the very low values are in series (next to each other), indicating that readings are truly low? Will averaging very low/high readings result in positive, unbiased readings in the end?


```{r}
# # Distribution of resulting BC readings 
# mm_full %>%  
#   filter(grepl("bc", variable)) %>%
#   label_pollutant(.) %>%
#   group_by(variable) %>%
# distribution.table(., var.string = "value") %>%
#   kable(caption = "Distribution of resulting 10-sec aethalometer readings") %>%
#   kable_styling()

```


# High instrument readings

**What others have done**   
*UFP*    
* dropped values above a quantile   

*BC*   
* MOVUP study: dropped BC readings > 27k ng/m3 (1% of data)   
* Kompmaker 2015: did minimal data cleaning b/c averaged 1-min readings to 30-mins   
* others have taken other approaches for dealing with noisy measurements and spike concentrations (e.g., Apte 2011 SI details dealing w/ spikes due to instrument jolts)

## High PTRAK readings 

A high concentration for PTRAKS is the limit of 500k pt/cm3. There are too many high values when using values above quantile 99.9% to manually inspect

```{r}

high_ptrak_val <-  ptrak_lim #quantile(mm_full$value[grepl("ptrak", mm_full$variable)], 0.999) # ptrak_lim # or quantile?

#bc_factor <- 10

```

Runs with PTRAK readings at or above: `r high_ptrak_val` pt/cm3

```{r}

high_ptrak <- mm_full %>%
  filter(grepl("ptrak", variable),
         #value == ptrak_lim 
         value >= high_ptrak_val
         ) %>%
  select(runname, site_id) %>% 
  unique()

#high_ptrak <- high_ptrak$runname

```
 
Plot of entire day.

```{r}
# plot of entire day
mm_full %>%
  mutate(value = ifelse(variable == "bc_ng_m3", value*bc_factor, value)) %>%
  filter(runname %in% high_ptrak$runname) %>%
  label_pollutant(var = "variable") %>%
  time_series_plots(., plot_bc_factor = bc_factor, 
                    hline_value = ptrak_lim,
                    mytitle = "time series for runs with high PTRAK concentrations") + 
  facet_wrap(~runname, scales="free")

```

Zoom in on sites of interest. In general, elevated PTRAK readings are associated with delayed elevated NanoScan and BC readings. Thus, keep these high readings?    
* 2019-06-06: construction at site noted (cutting metal pipe)
* 2019-07-23: no field notes at or near site MS0137 about any unusual TRAP sources

### --> ? is the NS time stamp at the end of the reading period? 

```{r}
df <- data.frame()

#only keep observations for sites with high readings 
for (i in 1:nrow(high_ptrak)) {
  one_site <- mm_full %>%
    filter(runname == high_ptrak$runname[i] &
             site_id == high_ptrak$site_id[i])
  
  df <- rbind(df, one_site)
}

df %>%
  mutate(value = ifelse(variable == "bc_ng_m3", value*bc_factor, value)) %>%
  label_pollutant(var = "variable") %>%
  time_series_plots(., plot_bc_factor = bc_factor, 
                    hline_value = ptrak_lim,
                    mytitle = "time series for sites with high PTRAK concentrations") + 
  facet_wrap(~runname+site_id, scales="free") 

```

## High BC readings 

High BC readings (ng/m3) are defined by a quantile because no observations reach the instrument maximum.

```{r}
bc_var <- "ma200_bc"

high_quant <- 0.99

bc_high_quant <- quantile(mm_full$value[mm_full$variable==bc_var], high_quant)

```

Runs with BC (raw or ONA-corrected)  readings above quantile (r `high_quant`): `r round(bc_high_quant)` ng/m3

```{r}
high_bc <- mm_full %>%
  filter(grepl("bc", variable),
         value >= quantile(value, high_quant)
         ) %>%
  select(runname, site_id) %>% 
  unique()

```

Plot of entire day.

Elevated BC readings are associated with elevated particle instrument readings.

```{r}
# plot of entire day
mm_full %>%
  mutate(value = ifelse(grepl("bc", variable), value*bc_factor, value)) %>%
  filter(runname %in% high_bc$runname) %>%
  time_series_plots(., plot_bc_factor = bc_factor, 
                    hline_value = ptrak_lim,
                    mytitle = "time series for runs with high BC concentrations")

```

Zoom in on sites of interest.     
* no notes associated with high BC readings   

```{r}

df <- data.frame()

#only keep observations for sites with high readings 
for (i in 1:nrow(high_bc)) {
  one_site <- mm_full %>%
    filter(runname == high_bc$runname[i] &
             site_id == high_bc$site_id[i])
  
  df <- rbind(df, one_site)
}

df %>%
  mutate(value = ifelse(variable == "bc_ng_m3", value*bc_factor, value)) %>%
  time_series_plots(., plot_bc_factor = bc_factor, 
                    hline_value = ptrak_lim, 
                    mytitle = "time series for sites with high BC concentrations") +
  facet_wrap(~runname+site_id, scales = "free")

```

# Compare collocated instruments 

## UFP

Compare collocated PTRAK readings. These will later be averaged when duplicate instruments are used. PMPT_94 has collected most of the measurements and been co-located with PMPT_93, PMPT_4 and PMPT_2. PMPT_1 and PMPT_93 collected measurements early on in the study. PMPT_93 was co-located with PMPT_94 and PMPT_4. Can't compare PMPT_1 to other PTRAKs because it was never co-located.

### PTRAK - PTRAK (field & lab collocations)

PTRAK 93 tends to have slightly lower readings than primary PTRAK 94.

```{r}
all_ptrak_colo <- mm_full %>%
  filter(grepl("ptrak", variable)) %>%
  select(time, value, location = route, instrument_id) %>%
  # add lab collocations
  rbind(lab_ptrak_collos) %>%
  spread(instrument_id, value) %>%
  drop_na()

ptrak_collo_dates <- (sort(unique(date(all_ptrak_colo$time))))

```

P-TRAKs were collocated on `r length(ptrak_collo_dates)` unique days: `r ptrak_collo_dates`

```{r}
# all data 
all_ptrak_colo %>%
  colo.plot(data.wide = .,
            x.variable = "PMPT_94",  
            y.variable = "PMPT_93", 
            mytitle = paste0("Comparison of collocated PTRAKs (pt/cm3)"), 
            col.by = "location")  
  
```

```{r}
# # PMPT_4 has slightly higher reaadings than primary PMPT_94.
# mm_full %>%
#   spread(instrument_id, value) %>%
#   colo.plot(data.wide = .,
#             x.variable = "PMPT_94",  
#             y.variable = "PMPT_4", 
#             mytitle = paste0("Comparison of collocated PTRAKs (pt/cm3)"), 
#             col.by = "route")
```

```{r}
# # PMPT_2 has slightly lower reaadings than primary PMPT_94.
# mm_full %>%
#   spread(instrument_id, value) %>%
#   colo.plot(data.wide = .,
#             x.variable = "PMPT_94",  
#             y.variable = "PMPT_2", 
#             mytitle = paste0("Comparison of collocated PTRAKs (pt/cm3)"), 
#             col.by = "route")
```

```{r}
# # PMPT_4 has slightly lower reaadings than more commonly used PMPT_93. Instruments have a better fit on Route 2 than 7?
# 
# mm_full %>%
#   spread(instrument_id, value) %>%
#   colo.plot(data.wide = .,
#             x.variable = "PMPT_93",  
#             y.variable = "PMPT_4", 
#             mytitle = paste0("Comparison of collocated PTRAKs (pt/cm3)"), 
#             col.by = "route")

```


### NanoScan - NanoScan (field collocations)

PMPSCAN_3 has slightly lower reaadings than primary PMSCAN_5.

```{r} 
ns_trim <- 0.00  # 0.01

mm_full %>%
  filter(grepl("scan", variable)) %>%
  # time stamps are sometimes a ~ 1 second off.
  mutate(time = floor_date(time, unit = "minute")) %>%
  spread(instrument_id, value) %>%
  colo.plot(
    x.variable = "PMSCAN_5", #x.label = "NanoScan ID 5",
    y.variable = "PMSCAN_3", #y.label = "NanoScan ID 3",
    mytitle = paste0("Comparison of collocated NanoScan instrument readings"), 
    col.by = "route")

```

### PTRAK - NanoScan (field collocations)

Compare NanoScan (24-422 nm) to ptrak (20-1000 nm) since NanoScan tends to be more steady. 

Assuming few particles > 420 nm, such that NanoScan and PTRAK readings are comparable.

First, calculate 30-second rolling means for PTRAKs. The last seconds of the rolling averages are dropped since they use values from the next stop rather than the next few seconds (data is only from stationary monitoring). We calculate floored times to the minute (h:mm:00) for all readings and calculate minute averages. Compare PTRAK to NanoScan readings.

Dropping PTRAK readings above 500k pt/cm3 (instrument threshold)

**note:** NanoScan 3 & 5 had poor agreement. Not sure how useful this comparison is.

**Note from Tim G:** "P-Trak clocks have a tendency to gain, reading perhaps 10 sec fast (but varies by unit) after 6 or 7 hrs or run time.  The NanoScan clock will lose time but at a rate that doesn't vary more than a few seconds in a day of operation. Since the NanoScan measurement is weighted toward the earlier part of the 1-min interval, make sure you are comparing P-Trak and NanoScan spikes for P-Trak readings in the first half of a minute, h:mm:00 to h:mm:30. The NS spike would be time stamped on the minute and corresponding P-Trak value up to 30 sec later."

```{r, eval=F}
window_duration_s <- 30

unique_times <- mm_full %>%
    filter(variable == "ptrak_pt_cm3") %>%
  select(runname, site_id, 
         instrument_id
         ) %>%
  unique()


# calculate 30-second rolling mean
ptrak_rolling0 <- mm_full %>%
  filter(variable == "ptrak_pt_cm3") %>%
  # DOESNT group properly, so have to later delete last few rolling avg estimates for each stop
  group_by(runname, site_id, instrument_id) %>%
  arrange(runname, site_id, instrument_id, time) %>%
  mutate(rolling_value = zoo::rollapply(value, FUN=mean, width=window_duration_s, align="left", fill=NA),
    #rolling_mean = zoo::rollmean(x=value, k=window_duration_s, align = "left", na.pad = T) # fill=NA
  )

# calculate 30 sec before the end of each site sampling period
ptrak_rolling_stop <- ptrak_rolling0 %>%
  group_by(runname, site_id, instrument_id) %>%
  dplyr::summarize(stop_time = max(time) - window_duration_s)

ptrak_rolling <- left_join(ptrak_rolling0, ptrak_rolling_stop) %>%
  mutate(
    #drop last seconds of rolling avg since its using values from the next stop rather than the next seconds
    rolling_value = ifelse(time > stop_time, NA, rolling_value),
    # replace
    value = rolling_value,
    variable = "ptrak_rolling"
    ) %>%
  select(-c(rolling_value,
            stop_time
         )
  ) %>%
  # add to rest of data (for plotting)
  rbind(mm_full)
 
```

```{r}
### --> use ceiling_date() instead of floor_date() to align PTRAK & NS readings?   

# use wide (takes avg of identical collocatd instruments) since not comparing specific instrument IDs, but instrument Type   
t <- mm_full %>%
  filter((grepl("ptrak", variable) & value < ptrak_lim) |
           grepl("scan", variable)) %>%
  # take avg ptrak reading at the "00" second mark for each instrument, for comparison w/ NanoScan
  mutate(time = floor_date(time, unit = "minute")) %>%  #ceiling_date()
  group_by(time, variable, route, instrument_id) %>%
  dplyr::summarize(value = mean(value)) %>%
  spread(variable, value)

# keep duplicate PTRAK & NS readings
t_ptrak <- t %>%
  select(time, route, ptrak_pt_cm3) %>%
  drop_na()

t_ns <- t %>%
  select(time, scan_20_420_pt_cm3) %>%
  drop_na()

full_join(t_ptrak, t_ns) %>%
  colo.plot(x.variable = "scan_20_420_pt_cm3", x.label = "NanoScan (24-422 nm pt/cm3)",
                      y.variable = "ptrak_pt_cm3", y.label = "PTRAK 94 (20-1000 nm pt/cm3)",
                      mytitle = paste0("Comparison of co-located 1-min avg PTRAK and NanoScan readings"), mysubtitle = paste0("dropped PTRAK readings >= ", ptrak_lim, " pt/cm3"),
            col.by = "route" 
            )

```

## Aethalometer - Aethalometer (field & lab collocations)

First, we round reading time to nearest 10-seconds since instrument time stamps may not be for the exact same 10 seconds. Then we compare collocated instrument readings. 

BC_66 (backup) may have some slightly lower readings.

```{r}
#dates w/ BC collocations
bc_collo_dates <- sort(as.Date(c("2019-07-09", "2019-06-13", "2019-09-05", "2019-03-20", "2019-09-06", "2019-12-29", "2020-03-11", "2019-03-22", "2019-09-12", "2019-11-07", "2019-12-30", "2019-05-10", "2019-08-09")))

all_bc_colo <- mm_full %>%
  filter(grepl("ma200_bc", variable),
         # only keep dates w/ collocaitons. get spreading issues otherwise from some other dates & have to round to 5/9 sec
         date(time) %in% bc_collo_dates) %>%
  select(time, value, location = route, instrument_id) %>%
  # one day (?? used to be 2020-01-07) has issues where the time stamp jumps from being 5 sec into the interval to being 4 sec into the interval. 
  mutate(time_round = round_date(time, unit = "10s")) %>%  
  # add lab collocations
  rbind(lab_bc_collos) %>%
  #drop time, otherwise merging has fewer pairs 
  select(-time) %>%
  spread(instrument_id, value) %>%
  drop_na()  

```

Aethalometers were collocated on `r length(bc_collo_dates)` unique days: `r paste(bc_collo_dates, collapse = ", ")`

Collocations are not great because aethalometer readings are very noisy. Fit is worse when the top 1% of observations are dropped (R2 = 0, RMSE = 561, slope = 0.51).

```{r}
# all data
all_bc_colo %>%
  colo.plot(x.variable = "BC_63",  
          y.variable = "BC_66",  
          mytitle = "All data - Collocated aethalometer instruments (ng/m3)", 
          col.by = "location")

# drop top 2 observations
drop_quantile <- 0.9999

all_bc_colo %>%
  filter_at(vars(contains("BC")), ~. <= quantile(., drop_quantile)) %>%
  colo.plot(x.variable = "BC_63",  
          y.variable = "BC_66",  
          mytitle = paste0("Q", drop_quantile, " - Collocated aethalometer instruments (ng/m3)"), 
          col.by = "location")

```

```{r}
# just looking at route data 
all_bc_colo %>%
  filter_at(vars(contains("BC")), ~. <= quantile(., drop_quantile)) %>%
  filter(grepl("R0", location)) %>%
  colo.plot(x.variable = "BC_63",  
          y.variable = "BC_66",
          alpha_value = 0.1,
          mytitle = paste0("Q", drop_quantile, " - Collocated aethalometer instruments (ng/m3), in field"), 
          col.by = "location")

# just lab data
all_bc_colo %>%
  filter_at(vars(contains("BC")), ~. <= quantile(., drop_quantile)) %>%
  filter(!grepl("R0", location)) %>%
  colo.plot(x.variable = "BC_63",  
          y.variable = "BC_66", 
          alpha_value = 0.01,
          mytitle = paste0("Q", drop_quantile, " - Collocated aethalometer instruments (ng/m3), inside"), 
          col.by = "location")

```


# Calibrate instrument readings to the mean 

This is done to avoid having systematic differences across instruments 

Sources of calibration to the mean of duplicate collocated instruments: Austin, 2019; Xiang 2020

Fit calibration curves.

```{r}
# PTRAK 
## calculate mean of duplicate collocated instrument readings
all_ptrak_colo <- all_ptrak_colo %>%
  group_by(time) %>%
  dplyr::summarize(mean = mean(c(PMPT_93, PMPT_94))) %>% 
  left_join(all_ptrak_colo)
## calibrate individual instrument readings to the mean
lm93 <- lm(mean~PMPT_93, data = all_ptrak_colo)
lm94 <- update(lm93, ~ PMPT_94)

# BC 
all_bc_colo <- all_bc_colo %>%
  group_by(time_round) %>%
  dplyr::summarize(mean = mean(c(BC_63, BC_66))) %>% 
  # keep original instrument readings
  left_join(all_bc_colo) %>%
  # [?? DO?] drop top observations fro aeth instruments 
  filter_at(vars(contains("BC")), ~. <= quantile(., drop_quantile))  



lm63 <- lm(mean~BC_63, data = all_bc_colo)
lm66 <- update(lm63, ~ BC_66)
# summary(lm66)

```

Plots depicting instrument vs mean reading (using all field & lab collocations).

```{r}
alpha_val <- 0.2


# PTRAKS
plot_range <- all_ptrak_colo %>%
  select(PMPT_94, PMPT_93) %>%
  dplyr::summarize(
    min = min(.),
    max = max(.))

all_ptrak_colo %>%
  gather("instrument", "value", contains("PMPT")) %>%
  ggplot(aes(y=mean, x=value)) +
  geom_point(alpha=alpha_val) +
  geom_abline(intercept = 0, slope = 1) +
  geom_smooth(method = "lm") + 
  xlim(plot_range$min, plot_range$max) +
  ylim(plot_range$min, plot_range$max) +
  facet_wrap(~instrument) +
  labs(
    title = "Mean BC concentration from collocated instruments (PMPT_93 & PMPT_94) vs PMPT_93 or PMPT_94 reading (ng/m3)"
  )

```

```{r}

plot_range <- all_bc_colo %>%
  select(BC_63, BC_66) %>%
  dplyr::summarize(
    min = min(.),
    max = max(.))

# aethalometers
all_bc_colo %>%
  gather("instrument", "value", contains("BC")) %>%
  ggplot(aes(y=mean, x=value)) +
  geom_point(alpha=alpha_val) +
  geom_abline(intercept = 0, slope = 1) +
  geom_smooth(method = "lm") + 
  xlim(plot_range$min, plot_range$max) +
  ylim(plot_range$min, plot_range$max) +
  facet_wrap(~instrument) +

  labs(
    title = "Mean BC concentration from collocated instruments (BC_66 & BC_63) vs BC_66 or BC_63 reading (ng/m3)"
  )

# plot_range <- all_bc_colo %>%
#   select(mean, BC_63) %>%
#   dplyr::summarize(
#     min = min(.),
#     max = max(.))
# 
# all_bc_colo %>%
#   ggplot(aes(y=mean, x=BC_63)) +
#   geom_point(alpha=alpha_val) +
#   geom_abline(intercept = 0, slope = 1) +
#   geom_smooth(method = "lm") + 
#   xlim(plot_range$min, plot_range$max) +
#   ylim(plot_range$min, plot_range$max) +
#   labs(
#     title = "Mean BC concentration from collocated instruments (BC_66 & BC_63) vs BC_63 reading (ng/m3)"
#   )

```


Calibrate raw P-TRAK & aethalometer readings 

ONA-corrected BC readings are not calibrated here.

Calibrating BC using quantile `r drop_quantile` of the data (drops 2 extreme observations).

```{r}
mm_full_calib <- mm_full %>% 
  filter(!grepl("ona", variable)) %>%
  # make wide format
  spread(instrument_id, value) %>%
  # replace raw readings w/ calibrated predictions
  mutate(
    PMPT_93 = predict(lm93, newdata = .),
    PMPT_94 = predict(lm94, newdata = .),
    BC_63 = predict(lm63, newdata = .),
    BC_66 = predict(lm66, newdata = .)
    ) %>%
  # make long format again
  gather("instrument_id", "value", contains(c("BC", "PMPT", "SCAN")), na.rm = T )

################
# # check that dimentions are the same. looks good.
# dim(mm_full_w)
# dim(mm_full)
# 
# mm_full_w %>%
#   group_by(instrument_id) %>%
#   dplyr::summarize(
#     n = n())
# 
# mm_full %>%
#   group_by(instrument_id) %>%
#   dplyr::summarize(
#     n = n())

```

Use calibrated readings to calculate ONA-corrected BC. 

### --> ONA correction only uses stop data 

```{r}
# merge calibrated BC readings w/ raw file w/ attenuation
# select calibrated bc values
bc_calib <- mm_full_calib %>%
  filter(grepl("ma200", variable)) %>%
  spread(variable, value) %>%
  dplyr::rename(ma200_ir_bc1 = ma200_bc)

# replace raw, uncalibrated IR values w/ calibrated values
bc.w_calib <- bc.w %>%
  select(
    #remove old ONA corrected values from raw aeth readings
    -contains("ona"),
    # drop uncalibrated IR values
    -ma200_ir_bc1) %>% 
  # add calibrated IR values
  left_join(bc_calib) %>%
  ONA() 

# only keep desired raw & ONA-corrected values
bc_calib2 <- bc.w_calib %>%
  select(site_id:date, 
        ona_bc = ona_ir,
        ma200_bc = ma200_ir_bc1) %>%
  gather("variable", "value", contains("bc")) %>%
  # BC_63 has a few missing values during a 2.5-minute period
  drop_na(value)

# Only keep desired aethalometer readings (raw & ONA corrected IR, 880 nm)
mm_full_calib2 <- mm_full_calib %>%
  #drop old BC readings
  filter(!grepl("bc", variable)) %>%
  # attach new BC readings (raw & ONA IR)
  rbind(bc_calib2) %>%
  mutate(variable = droplevels(variable))
  
```


```{r}
### --> minute & hour DOE data is only available for BC through April 2019. ? should we compare BC readings to AQS site readings (2 min & overnight). ? Select a reference instrument that is most similar? 

# note from Jill  Schulte: "1-min averages are never validated. We recommend you line up the validated 1-hour data with the corresponding minutes and remove any that donâ€™t have a valid 1-hour average"
# 
# (cite: Minet 2017 & their refs: Deville Cvaellin 2016; Lin 2015)

```

Distribution of final cleaned data

```{r}
mm_full_calib2 %>% 
  filter(grepl("ptrak|bc", variable)) %>%
  label_pollutant(var = "variable", label = "pollutant") %>%
  group_by(variable) %>%
  dplyr::rename(Pollutant = variable) %>%
distribution.table(., var.string = "value") %>%
  kable(caption = "Distribution of clean intrument readings") %>%
  kable_styling()

```


````{r}
# # # Save dataset
# mm_full_calib2 %>%
#   # don't need NanoScan data anymore
#   filter(grepl("ptrak|bc", variable)) %>%
#   mutate(variable = droplevels(variable)) %>%
#   saveRDS(., file.path("Data", "Aim 2", "Mobile Monitoring", "mm_clean_2020-03-17.rda"))

```
