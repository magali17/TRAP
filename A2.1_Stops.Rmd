---
title: 'Aim 2: Stop Readings'
author: "Magali Blanco"
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: yes
    df_print: paged
    toc: yes
    toc_depth: '3'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: console
---

```{r}
# ---> TO DO:
# ---> ? how to drop very low/high UFP & BC readings?

```

```{r, echo=F}
# notes
#BC = 880 nm (IR); 625 nm (Red); 528 nm (Green); 470 nm (Blue); and 375 nm (UV);  

```

# Summary of Script

**All data**   

* keep only BC and PTRAK readings, current MM stops (drop old stops)
* relabeled incorrectly labeled instruments
* split up data into UFP & BC datasets 

**UFP** 

* drop erroneous UFP instrument readings due to wick/other PTRAK issues
	+ < ~300 data points were dropped from 2 periods where PTRAKs appeared to have failed - concentrations were at or near zero and very different than concentrations immediately before/after
	+ these readings did not correlate well to measures from other particle measurement instruments

**BC** 

* perform ONA correction   
* estimate BC from 880 nm (IR) wavelength 

**All data** 

* compare co-located instruments to make sure readings are similar
  + PTRAK - PTRAK   
	+ NanoScan - NanoScan    
	+ PTRAK - NanoScan (< ptrak limit)   
    - used NanoScan particle counts comparable to PTRAK (subtracted counts for particles < 20 nm)   
* Decided to focus on stop medians for primary analysis b/c the distribution of 1-sec PTRAK readings were log-normal, overall & by site. 
* calculate stop medians and means
	+ Since co-located PTRAK instruments responded similar, took the average 1-sec reading when duplicate instruments were on platform before calculating stop means or medians   
	+  [?? DO SAME FOR OTHER UFP INSTRUMENTS?]   

# Analyses  

### --> keep DiscMini

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, 
                      cache=T, cache.comments = F, 
                      message = F, warning = F, 
                      tidy.opts=list(width.cutoff=60), tidy=TRUE,
                      fig.height = 5, fig.width = 8
                      )  

# Clear workspace of all objects and unload all extra (non-base) packages
# rm(list = ls(all = TRUE))
# if (!is.null(sessionInfo()$otherPkgs)) {
#   res <- suppressWarnings(
#     lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
#            detach, character.only=TRUE, unload=TRUE, force=TRUE))
# }

# load packages 
pacman::p_load(tidyverse, 
               # table
               knitr, kableExtra,
               # dates
               chron, lubridate,
               Hmisc
               )   

# source global variables & functions
source("0.Global_Fns.R")
source(file.path("A2.0.1_Var&Fns.R"))
#source(file.path("ONA smoothing_5_channels.R"))

images_path <- file.path(images_path0, "1. Stops")
tables_path <- file.path(tables_path0, "1. Stops")

#read in data
mm_full0 <- readRDS(file.path("Data", "Aim 2", "Mobile Monitoring", "all_data_2020-01-25.rda")) 

#unique(mm_full0$variable)

### --> why do these runs have missing variable/value? 2019-05-14_R03, 2019-07-17_R07	

site_ids <- read.csv(file.path("Data", "Aim 2", "Mobile Monitoring", "locations_190715.csv")) %>%
  select(site_id) %>%
  #drop Roosevelt garage stop; drop site w/ only 1 observation - stopped sampling here & added MS0601
  filter(!site_id %in% c("MS0000", "MS0398")) %>%
  unique()

mm_full <- mm_full0 %>%
  # --> why do 2 runs have missing values??
  select(-duration_sec) %>%
  drop_na(value) %>%
  filter(!variable %in% c("ufp_disc_ct_cm3",
                         "ufp_disc_med_size_nm", 
                         "ufp_pt_screen_ct_cm3",
                         "ufp_scan_20_5_ct_cm3")) %>%
  mutate(variable = recode_factor(factor(variable),  
                              "ufp_pt_noscreen_ct_cm3" = "ptrak_pt_cm3")) %>%
  # not sure why there are repeated identical rows for ufp_scan_11_5_ct_cm3
  unique()

#unique(mm_full$variable)

#drop old stops 
mm_full <- left_join(site_ids, mm_full)

#relabel instruments that were incorrectly labeled
mm_full <- mm_full %>%
  mutate(instrument_id = ifelse(instrument_id == "BC_0063", "BC_63",
                                #ifelse(instrument_id == "CO_2", "CO_3",
                                       ifelse(instrument_id == "PMSCAN_1", "PMSCAN_3",
                                              instrument_id))
         )

#Create NanoScan counts (20-420 nm) similar to ptraks: 20-1000 nm)
ns <- mm_full %>%
  #look at variables from NanoScan
  filter(grepl("scan", variable)) %>%
  #not sure why there are repeated identical rows for ufp_scan_11_5_ct_cm3
  unique() %>%
  #make wide format to calculate the difference
  spread(variable, value) %>%
  mutate(scan_20_420_pt_cm3 = ufp_scan_ct_cm3 - ufp_scan_11_5_ct_cm3 - ufp_scan_15_4_ct_cm3) %>%
  select(-c(ufp_scan_11_5_ct_cm3, ufp_scan_15_4_ct_cm3,
            ufp_scan_ct_cm3)) %>%
  #dplyr::rename(scan_10_420_pt_cm3 = ufp_scan_ct_cm3) #%>%
  #make back to long format
  gather("variable", "value", scan_20_420_pt_cm3)

# replace old nanoscan calculations w/ new ones similar to PTRAK
mm_full <- mm_full %>%
  filter(!grepl("scan", variable)) %>%
  rbind(ns) %>%
  arrange(time)  
  
#separate UFP and BC readings since doing different analyses on these

# UFP instruments
ufp <- mm_full %>%
  filter(grepl("ptrak|scan", variable))

# BC aethelometer
bc <- mm_full %>%
  filter(grepl("ma200", variable)) 

```

Instruments Used

```{r}
#instrument used each day
mm_full %>%
  select(instrument_id, date) %>%
  unique() %>%
  ggplot(aes(x=date, y=instrument_id, colour = instrument_id)) + 
  geom_point(alpha=0.5) + 
  theme(legend.position = "none") + 
  labs(title = "Instruments used",
       x = "Date",
       y = "Instrument ID"
       ) 
 
```

# Drop erroneous, low instrument readings 

## UFP - PTRAKS 

very low concentrations: Elena (MOVUP Study) excluded UPF < 100 b/c: a) had very few samples that were less than 100 (less then 1%), b) they did not correlate to low measures on other particle measurement instruments, c) these values also resulted in extreme values on some the ratio metrics.

PMPT_93 and PMPT_94 have both had 0 readings. PMPT_94 has had a maximum reading of 500k pt/cm3. 

```{r}
ptrak_lim <- 5e5 

ufp %>% filter(grepl("ptrak", variable)) %>%
  group_by(instrument_id) %>%
  #rename("Instrument ID" = instrument_id) %>%
distribution.table(., var.string = "value") %>%
  kable(caption = "summary of 1 sec PTRAK distribution (all data)") %>%
  kable_styling()

```

Time series plots of runs with very low instrument readings.

```{r}
ns <- ufp %>%
  filter(grepl("scan", variable)) %>%
  select(#-variable,
    time_crude = time,
    scan_20_420_pt_cm3 = value
                # labeled same as ptrak.w df
                
         
         ) #%>%
  # dplyr::rename(scan_20_420_pt_cm3 = value,
  #               # labeled same as ptrak.w df
  #               time_crude = time
  #               ) %>%
  # select(-instrument_id) 
   
  
low.ptrak.conc <- 2000
very.low.ptrak.conc <- 100

#take avg when duplicate instruments on car # don't do b/c avgs bad readings so they end up looking OK
  # group_by(site_id, runname, route, aqs_id, aqs_location, site_long, site_lat, time) %>%
  # dplyr::summarize(scan_20_420_pt_cm3 = mean(scan_20_420_pt_cm3))
  
ptrak <- ufp %>%
  filter(grepl("ptrak", variable)) %>%
  select(-variable) %>%
  dplyr::rename(ptrak_pt_cm3 = value) # %>% select(-instrument_id)  

#plot showing when low Concs are seen & by what instruments. 
# Low Conc:
## PMPT_93 has issue on  3/22
## PMPT_94 has issue on  7/13.
# High Conc:
## PMPT_94: 2019-06-06, 2019-07-23

# runnames with very high/low concentrations
low_runs <- ptrak %>%
  filter(ptrak_pt_cm3 < very.low.ptrak.conc)  %>% 
  select(runname) %>%
  unique()
low_runs <- low_runs$runname  

# high_runs <- ptrak %>%
#   filter(ptrak_pt_cm3 > ptrak_lim*.9)  %>% 
#   select(runname) %>%
#   unique()
# high_runs <- high_runs$runname  


ptrak %>%
  filter(runname %in% c(low_runs)) %>%
  #gather("variable", "value", ptrak_pt_cm3, scan_20_420_pt_cm3) %>%
  ggplot(aes(x=time, y = ptrak_pt_cm3)) +
  geom_point(aes(col=instrument_id)) +
  geom_hline(yintercept = very.low.ptrak.conc) +
  facet_wrap(~runname, scales = "free") +
  labs(title = paste0("Time series plot to identify low PTRAK concentration times"),
  y = "PTRAK (pt/cm3)"
  )

# average 1-sec PTRAK readings to 1-min so comparable to NS readings
# ufp.w_crude <- ptrak %>% 
#   mutate(time_crude = floor_date(time, unit = "minute")) %>%
#   group_by(runname,time_crude) %>%
#   dplyr::summarize(ptrak_pt_cm3 = mean(ptrak_pt_cm3)) %>%
#   left_join(ns) 

ufp.w <- ns %>%
  dplyr::rename(time = time_crude) %>%
  full_join(ptrak) 
 

# [keep this code chunk for upating in future]
# #plot to ID when low PTRAKs readings occurred
# ufp.w %>%
#   filter(ptrak_pt_cm3 < very.low.ptrak.conc) %>%
#   gather("variable", "value", ptrak_pt_cm3, scan_20_420_pt_cm3) %>%
#   ggplot(aes(x=time, y = value, col = variable)) + 
#   geom_point() + 
#   facet_wrap(~runname, scales = "free") + 
#   labs(title = paste0("Time series plot to identify low PTRAK concentration times"),
#   subtitle = paste0("only showing PTRAK conc <",
#                       very.low.ptrak.conc,
#                       " ufp/cm3)"))

```

Dropping the very low readings b/c patterns are characteristic of PTRAK wick issues.

```{r}
# veyr low concentrations
low_date1 <- substr(low_runs[1], 1, 10)
low_run1 <- low_runs[1]
low_date2 <- substr(low_runs[2], 1, 10)
low_run2 <- low_runs[2]

#duplicate instruments used in some cases
low_run1.instruments <- unique(ufp[ufp$runname == low_run1, "instrument_id"])
low_run2.instruments <- unique(ufp[ufp$runname == low_run2, "instrument_id"])

```

```{r}
# NOTE: do not use shape = instrument_id. instrument_id is only for PTRAK b/c of how files were merged.
ufp.w %>%
  filter(runname == low_run1,
         time > paste0(low_date1, " 17:13:30"),
         time < paste0(low_date1, " 17:15")
         ) %>%
  gather("variable", "value", ptrak_pt_cm3, scan_20_420_pt_cm3) %>%
  mutate(variable = recode(variable, 
                       "ptrak_pt_cm3" = "PTRAK_20_1000_nm_pt", 
                      "scan_20_420_pt_cm3" = "NanoScan_20_420_pt")
         ) %>%
  ggplot(aes(x=time, y = value, col = variable)) + 
  geom_point(alpha=0.7, aes()) +
  labs(title = paste0("Time series of very low PTRAK concentrations \n(< ", very.low.ptrak.conc, " ufp/cm3) were observed"),
       subtitle = paste0(low_run1, ", instruments used: ", paste0(low_run1.instruments, collapse = ", ")),
       y = "Concentration (pt/cm3)",
       colour = "Instrument",
       linetype = ""
       )

```

```{r}
ufp.w %>%
  filter(runname == low_run2,
         time > paste0(low_date2, " 05:38:30"),
         time < paste0(low_date2, " 05:41:40")
         ) %>%
  gather("variable", "value", ptrak_pt_cm3, scan_20_420_pt_cm3) %>%
  mutate(variable = recode(variable, 
                       "ptrak_pt_cm3" = "PTRAK_20_1000_nm_pt", 
                      "scan_20_420_pt_cm3" = "NanoScan_20_420_pt")
         ) %>%
  ggplot(aes(x=time, y = value, col = variable)) + 
  geom_point(alpha=0.7, aes()) +
    #geom_hline(aes(yintercept = very.low.ptrak.conc, linetype = "100 pt/cm3"), col = "red") +
  labs(title = paste0("Time series of very low PTRAK concentrations \n(< ", 
                      very.low.ptrak.conc, " pt/cm3) were observed"),
       subtitle = paste0(low_run2, ", instruments used: ", paste0(low_run2.instruments, collapse = ", ")),
       colour = "Instrument"
       )

```


Total PTRAK readings before dropping any values: 

```{r}

total_ptrak_readings <- ufp.w %>%
  #filter(instrument_id %in% c("PMPT_93", "PMPT_94")) %>%
  nrow()

total_ptrak_readings

```

Dropping low UFP readings:   
* from low alcohol wick issues   
* those that are < 100 pt/cm3 since these are indicative of an instrument error (MOV-UP study also used 100 pt/cm3; Kerckhoffs et al. 2017 MM study & Kompmaker et al. 2015 used 500 pt/cm3 & cites other studies that used this criteria)

```{r}
#PMPT_93
bad.times1 <- seq(ymd_hms(paste0(low_date1, " 17:13:30")),
                  ymd_hms(paste0(low_date1, " 17:15:00")),
                  by = 1)  
tz(bad.times1) <- "PST8PDT" #  Sys.timezone()

#PMPT_94
bad.times2 <- seq(ymd_hms(paste0(low_date2, " 05:38:30")),
                  ymd_hms(paste0(low_date2, " 05:41:40")),
                  by = 1)  
tz(bad.times2) <- "PST8PDT"

# drop bad readings from appropriate instrument
ufp <- ufp %>%
  filter(!(time %in% bad.times1 & instrument_id == "PMPT_93"),
         !(time %in% bad.times2 & instrument_id == "PMPT_94"),
         
          #drop UFP < 100  
         !(grepl("ptrak", variable) &  value < 100)
         ) 
  # check that it looks good
  # %>% filter(time %in% c(bad.times1, bad.times2))


ufp.w <- ufp.w %>%
  filter(!(time %in% bad.times1 & instrument_id == "PMPT_93"),
         !(time %in% bad.times2 & instrument_id == "PMPT_94"),
        # drop UFP < 100  
        ptrak_pt_cm3 > 100
         ) 

```

number of 1-sec PTRAK readings dropped:

```{r}

num.ptrak.seconds.dropped <- length(bad.times1) + length(bad.times2)

pct_ptrak_sec_dropped <- round(num.ptrak.seconds.dropped/total_ptrak_readings*100, 2) 

paste0(num.ptrak.seconds.dropped, " (", pct_ptrak_sec_dropped, "%)")

```

```{r}

ufp %>% filter(grepl("ptrak", variable)) %>%
  group_by(instrument_id) %>%
distribution.table(., var.string = "value") %>%
  kable(caption = "summary of 1 sec PTRAK distribution after dropping poor instrument readings", 
         ) %>%
  kable_styling()
 
```

Final 1-second PTRAK readings. They are right skewed.

```{r}
ufp %>%
  filter(grepl("ptrak", variable)) %>%
  ggplot(aes(x=value)) + 
  geom_histogram() + 
  labs(title = paste0("PTRAK concentrations after dropping erroneous readings \ndue to alcohol wick isues"),
       #subtitle = "on log x scale",
       x = "Concentration (pt/cm3)"
       ) #+ scale_x_log10()

```
 
## BC 

```{r}
max_bc_limit <- 1e6 #ng/m3

```

Distribution of raw BC readings. See that both instruments have negative BC readings.  

```{r}

bc %>% filter(grepl("ir_bc", variable)) %>%
  group_by(instrument_id) %>%
distribution.table(., var.string = "value") %>%
  kable(caption = "Distribution of raw 10-sec Aethelometer readings") %>%
  kable_styling()

```

### Use the Optimized Noise-Reduction Algorithm (ONA) correction

```{r}
# this does not need to be done separatebly by instrument, results are the same. May be related to different tape positions for differnet instruments, which is already taken into account?
bc.w <- bc %>%
  spread(variable, value) %>%
  ONA() 

#BC/IR
bc.w %>%
  ggplot(aes(x= ma200_ir_bc1, y = ona_ir)) + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) + 
  geom_smooth() + 
  labs(title = "IR (880 nm, black carbon) concentrations before and after ONA correction",
      x = "Aethelometer (ng/m3)",
      y = "ONA-corrected (ng/m3)"
       )

bc <- bc.w %>%
  #only keep ONA-corrected values
  select(site_id:instrument_id, 
        bc_ng_m3 = ona_ir) %>%
  gather("variable", "value", contains("bc")) %>%
  # BC_63 has a few missing values during a 2.5-minute period
  drop_na(value)
  
```

Distribution of ONA-corrected BC readings. Still see some negative values, but there are fewer and they are not as negative. The highest values are a bit lower than the raw values.

```{r}

bc %>% #filter(grepl("ona_ir", variable)) %>%
  group_by(instrument_id) %>%
distribution.table(., var.string = "value") %>%
  kable(caption = "Distribution of ONA-corrected 10-sec Aethalometer readings") %>%
  kable_styling()

```

```{r}
bc %>%
  ggplot(aes(x=value)) + 
  geom_histogram() + 
  #scale_x_log10() +
  labs(title = "Distribution of ONA-corrected 10-sec Aethelometer IR (BC) readings", 
       #subtitle = "log x scale",
       x= "BC (ng/m3)"
         )

```

### (?) Adjust very low readings

### --> [will email Elena] ?? Drop or keep values < 0 or < threshold (or set to ~ 0/min) since so few and don't know wha cutoff to use for high values? 


The number of negative (<0) 10-sec BC readings is very low. 

```{r}
# proportion of negative BC readings
negative_bc_no <- sum(bc$value <0) 
negative_bc_pct <- round(negative_bc_no/length(bc$value)*100, 2)

paste0(negative_bc_no, " (", negative_bc_pct, "%)")

```

**Not doing anything for now since some of the very low values are in series (next to each other), indicating that readings are truly low?? Will averaging very low/high readings result in positive, unbiased readings in the end?**

```{r}
# [??] Set values < 0 equal to ___ the minimum positive BC reading divided by sqrt(2) ___
# 556 notes suggest: LOD/sqrt(2), but manual does not have a LOD for a 10-sec aethalometer reading.

# min_positive_bc <- min(bc$value[bc$value>0])
# min_positive_bc/sqrt(2)

# bc <- bc %>%
#   #filter(value >0)
#   mutate(
#     value = ifelse(value < min_positive_bc, min_positive_bc/sqrt(2), value)
#   )

```


```{r}
# # Time series of high readings
# 
# high_bc_runs <- bc %>%
#   # find when high BC readings are taken
#   filter(value > quantile(value, 0.999)) %>%
#   group_by(runname) %>%
#   # count the no. of high readings/run
#   dplyr::summarize(high_readings_n = n()) %>%
#   arrange(desc(high_readings_n))

```


```{r}
# # see several very high readings on some days 
#  
# # can change high_bc_runs$runname # to see other days w/ high readings
# bc %>%
#   filter(runname %in% high_bc_runs$runname[1]) %>%
#   ggplot(aes(x=time, y=value)) + 
#   geom_point(aes(col=site_id), alpha=0.2) 

```


```{r}
# # other days have only a few high readings 
# 
# ## see just a few high readings
# bc %>%
#   filter(runname %in% high_bc_runs$runname[25]) %>%
#   ggplot(aes(x=time, y=value)) + 
#   geom_point(aes(col=site_id), alpha=0.2) 

```

Distribution of resulting BC readings 

```{r}
bc %>%  
  group_by(instrument_id) %>%
distribution.table(., var.string = "value") %>%
  kable(caption = "Distribution of final 10-sec Aethalometer readings") %>%
  kable_styling()

```


Distribution of BC readings are __ log-normal __

```{r}


```

# Combine clean datasets. 

```{r}
mm_full <- rbind(ufp, bc) %>%
  arrange(time) %>%
  dplyr::group_by(runname, site_id) %>%   
  #set time to arrival time 
  dplyr::mutate(arrival_time = min(time)) %>%
  mutate(date = as.Date(substr(arrival_time, 1,10))) %>%
  ungroup()

```

# Compare instruments during high concentration times

*BC: What others have done*   
* MOVUP study: dropped BC readings > 27k ng/m3 (1% of data)   
* Kompmaker 2015: did minimal data cleaning b/c averaged 1-min readings to 30-mins   
* others have taken other approaches for dealing with noisy measurements and spike concentrations (e.g., apte 2011 SI details dealing w/ spikes due to instrument jolts)

### --> is there a way to detect BC spikes/high concentrations due to instrument jolts that are erroneous (e.g., like Apte 2011, but simpler?)? 


### --> ? take 1 min rolling avg for PTRAK & plot time series? Can see when concentrations diverge
### --> ? also see high BC concentrations at high concentrations? 
### --> see field notes for high/low times
### --> plot where have divergent estimates. e.g. very high NS readings. near airport? is this where discMini has high readings? 












# Compare co-located duplicate instruments 

## UFP

Compare collocated PTRAK readings. These will later be averaged when duplicate instruments are used. PMPT_94 has collected most of the measurements and been co-located with PMPT_93, PMPT_4 and PMPT_2. PMPT_1 and PMPT_93 collected measurements early on in the study. PMPT_93 was co-located with PMPT_94 and PMPT_4. __??__ can't compare PMPT_1 to other PTRAKs because it was never co-located.

PTRAK 93 tends to have higher readings than primary PTRAK 94.

### --> ? error w/ PMPT_94 not existing??

```{r}
# don't need to compare: PMPT 4 - has never been used on its own. PMPT1 - has never been collocated (only used at begining of study)

mm_full %>%
    filter(instrument_id %in% c("PMPT_93", "PMPT_4")) %>%
  spread(instrument_id, value) %>%
  drop_na("PMPT_93", "PMPT_4") %>%
  colo.plot(data.wide = ., 
                      y.variable = "PMPT_93", y.label = "PTRAK ID 93",
                      x.variable = "PMPT_4",  x.label = "PTRAK ID 4",
                      mytitle = paste0("Comparison of collocated PTRAK instrument readings \n 1-sec data"),
            r2.digits = 2,
            coef_digits = 2
            )

```

### --> compare PMPT_94 vs PMPT_4

```{r}

```

### --> compare PMPT_94 vs PMPT_2

```{r}

```

### --> compare PMPT_93 vs PMPT_4

```{r}

```


### --> compare PTRAK to discMini

```{r}

```


Compare NanoScan instruments. Look similar, thus OK to take avg?

```{r} 
ns_trim <- 0.00  # 0.01

mm_full %>%  
    #select only values from desired instruments
    filter(instrument_id %in% c("PMSCAN_5", "PMSCAN_3")
           ) %>%
    spread(instrument_id, value) %>%
  colo.plot(
    x.variable = "PMSCAN_5", x.label = "NanoScan ID 5",
    y.variable = "PMSCAN_3", y.label = "NanoScan ID 3",
          mytitle = paste0("Comparison of collocated NanoScan instrument readings" #, 
                                        #"\ndropped top and bottom ", (ns_trim)*100, "% of data"
                           ),
                      coef_digits = 2
          )

```

Compare NanoScan (20-420 nm +) to ptrak (20- 1000 nm) since NanoScan tends to be more steady. Assuming few particles > 420 nm, such that the NanoScan and PTRAK are comparable.

Dropping very low nanoscan readings and those above 500k pt/cm3 (PTRAK instrument threshold)

### --> use diff NS bins? drop lowest bin 

```{r}
# use wide (takes avg of identical collocatd instruments) since not comparing specific instrument IDs, but instrument Type   
mm_full %>%
  filter(grepl("scan|ptrak", variable),
         value < ptrak_lim
         ) %>%
  # take avg ptrak reading at the "00" second mark for comparison w/ NanoScan
  mutate(time_crude = floor_date(time, unit = "minute")) %>%
  group_by(time_crude, variable) %>%
  dplyr::summarize(value = mean(value)) %>%
  spread(variable, value) %>%
  drop_na(ptrak_pt_cm3, scan_20_420_pt_cm3) %>%
  colo.plot(x.variable = "scan_20_420_pt_cm3", x.label = "NanoScan 5 (20-420 nm pt/cm3)",
                      y.variable = "ptrak_pt_cm3", y.label = "PTRAK 94 (20-1000 nm pt/cm3)",
                      mytitle = paste0("Comparison of co-located 1-min avg PTRAK and NanoScan readings", 
                                        "\n dropped NanoScan readings > PTRAK limit: ", ptrak_lim, " pt/cm3"
                                       ),
            r2.digits = 2,             
            coef_digits = 2
            )


```

 
## BC

##  Compare co-located Aethelometer instruments

First, round reading time to nearest 10-seconds since instrument time stamps may not be for the exact same 10 seconds.

```{r}
 mm_full %>%
  filter(grepl("bc", variable)) %>%
  # 2020-01-07 has issues where the time stamp jumps from being 5 sec into the interval to being 4 sec into the interval. creates merging issues where some points are dropped. round to nearest 5-sec to adjust for this.
  mutate(time_round = round_date(time, unit = "5s")) %>%
  select(runname, time_round, instrument_id, value) %>%
   spread(instrument_id, value) %>%
  colo.plot(x.variable = "BC_63", x.label = "BC_63 ng/m3",
          y.variable = "BC_66", y.label = "BC_66 ng/m3",
          coef_digits = 2, 
          mytitle = "Co-located aethalometer readings", 
          col.by = "runname" 
          )
 
```

## --> ? compare BC readings to AQS site readings (2 min & overnight). select a reference instrument that is most similar?

(cite: Minet 2017 & their refs: Deville Cvaellin 2016; Lin 2015)

```{r}

```


# Calculate Stop medians and means    

Distribution of 1-second PTRAK readings is log-normal, overall and by site.

```{r}

mm_full %>%
  filter(grepl("ptrak", variable)) %>%  
  #filter(variable %in% c("ptrak_ct_cm3")) %>%
  ggplot(aes(x=value)) +
  geom_density(alpha=0.1) + 
  labs(title = "1-second PTRAK readings",
       subtitle = "on log x scale",
       x = "Concentration (pt/cm3)"
       ) +
    scale_x_log10() +
  theme(legend.position = "none")

mm_full %>%
  filter(grepl("ptrak", variable)) %>%  
  ggplot(aes(y=value, x=site_id, group=site_id)) +
  geom_boxplot(alpha=0.05) + 
  scale_y_log10() + 
  labs(title = "1-second PTRAK readings",
       y = "Concentration (pt/cm3)",
       x = "site"
       ) 

```

Since PTRAK instruments respond similar, take the average 1-sec reading when duplicate instruments are on platform before calculating stop means or medians.

```{r}
 
mm <- mm_full %>%
  select(-time, instrument_id) %>%
  #drop tape position
  filter(!grepl("tape_posit", variable)) %>%
  dplyr::group_by(date, runname, route, site_id, aqs_id, aqs_location, site_long, site_lat, arrival_time, variable) %>% 
  dplyr::summarize(median_value = median(value, na.rm = T),
            mean_value = mean(value, na.rm = T)) %>%
  ungroup() %>%
  arrange(arrival_time) %>%
  #add temporal variables
  add.temporal.variables(data = ., date.var = "arrival_time")

# #give each site unique number ID, based on time when stop was first sampled
site_no <- mm %>%
  select(site_id) %>% unique() %>%
  dplyr::mutate(site_no = seq(1:length(site_id)))

# #number of times each site has been visited
# site_visit_no <- mm %>%
#   select(site_id, runname) %>%
#   group_by(site_id) %>%
#   #only 1 observation row
#   unique() %>%
#   dplyr::mutate(site_visit_no = seq(1:n()))

mm <- left_join(mm, site_no) 
  #left_join(site_visit_no) %>%
 

```

Make wide format.

```{r}
mm.w.median <- mm %>%
  select(-mean_value) %>%
  spread(variable, median_value) %>%  #
  rename_at(vars(contains("ptrak"), contains("ona"), contains("scan")), ~(paste0(., "_median"))) 

mm.w.mean <- mm %>%
  select(-median_value) %>%
  spread(variable, mean_value) %>%  #
  rename_at(vars(contains("ptrak"), contains("ona"), contains("scan")), ~(paste0(., "_mean"))) 

mm.w <- full_join(mm.w.median, mm.w.mean)
 
```

Will focus on medians vs means b/c:
* more robust to outliers during short-two minute stops
* data are right skewed 

```{r}
## Mean is only ~3% higher? 
print("Average mean/median ratio")
mean(mm$mean_value[mm$variable=="ptrak_pt_cm3"])/mean(mm$median_value[mm$variable=="ptrak_pt_cm3"])

```

```{r}
#compare mean vs median. if no different, use one 
mm %>%
  filter(variable == "ptrak_pt_cm3") %>%
  gather("method", "value", median_value, mean_value) %>%
  mutate(method = ifelse(method == "median_value", "median", "mean")) %>%
  ggplot(aes(x=value, fill=method)) + 
  geom_density(alpha=0.3) + 
  scale_x_log10() + 
  labs(
    title = "Mean vs median stop readings from 1-sec data",
    subtitle = "log x scale",
    x = "Concentration (pt/cm3)"
    )

#colocation plot
mm %>%
  filter(grepl("ptrak", variable)) %>%
colo.plot(
  x.variable = "median_value", x.label = "median value",
  y.variable = "mean_value", y.label = "mean value",
  #col.by = "season", 
  mytitle = "Comparing diferent central tendency metrics\nfor stop concentrations", 
  coef_digits = 2
  )

mm %>%
  filter(variable == "ptrak_pt_cm3") %>%
  dplyr::rename(mean = mean_value,
         median = median_value
         ) %>%
  gather("Method", "value", median, mean) %>%
  group_by(Method) %>%
  distribution.table(var.string = "value") %>%
  kable(caption = "Distribution of stop means and medians. N = number of stop visits (308 sites x ~30 stop visits/site)") %>%
  kable_styling()

```

Empiric fractions of overall mean and median relative to 1-sec data. Computing the percentile of the overall mean and median UFP concentration value relative to all values

```{r}
#overall
## Empiric fraction:
ufp.values <- mm_full$value[mm_full$variable == "ptrak_pt_cm3"]

### mean
empir_frac_mean <- round(sum(ufp.values < mean(ufp.values)) / length(ufp.values), 2)
### median
empir_frac_median <- round(sum(ufp.values < median(ufp.values)) / length(ufp.values), 2)

## Parametric fraction:
### median
### log transform values since right skewed
# round(pnorm((median(log(ufp.values)) - mean(log(ufp.values)))/sd(log(ufp.values))), 2)

```

empiric fraction of overall mean: `r empir_frac_mean`

empiric fraction of overall median: `r empir_frac_median`


 



Save datasets.

````{r}
# saveRDS(mm.w, file.path("Data", "Aim 2", "Mobile Monitoring", "mm.w_2020-01-25.rda"))


# DELETE?
# saveRDS(mm, file.path("Data", "Aim 2", "Mobile Monitoring", "mm_2020-01-25.rda"))
# saveRDS(mm_full, file.path("Data", "Aim 2", "Mobile Monitoring", "mm_full_2020-01-25.rda"))

```
