---
title: 'Aim 2: Annual Averages'
author: "Magali Blanco"
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: yes
    df_print: paged
    toc: yes
    toc_depth: '3'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: console
---

```{r}
# to do:

```

```{r, echo=FALSE}
#notes
# refs:
## Sampson 2013 National UK Model using PLS for PM2.5

# # get location of package
# find.package("VCA")
# # deleted VCA folder
# # reinstall package
# install.packages("VCA")
# # see what libraries this package depends on
# packageDescription("VCA")  # Imports = stats, graphics, grDevices, lme4, Matrix, methods, numDeriv
# # load packge 
# pacman::p_load(VCA) 
# # check that imports are all also loaded. # ?didn't have lme4?

# some functions used:
# Himsc: describe(); EnvStats: summaryFull(); ggpubr: ggarrange(); qwraps2::mean_sd, median_iqr

```

# Summary Script

* categorized hours into times of day (2, 3, 5 times of day)
* trim 5% top/bottom observations per site
* prepare data for sensitivity analyses 
* plot UFP & BC concentrations at various times (e.g., hour, TOD, TOW, season)
* calculate stop sample sizes for different times
* calculate annual averages using various methods and weights
	+ site specific
		- unweighted, weighted by: season, TOW, TOD
	+ regression (borrowing info across sites)
		- unweighted, weighted by: season, TOW, various TODs
* compare annual averages from primary and sensitivity analysis 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, 
                      cache=T, cache.comments = F, 
                      message = F, warning = F, 
                      tidy.opts=list(width.cutoff=60), tidy=TRUE,
                      fig.height = 6, fig.width = 11
                      )  

# # Clear workspace of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
  res <- suppressWarnings(
    lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
      detach, character.only=TRUE, unload=TRUE, force=TRUE))
}

pacman::p_load(
  #plots & tables
  tidyverse, ggpubr, ggmap, #dplyr, 
  knitr, kableExtra, 
  # descriptive satistics
  Hmisc, EnvStats, #qwraps2,  
  # dates
  lubridate, 
  # modeling: lasso, ANOVA for mixed models
  glmnet, 
  VCA  
  )    

options(knitr.kable.NA = '')
set.seed(1)
source("0.Global_Fns.R")
source("A2.0.1_Var&Fns.R")

#load data
stops0 <- readRDS(file.path("Data", "Aim 2", "Mobile Monitoring", "mm_stops_2020-03-08.rda")) 

site_locations <- readRDS(file.path("Data", "Aim 2", "Geocovariates", "cov_mm_log_scale_preprocessed.rda")) %>% 
  select(site_id, latitude, longitude)

stops <- stops0 %>%
  rename(
    ptrak_median_all_data = ptrak_pt_cm3_median,
    ptrak_mean_all_data = ptrak_pt_cm3_mean,
    bc_median_all_data = bc_ng_m3_median,
    bc_mean_all_data = bc_ng_m3_mean
  ) %>%
  group_by(site_id) %>%
  # deal with extreme observations for each site 
  mutate(
    # UFP
    ## primary analysis using medians & trimming 5%
    ptrak_median_trim5 = ifelse(ptrak_median_all_data >= quantile(ptrak_median_all_data, 0.05, na.rm = T) &
                                ptrak_median_all_data <= quantile(ptrak_median_all_data, 0.95, na.rm = T), ptrak_median_all_data, NA),
    ## sensitivity analyses 
    ### stop means
    ptrak_mean_trim5 = ifelse(ptrak_mean_all_data >= quantile(ptrak_mean_all_data, 0.05, na.rm = T) &
                                ptrak_mean_all_data <= quantile(ptrak_mean_all_data, 0.95, na.rm = T), ptrak_mean_all_data, NA),
    ### trim 10%
    ptrak_median_trim10 = ifelse(ptrak_median_all_data >= quantile(ptrak_median_all_data, 0.10, na.rm = T) &
                                ptrak_median_all_data <= quantile(ptrak_median_all_data, 0.90, na.rm = T), ptrak_median_all_data, NA),
    ### windosrize
    ptrak_median_windsorize = ifelse(ptrak_median_all_data > quantile(ptrak_median_all_data, 0.95, na.rm=T), quantile(ptrak_median_all_data, 0.95, na.rm = T),
                                     ifelse(ptrak_median_all_data < quantile(ptrak_median_all_data, 0.05, na.rm=T), quantile(ptrak_median_all_data, 0.05, na.rm = T), ptrak_median_all_data)),
    
    # BC
    ## primary analysis using medians & trimming 5%
    bc_median_trim5 = ifelse(bc_median_all_data >= quantile(bc_median_all_data, 0.05, na.rm = T) &
                                bc_median_all_data <= quantile(bc_median_all_data, 0.95, na.rm = T), bc_median_all_data, NA),
    ## sensitivity analyses 
    ### stop means
    bc_mean_trim5 = ifelse(bc_mean_all_data >= quantile(bc_mean_all_data, 0.05, na.rm = T) &
                                bc_mean_all_data <= quantile(bc_mean_all_data, 0.95, na.rm = T), bc_mean_all_data, NA),
    ### trim 10%
    bc_median_trim10 = ifelse(bc_median_all_data >= quantile(bc_median_all_data, 0.10, na.rm = T) &
                                bc_median_all_data <= quantile(bc_median_all_data, 0.90, na.rm = T), bc_median_all_data, NA),
    ### windosrize
    bc_median_windsorize = ifelse(bc_median_all_data > quantile(bc_median_all_data, 0.95, na.rm=T), quantile(bc_median_all_data, 0.95, na.rm = T),
                                     ifelse(bc_median_all_data < quantile(bc_median_all_data, 0.05, na.rm=T), quantile(bc_median_all_data, 0.05, na.rm = T), bc_median_all_data))
    ) %>%
  ungroup() %>%
  mutate(
    site_id = factor(site_id),  
    # add other temporal variables & geocovariates
    tod5 = factor(ifelse(hour %in% seq(3,8), "3_8",
                                       ifelse(hour %in% seq(9,11), "9_11", 
                                              ifelse(hour %in% seq(12,15), "12_15",
                                                     ifelse(hour %in% seq(16,20), "16_20", "21_2")))),
                         levels= c("3_8", "9_11", "12_15", "16_20", "21_2")),
    tod3 = factor(ifelse(hour %in% seq(0,8), "0_8",
                                       ifelse(hour %in% seq(9,17), "9_17", "18_23")),
                         levels= c("0_8", "9_17", "18_23")),
    #selected this break b/c: 1) UFP values rise during warmer daytime hours; 2) mixing ht is higher during day; 3) "daytime" = typical business as usual mm campaigns
    tod2 = factor(ifelse(hour %in% seq(9, 17), "9_17", "18_08"), 
                         levels= c("9_17", "18_08")),
    stop_type = ifelse(grepl("MC", site_id), "AQS", "ACT"))  

n.months.sampled <- length(unique(stops$month))
n.seasons.sampled <- length(unique(stops$season))

```

# Distribution of Stop Concentrations

Using all of the median stop concentration estimates (median_all_data), the data are a lot more variable and have much higher values. Other trimmed and windsorized concentrations are less skewed to the right.

```{r}
stops_l_all_analyses <- stops %>%
select(contains("ptrak"), contains("bc"),
       -c(ptrak_mean_all_data, bc_mean_all_data)) %>%
  gather(key = "Pollutant", value = "value") %>%
  mutate(
    Estimate = ifelse(grepl("ptrak", Pollutant), substr(Pollutant, 7, nchar(Pollutant)), substr(Pollutant, 4, nchar(Pollutant))),
    Pollutant = ifelse(grepl("ptrak", Pollutant), "UFP (pt/cm3)", "BC (ng/m3)"),
    Estimate = factor(Estimate, levels = unique(Estimate))
    ) %>%
  drop_na(value) 

data_crosswalk <- data.frame(
  Estimate = unique(stops_l_all_analyses$Estimate),
  Description = c(
    "Medians stop concentrations for all data",
    "PRIMARY ANALYSIS: 5% trimmed median stop concentrations",
    "5% trimmed mean stop concentrations",
    "10% trimmed median stop concentrations",
    "Windsorized median stop concentrations"
    ))
stops_l_all_analyses <- left_join(stops_l_all_analyses, data_crosswalk)

```

### --> create table just for primary analyses before & after trimming 

```{r}
stops_l_all_analyses %>%
  group_by(Pollutant, Estimate, Description) %>% 
  distribution.table(var.string = "value") %>%
  kable(caption = "Distribution of stop concentrations for all the data (median_all_data), the primary analysis (median_trim5) and sensitivity analyses") %>%
  kable_styling()

```

### --> ? create plot of just the primary analyses before & after trimming 

```{r}
stops_l_all_analyses %>% 
    ggplot(aes(x=Estimate, y=value, fill=Estimate)) + 
  geom_boxplot() + 
  facet_wrap(~Pollutant, scales="free", ncol=1) + 
  labs(title = "Distribution of stop concentrations for all the data (median_all_data), the primary analysis (median_trim5) and sensitivity analyses",
       y = "Stop Concentration Estimate",
       x = "Data Used"
       )  + 
  theme(legend.position = "none") +
  coord_flip()
```

**All analyses starting here use data for the primary analyses (5% trimmed stop medians) unless otherwise stated.**

```{r}
# rename primary analyses for easlier plotting & coding
stops <- stops %>%
  rename(ufp_pt_cm3 = ptrak_median_trim5,
         bc_ng_m3 = bc_median_trim5)

# make PTRAK and BC in long format
stops_l <- stops %>%
  gather("ufp_pt_cm3", "bc_ng_m3", key = "Pollutant", value = "Value" ) %>%
  group_by(Pollutant) %>%
  drop_na(Value) %>%
  ungroup() #%>%
  #mutate(Pollutant = factor(Pollutant, levels = c("ufp_pt_cm3", "bc_ng_m3"), labels = c("UFP (pt/cm3)", "BC (ng/m3)") ))

  
```

# Sample size 

By temporal variables. 

### --> make these tables into plots for dissertation

```{r}
## table of stop counts per site overall & stratified
stop.counts.total <- stops_l %>%
  dplyr::group_by(Pollutant, site_id) %>%
  # no. samples/site
  dplyr::summarize(N = n()) %>%
  group_by(Pollutant) %>%
  # distribution of no. samples
  distribution.table(var.string = "N") %>%
  mutate(Time = "Overall") %>%
  select(Pollutant, Time, everything())

stop.counts.season <- stops_l %>%
  dplyr::group_by(Pollutant, site_id, season) %>%
  # no. samples/site
  dplyr::summarize(N = n()) %>%
  #group by time period of interest
  group_by(Pollutant, Time=season) %>%
  distribution.table(var.string = "N")  

stop.counts.tow <- stops_l %>%
  group_by(Pollutant, site_id, time_of_week) %>%
  # no. samples/site
  dplyr::summarize(N = n()) %>%
  #group by time period of interest
  group_by(Pollutant, Time=time_of_week) %>%
  distribution.table(var.string = "N")  
  
stop.counts.hr <- stops_l %>%
  group_by(Pollutant, site_id, hour) %>%
  # no. samples/site
  dplyr::summarize(N = n()) %>%
  #group by time period of interest
  group_by(Pollutant, Time=hour) %>%
  distribution.table(var.string = "N") %>%
  mutate(Time = as.character(Time))
   
n_distribution <- bind_rows(
  stop.counts.total,
  stop.counts.season,
  stop.counts.tow,
  stop.counts.hr
    ) %>%
  rename('Unique Sites Sampled' = N)

```

- UFP 

On average (SD), we collected 24 (1) two-minute samples from each site, ranging from a minimum of __21__ to a maximum of __26__ samples. Sites were generally sampled __5-7__ times each season, __17__ times during weekdays, __7__ times during weekends, and __1-4__ times during each hour between 4 AM and midnight. These sample counts are mutually exclusive across categories. 

```{r}
n_distribution %>%
  filter(Pollutant == "ufp_pt_cm3") %>%
  select(-Pollutant) %>%
  add_row(Time = "Season", .before = 2) %>%
  add_row(Time = "Time of Week", .before = 7) %>%
  add_row(Time = "Hour", .before = 10) %>%
  kable(caption = "Number of UFP samples collected at each site") %>%
  add_indent(c(3:6, 8:9, 11:31)) %>%
  kable_styling()

```

- BC

On average (SD), we collected 24 (1) two-minute samples from each site, ranging from a minimum of __21__ to a maximum of __26__ samples. Sites were generally sampled __5-7__ times each season, __17__ times during weekdays, __7__ times during weekends, and __1-4__ times during each hour between 4 AM and midnight. These sample counts are mutually exclusive across categories. 

```{r}
n_distribution %>%
  filter(Pollutant == "ufp_pt_cm3") %>%
  select(-Pollutant) %>%
  add_row(Time = "Season", .before = 2) %>%
  add_row(Time = "Time of Week", .before = 7) %>%
  add_row(Time = "Hour", .before = 10) %>%
  kable(caption = "Number of UFP samples collected at each site") %>%
  add_indent(c(3:6, 8:9, 11:31)) %>%
  kable_styling()
```

By site.

- UFP

The figure below shows the number of samples collected for each site during each season, time of week and time of day combination. For logistical reasons related to site location along a route, some sites were sampled during more times of day than others. Sites were more likely to be sampled on more times of day during weekendays than weekends because weekdays received more sampling times (five vs two days out of the week).

```{r}
## plot stratified by time 
stops_l %>%
  filter(Pollutant == "ufp_pt_cm3") %>%
  group_by(site_no, season, time_of_week, tod5) %>%
  dplyr::summarize(N = n()) %>%
  ggplot(aes(x=site_no, y=N, fill= tod5)) +
  geom_bar(stat = "identity", aes(group=site_no))+
  facet_grid(season~time_of_week, switch="y") +
  labs(title = "Number of UFP samples by site and time",
    y="No. Samples",
    x= "Site No.",
    fill = "Hour") + #scale_colour_binned() +
theme(legend.position = "bottom")
  
```

- BC

[same description as above]

```{r}
## plot stratified by time 
stops_l %>%
  filter(Pollutant == "bc_ng_m3") %>%
  group_by(site_no, season, time_of_week, tod5) %>%
  dplyr::summarize(N = n()) %>%
  ggplot(aes(x=site_no, y=N, fill= tod5)) +
  geom_bar(stat = "identity", aes(group=site_no))+
  facet_grid(season~time_of_week, switch="y") +
  labs(title = "Number of BC samples by site and time",
    y="No. Samples",
    x= "Site No.",
    fill = "Hour") +  
theme(legend.position = "bottom")
  
```

# Pollutant Concentrations

## by site 

Distribution of stop concentrations by site (using trimmed data). Distributions look semi normally-distributed or slightly right skewed. Some sites have more variability than others.

```{r}
stops_l %>%
  ggplot(aes(x= site_no, y=Value, group = site_no)) + 
  geom_boxplot() +
  labs(title = paste0("Distribtuion of stop concentrations" ),
       y= "Concentration",
       x = "Site No.") + 
    facet_wrap(~ Pollutant,scales="free", ncol=1)  

```

## over time

```{r}
# table of concentrations distribution 
# overall
ufp.dist.overall <- stops_l %>% 
  group_by(Pollutant) %>%
  distribution.table(dt = ., var.string = "Value") %>%
  mutate(time = "Overall") %>%
  select(Pollutant, time, everything())  

#by season
season.distrib <- stops_l %>% 
  group_by(Pollutant, time=season) %>%
  distribution.table(dt = ., var.string = "Value")  

#by TOW
tow.distrib <- stops_l %>% 
  group_by(Pollutant, time= time_of_week) %>%
  distribution.table(dt = ., var.string = "Value")  

# by hour
hr.distrib <- stops_l %>%
  group_by(Pollutant, time= hour) %>%
  distribution.table(dt = ., var.string = "Value") %>%
  mutate(time = as.character(time))
   
conc_distributions <- bind_rows(ufp.dist.overall,
                            season.distrib,
                            tow.distrib,
                            hr.distrib)  

```

Tables

- UFPs

Average UFP concentrations were generally higher during the fall and winter, on weekdays and during late morning and evening hours.   
-This is in line with the literature, which has reported higher UFP concentrations during cold weather and high traffic activity times.

```{r}
conc_distributions %>%
  filter(Pollutant == "ufp_pt_cm3") %>%
  select(-Pollutant) %>%
  add_row(time = "Season", .before = 2) %>%
  add_row(time = "Time of Week", .before = 7) %>%
  add_row(time = "Hour", .before = 10) %>%
  kable(caption = "Distribution of median UFP stop concentrations over time") %>%
  add_indent(c(3:6, 8:9, 11:31)) %>%
  kable_styling()
  
```

- BC

Average BC concentrations were generally higher during the fall and winter, on weekdays and during morning and evening hours.

```{r}
conc_distributions %>%
  filter(Pollutant == "bc_ng_m3") %>%
  select(-Pollutant) %>%
  add_row(time = "Season", .before = 2) %>%
  add_row(time = "Time of Week", .before = 7) %>%
  add_row(time = "Hour", .before = 10) %>%
  kable(caption = "Distribution of median BC stop concentrations over time") %>%
  add_indent(c(3:6, 8:9, 11:31)) %>%
  kable_styling()

```

Plots

UFP and BC concentrations were very variable for any one hour, day of the week and season.

### --> check that temporal_variable is factored correctly

```{r}
stops_l %>%
  gather(hour, day, season, key = "temporal_variable", value = "temporal_value") %>%
  #filter(Pollutant == "ufp_pt_cm3") %>% #comment this out to plot UFP and BC on sample plot
  mutate(
    temporal_variable = factor(temporal_variable, levels = c("season", "day", "hour")),
    temporal_value = factor(temporal_value, levels = c(levels(factor(stops$hour)), levels(stops$day), levels(stops$season))),
    Pollutant = factor(Pollutant, levels = c("ufp_pt_cm3", "bc_ng_m3"), labels = c("UFP (pt/cm3)", "BC (ng/m3)"))
    ) %>%
  ggplot(aes(x=temporal_value, y=Value)) + 
  geom_boxplot() + 
  facet_grid(Pollutant~temporal_variable, scales= "free", switch = "both") +
  #facet_wrap(Pollutant~temporal_variable, scales= "free",switch = "y",) +
  labs(
    title = "Stop concentrations over time",
    x = "",
    y = ""  #"Concentration"
  )

```

```{r}
# # BC concentrations were very variable for any one hour, day of the week and season.

# # same code as above, but filtered for BC
# stops_l %>%
#   gather(hour, day, season, key = "temporal_variable", value = "temporal_value") %>%
#   filter(Pollutant == "bc_ng_m3") %>%
#   mutate(
#     temporal_value = factor(temporal_value, levels = c(levels(factor(stops$hour)), levels(stops$day), levels(stops$season))),
#     Pollutant = factor(Pollutant, levels = c("ufp_pt_cm3", "bc_ng_m3"), labels = c("UFP (pt/cm3)", "BC (ng/m3)"))
#     ) %>%
#   ggplot(aes(x=temporal_value, y=Value)) + 
#   geom_boxplot() + 
#   facet_grid(Pollutant~temporal_variable, scales= "free", switch = "both") +
#   #facet_wrap(Pollutant~temporal_variable, scales= "free",switch = "y",) +
#   labs(
#     title = "Stop concentrations over time",
#     x = "",
#     y = "")
  
```


# ANOVA for stop medians

stop_medians ~ season + day of week + hour + site_id 

- UFP

Most (~74%) of the variation in UFP stop concentration occurs __[?]within stops at any particular time__. About 22% of the variation in UFP concentration occurs between stops and only ~ 4% occurs as a result temporal changes.

```{r}
# using all of the observations to characterize variability 
anovaVCA(Value ~ season + day + hour + site_id, Data = as.data.frame(subset(stops_l, Pollutant == "ufp_pt_cm3")))$aov.tab %>%
  kable(caption = "Variance components analysis for UFP", 
        digits = 1) %>%
  kable_styling()

```

Site ID and temporal variables are all significantly associated with variation in stop-level UFP concentrations. 

```{r}
ufp_anova <- stops_l %>%
  filter(Pollutant == "ufp_pt_cm3") %>%
  mutate(day = factor(day, ordered = F),
         hour = factor(hour)) %>%
  lm(Value ~ season + day + hour + site_id, data = .)

anova(ufp_anova) %>% 
  kable(caption = "ANOVA results for UFP stop concentrations") %>% 
  kable_styling()

#summary(ufp_anova) 

```

- BC

Most (~77%) of the variation in BC stop concentration occurs __within stops at any particular time__. About 11% of the variation in BC concentration occurs between stops and ~12% occurs as a result temporal changes. 

- BC concentrations are slightly more affected by temporal changes than UFP concentrations.

```{r}
# using all of the observations to characterize variability 
anovaVCA(Value ~ season + day + hour + site_id, Data = as.data.frame(subset(stops_l, Pollutant == "bc_ng_m3")))$aov.tab %>%
  kable(caption = "Variance components analysis for BC", 
        digits = 1) %>%
  kable_styling()

```

Like UFP concentrations, site ID and temporal variables are all significantly associated with variation in stop-level BC concentrations. 

```{r}
bc_anova <- stops_l %>%
  filter(Pollutant == "bc_ng_m3") %>%
  mutate(day = factor(day, ordered = F),
         hour = factor(hour)) %>%
  lm(Value ~ season + day + hour + site_id, data = .)

anova(bc_anova) %>% 
  kable(caption = "ANOVA results for BC stop concentrations") %>% 
  kable_styling()

#summary(bc_anova) 

``` 

# Annual averages 

calculate annual avg means using different methods and weights to determine how sensitve estimates are to using various approaches: 
* site-specific data vs regression  
* unweighted vs weighted (season, tow, tod) means

## Site-specific data 

### season-TOW2-TOD5

```{r}
# unique times
min.t <- n.seasons.sampled*2*5

```

No sites are sampled each season-TOW2_TOD5 combination (n = `r min.t` unique times).

```{r}
stops_l %>%
  unique_times_sampled(.,min_samples_required = min.t,
                       temporal_vars = c("season", "time_of_week", "tod5")) %>%
  kable(caption = "Number of sites that sampled during each time combination") %>% 
  kable_styling()

```
 
 
### season-TOW2-TOD3

```{r}
min.t <- n.seasons.sampled*2*3

```

No sites are sampled each season-TOW2-TOD3 combination (n = `r min.t` unique times).

```{r}
stops_l %>%
  unique_times_sampled(.,min_samples_required = min.t,
                       temporal_vars = c("season", "time_of_week", "tod3")) %>%
  kable(caption = "Number of sites that sampled during each time combination") %>% 
  kable_styling()

```

### season-TOW2-TOD2

```{r}
min.t <- n.seasons.sampled*2*2

```

A few sites sampled each season-TOW2-TOD2 combination (n = `r min.t` unique times).

```{r}
s_tow2_tod2 <- stops_l %>%
  unique_times_sampled(.,min_samples_required = min.t,
                       temporal_vars = c("season", "time_of_week", "tod2"), 
                       return_site_ids = T) 

s_tow2_tod2$n_sampled_min_amount %>%
  kable(caption = "Number of sites that sampled during each time combination") %>% 
  kable_styling()

```

Calculate the weighted means for these locations. 

```{r}
## using tod2, caclulate weighted mean for sites w/ obs during all time combinations
s_tow2_tod2 <- s_tow2_tod2$sites_sampled_min_amount %>%
  left_join(stops_l) %>%
  # calculate means for each temporal combination & pollutant
  group_by(Pollutant, site_id, season, time_of_week, tod2) %>%
  dplyr::summarize(grp_mean = mean(Value)) %>%
  mutate(
    season.wt = 1/n.seasons.sampled,
    wk.wt = ifelse(time_of_week == "weekday", 5/7, 2/7),
    tod.wt = ifelse(tod2 == "9_17", 9/24, 15/24),
    wt = season.wt * wk.wt * tod.wt,
    grp_mean_wt = grp_mean*wt) %>%
  # #check that weights for all Pollutants & sites = 1. #looks good
  # group_by(Pollutant, site_id) %>%
  # dplyr::summarize(n = sum(wt)) %>%
  # group_by(Pollutant) %>%
  # dplyr::summarize(sum_is_not_one = sum(n !=1))

  #calculate each site's weighted mean
  group_by(Pollutant, site_id) %>%
  dplyr::summarize(site_only_s_tow2_tod2 = sum(grp_mean_wt))
  
```

### season-TOW2

```{r}
min.t <- n.seasons.sampled*2

```

More sites sampled each season-TOW2 combination (n = `r min.t` unique times).

```{r}
s_tow2 <- stops_l %>%
  unique_times_sampled(.,min_samples_required = min.t,
                       temporal_vars = c("season", "time_of_week"), 
                       return_site_ids = T) 

s_tow2$n_sampled_min_amount %>%
  kable(caption = "Number of sites that sampled during each time combination") %>% 
  kable_styling()

```

Calculate the weighted means for these locations. 

```{r}
## using tod2, caclulate weighted mean for sites w/ obs during all time combinations
s_tow2 <- s_tow2$sites_sampled_min_amount %>%
  left_join(stops_l) %>%
  # calculate means for each temporal combination & pollutant
  group_by(Pollutant, site_id, season, time_of_week) %>%
  dplyr::summarize(grp_mean = mean(Value)) %>%
  mutate(
    season.wt = 1/n.seasons.sampled,
    wk.wt = ifelse(time_of_week == "weekday", 5/7, 2/7),
    wt = season.wt * wk.wt,
    grp_mean_wt = grp_mean*wt) %>%
  # #check if any weights for all Pollutants & sites != 1. #looks good
  # group_by(Pollutant, site_id) %>%
  # dplyr::summarize(n = sum(wt)) %>%
  # group_by(Pollutant) %>%
  # dplyr::summarize(sum_is_not_one = sum(n !=1))

  #calculate each site's weighted mean
  group_by(Pollutant, site_id) %>%
  dplyr::summarize(site_only_s_tow2 = sum(grp_mean_wt))

```

### season  

```{r}
min.t <- n.seasons.sampled

```

All sites sampled each season-TOW2 combination (n = `r min.t` unique times).

```{r}
s <- stops_l %>%
  unique_times_sampled(.,min_samples_required = min.t,
                       temporal_vars = c("season"), 
                       return_site_ids = T) 

s$n_sampled_min_amount %>%
  kable(caption = "Number of sites that sampled during each time combination") %>% 
  kable_styling()

```

Calculate the weighted means for these locations. 

```{r}
## using tod2, caclulate weighted mean for sites w/ obs during all time combinations
s <- s$sites_sampled_min_amount %>%
  left_join(stops_l) %>%
  # calculate means for each temporal combination & pollutant
  group_by(Pollutant, site_id, season) %>%
  dplyr::summarize(grp_mean = mean(Value)) %>%
  mutate(
    season.wt = 1/n.seasons.sampled,
    wt = season.wt,
    grp_mean_wt = grp_mean*wt) %>%
  # #check if any weights for all Pollutants & sites != 1. #looks good
  # group_by(Pollutant, site_id) %>%
  # dplyr::summarize(n = sum(wt)) %>%
  # group_by(Pollutant) %>%
  # dplyr::summarize(sum_is_not_one = sum(n !=1))

  #calculate each site's weighted mean
  group_by(Pollutant, site_id) %>%
  dplyr::summarize(site_only_s = sum(grp_mean_wt))
  
```

### merge all estimates 

```{r}
# add estimates to stops_l

stops_l <- stops_l %>%
  # weighted avgs
  left_join(s_tow2_tod2) %>%
  left_join(s_tow2) %>%
  left_join(s) %>%
  group_by(Pollutant, site_id) %>%
  # unweighted avg
  mutate(site_only_uw = mean(Value, na.rm=T))

```

# Regression  

Averaging method weight description

```{r}
data.frame(
  Weight = c("uw",
               "s",
               "s_tow2",
               "s_tow2_tod2",
               "s_tow2_tod5",
               "s_day_tod5"),
  Description = c("unweighted annual average",
                  "season-adjusted annual average",
                  "season- and time-of-week- (weekend vs weekday) adjusted annual average",
                  "season-, time-of-week- (weekend vs weekday) and time-of-day (2 categories: 9 AM - 5 PM, 6 PM - 8 AM) adjusted annual average",
                  "season-, time-of-week- (weekend vs weekday) and time-of-day (5 categories: 3-8 AM, 9-11 AM, 12-3 PM, 4-8 PM, 9 PM - 2 AM) adjusted annual average",
                  "season-, day-of-week (7 days) and time-of-day (5 categories) adjusted annual average"),
  Primary_Analysis = c("No",
                       "No",
                       "No",
                       "No",
                       "Yes",
                       "No"),
  Regression_Estimate = "Yes",
  Site_Only_Estimate = c(rep("Yes", 4),
                         rep("No", 2))
  ) %>%
  kable(caption = "Description of weights used to estimate annual averages from short-term mobile monitoring stop observations for primary and sensitivity analyses using both regression and site-only methods", 
        col.names = c("Weight", "Description", "Primary Analysis", "Regression Estimate", "Site-Only Estimate" )
        ) %>%
  kable_styling()
   
```


Fit models to predict UFP and BC at different times 

```{r}
#df for predictions - all unique variable combinations

preds_s_ufp0 <- stops %>% ungroup() %>%
  tidyr::expand(site_id, season) %>%
  mutate(season_wt = 1/n.seasons.sampled,
         wt = season_wt)
preds_s_bc0 <- preds_s_ufp0
  
preds_s_tow2_ufp0 <- stops %>% ungroup() %>%
  tidyr::expand(site_id, season, time_of_week) %>%
  mutate(season_wt = 1/n.seasons.sampled,
         tow2_wt = ifelse(time_of_week == "weekday", 5/7, 2/7),
         wt = season_wt*tow2_wt)
preds_s_tow2_bc0 <- preds_s_tow2_ufp0

preds_s_tow2_tod2_ufp0 <- stops %>% ungroup() %>%
  tidyr::expand(site_id, season, time_of_week, tod2) %>%
  mutate(season_wt = 1/n.seasons.sampled,
         tow2_wt = ifelse(time_of_week == "weekday", 5/7, 2/7),
         tod2_wt = ifelse(tod2 == "9_17", 9/24, (1- 9/24)),
         wt = season_wt*tow2_wt*tod2_wt)
preds_s_tow2_tod2_bc0 <- preds_s_tow2_tod2_ufp0

preds_s_tow2_tod5_ufp0 <- stops %>% ungroup() %>% 
  tidyr::expand(site_id, season, time_of_week, tod5) %>%
  mutate(season_wt = 1/n.seasons.sampled,
         tow2_wt = ifelse(time_of_week == "weekday", 5/7, 2/7),
         tod5_wt = recode(tod5,
                          "3_8" = 6,
                          "9_11" = 3,
                          "12_15" = 4,
                          "16_20" = 5,
                          "21_2" = 6)/24,
         wt = season_wt*tow2_wt*tod5_wt)
preds_s_tow2_tod5_bc0 <- preds_s_tow2_tod5_ufp0

preds_s_day_tod5_ufp0 <- stops %>% ungroup() %>%
  tidyr::expand(site_id, season, day, tod5) %>%
  mutate(season_wt = 1/n.seasons.sampled,
         day_wt = 1/7,
         tod5_wt = recode(tod5,
                          "3_8" = 6,
                          "9_11" = 3,
                          "12_15" = 4,
                          "16_20" = 5,
                          "21_2" = 6)/24,
         wt = season_wt*day_wt*tod5_wt)
preds_s_day_tod5_bc0 <- preds_s_day_tod5_ufp0

```

```{r}
# model fits
fit_s_ufp <-  lm(Value ~ site_id + season, data = stops_l, subset = (Pollutant =="ufp_pt_cm3"))
# same model as above but for a different pollutant
fit_s_bc <-  update(fit_s_ufp, subset = (Pollutant =="bc_ng_m3"))
 
fit_s_tow2_ufp <- update(fit_s_ufp, ~. + time_of_week)
fit_s_tow2_bc <- update(fit_s_tow2_ufp, subset = (Pollutant =="bc_ng_m3"))

fit_s_tow2_tod2_ufp <- update(fit_s_tow2_ufp, ~. + tod2)
fit_s_tow2_tod2_bc <- update(fit_s_tow2_tod2_ufp, subset = (Pollutant =="bc_ng_m3"))

fit_s_tow2_tod5_ufp <- update(fit_s_tow2_ufp, ~. + tod5)
fit_s_tow2_tod5_bc <- update(fit_s_tow2_tod5_ufp,  subset = (Pollutant =="bc_ng_m3"))

fit_s_day_tod5_ufp <- update(fit_s_tow2_tod5_ufp, ~. -time_of_week + factor(day, ordered = F))
fit_s_day_tod5_bc <- update(fit_s_day_tod5_ufp, subset = (Pollutant =="bc_ng_m3"))

```

Calculate weighted annual averages based on predictions

```{r}
# season
preds_s_ufp <- preds_s_ufp0 %>%
  mutate(yhat = predict(object = fit_s_ufp, newdata = .),
         yhat_wt = yhat*wt) %>%
  group_by(site_id) %>%
  dplyr::summarize(sum_yhat_wt = sum(yhat_wt)) %>%
  mutate(Pollutant = "ufp_pt_cm3")

preds_s_bc <- preds_s_bc0 %>%
  mutate(yhat = predict(object = fit_s_bc, newdata = .),
         yhat_wt = yhat*wt) %>%
  group_by(site_id) %>%
  dplyr::summarize(sum_yhat_wt = sum(yhat_wt)) %>%
  mutate(Pollutant = "bc_ng_m3")

preds_s <- rbind(preds_s_ufp, preds_s_bc) %>%
  rename(regression_s = sum_yhat_wt)

```

```{r}
# season-TOW2
preds_s_tow2_ufp <- preds_s_tow2_ufp0 %>%
  mutate(yhat = predict(object = fit_s_tow2_ufp, newdata = .),
         yhat_wt = yhat*wt) %>%
  group_by(site_id) %>%
  dplyr::summarize(sum_yhat_wt = sum(yhat_wt)) %>%
  mutate(Pollutant = "ufp_pt_cm3")

preds_s_tow2_bc <- preds_s_tow2_bc0 %>%
  mutate(yhat = predict(object = fit_s_tow2_bc, newdata = .),
         yhat_wt = yhat*wt) %>%
  group_by(site_id) %>%
  dplyr::summarize(sum_yhat_wt = sum(yhat_wt)) %>%
  mutate(Pollutant = "bc_ng_m3")

preds_s_tow2 <- rbind(preds_s_tow2_ufp, preds_s_tow2_bc) %>%
  rename(regression_s_tow2 = sum_yhat_wt)

```

```{r}
# season-TOW2-TOD2
preds_s_tow2_tod2_ufp <- preds_s_tow2_tod2_ufp0 %>%
  mutate(yhat = predict(object = fit_s_tow2_tod2_ufp, newdata = .),
         yhat_wt = yhat*wt) %>%
  group_by(site_id) %>%
  dplyr::summarize(sum_yhat_wt = sum(yhat_wt)) %>%
  mutate(Pollutant = "ufp_pt_cm3")

preds_s_tow2_tod2_bc <- preds_s_tow2_tod2_bc0 %>%
  mutate(yhat = predict(object = fit_s_tow2_tod2_bc, newdata = .),
         yhat_wt = yhat*wt) %>%
  group_by(site_id) %>%
  dplyr::summarize(sum_yhat_wt = sum(yhat_wt)) %>%
  mutate(Pollutant = "bc_ng_m3")

preds_s_tow2_tod2 <- rbind(preds_s_tow2_tod2_ufp, preds_s_tow2_tod2_bc) %>%
  rename(regression_s_tow2_tod2 = sum_yhat_wt)

```

```{r}
# season-TOW2-TOD5
preds_s_tow2_tod5_ufp <- preds_s_tow2_tod5_ufp0 %>%
  mutate(yhat = predict(object = fit_s_tow2_tod5_ufp, newdata = .),
         yhat_wt = yhat*wt) %>%
  group_by(site_id) %>%
  dplyr::summarize(sum_yhat_wt = sum(yhat_wt)) %>%
  mutate(Pollutant = "ufp_pt_cm3")

preds_s_tow2_tod5_bc <- preds_s_tow2_tod5_bc0 %>%
  mutate(yhat = predict(object = fit_s_tow2_tod5_bc, newdata = .),
         yhat_wt = yhat*wt) %>%
  group_by(site_id) %>%
  dplyr::summarize(sum_yhat_wt = sum(yhat_wt)) %>%
  mutate(Pollutant = "bc_ng_m3")

preds_s_tow2_tod5 <- rbind(preds_s_tow2_tod5_ufp, preds_s_tow2_tod5_bc) %>%
  rename(regression_s_tow2_tod5 = sum_yhat_wt)

```

```{r}
# season-day-TOD5
preds_s_day_tod5_ufp <- preds_s_day_tod5_ufp0 %>%
  mutate(yhat = predict(object = fit_s_day_tod5_ufp, newdata = .),
         yhat_wt = yhat*wt) %>%
  group_by(site_id) %>%
  dplyr::summarize(sum_yhat_wt = sum(yhat_wt)) %>%
  mutate(Pollutant = "ufp_pt_cm3")

preds_s_day_tod5_bc <- preds_s_day_tod5_bc0 %>%
  mutate(yhat = predict(object = fit_s_day_tod5_bc, newdata = .),
         yhat_wt = yhat*wt) %>%
  group_by(site_id) %>%
  dplyr::summarize(sum_yhat_wt = sum(yhat_wt)) %>%
  mutate(Pollutant = "bc_ng_m3")

preds_s_day_tod5 <- rbind(preds_s_day_tod5_ufp, preds_s_day_tod5_bc) %>%
  rename(regression_s_day_tod5 = sum_yhat_wt)

```

```{r}
 # merge regression predictions
stops_l <- stops_l %>%
  left_join(preds_s_day_tod5) %>%
  left_join(preds_s_tow2_tod5) %>%
  left_join(preds_s_tow2_tod2) %>%
  left_join(preds_s_tow2) %>%
  left_join(preds_s) 
  
```

```{r, include=T}
# create df for plotting 
method_names_all <- stops_l %>% ungroup() %>%
  select(contains(c("site_only", "regression"))) %>%
  names()

#drop estimate/s that can only be calculated w/ regression
method_names <- setdiff(method_names_all, c("yhat_s_tow2_tod5", "regression_s_day_tod5"))

annual <- stops_l %>% ungroup() %>%
  select(site_no, site_id, Pollutant,
         method_names_all) %>%
  unique() 

annual.l <- annual %>%
  gather(key = "method_weight", value = "value", method_names_all) %>%
  mutate(
    method = ifelse(grepl("site_only", method_weight), "site only", "regression"),
    weight = ifelse(grepl("site_only", method_weight), substr(method_weight, 11, nchar(method_weight)), substr(method_weight, 12, nchar(method_weight))),
    weight = factor(weight, levels = c("uw", "s", "s_tow2", "s_tow2_tod2", "s_tow2_tod5", "s_day_tod5"))
  ) %>%
  drop_na(value)

```
 
```{r}
annual.l %>%
  ggplot(aes(x=weight, y = ..count.., fill=method)) +
  geom_bar(position = "dodge") + 
  facet_wrap(~Pollutant, #ncol=1
             ) + 
  labs(title = "Number of sites included in annual average estimation methods",
       y = "No. Sites Included",
       x = "Weight",
       fill = "Averaging Method"
       ) +
  geom_text(stat = "count", 
            aes(label = ..count..),
            hjust= 1,  
            position = position_dodge(width = 1)
            ) + 
  coord_flip() +
  theme(legend.position = "bottom")

```

Disribution of annual estimates.

Annual average estimates are mostly similar for both UFPs and BC using different averaging methods (site only data vs regression) and different weights (e.g., unweighted; season; season and time-of-week). Site-only estimates weighted by season, time of week and time of day (2 categories) appear to be differently distributed than other estimates, though this is likely due to the small sample size.

```{r}
#histograms
annual.l %>%
  #filter(Pollutant == "ufp_pt_cm3") %>%
  ggplot(aes(x=value, fill = method_weight)) +   
  geom_density(alpha=0.2) + 
  facet_wrap(~Pollutant, scales = "free"
             ) + 
  labs(title = "Annual average site concentration estimates by method and weight",
       x = "Annual Avg Concentration Estimate",
       fill = "AveragingMethod_Weight"
       )  + 
  theme(legend.position = "bottom")

```

Scatterplots comparing annual average site estimates from the desired regression estimation method that adjusts for season, time of week (weekend vs weekday) and time of day (5 categories; yhat_s_tow2_tod5) to site-only averaging methods.

- UFP 

The regression estimates are similar to all site-only estimation methods.

```{r}
# test <- annual %>%
#   #filter(Pollutant == "ufp_pt_cm3") %>%
#   select(Pollutant, regression_s_tow2_tod5, contains("site_only")) %>%
#   gather(key = "variable", value = "value", contains("site_only")) %>%
#   drop_na(value)
# 
# test %>%
#   filter(Pollutant == "ufp_pt_cm3") %>%
#   colo.plot(x.variable = "value", y.variable = "regression_s_tow2_tod5") +
#   facet_wrap(~variable)

plot_pollutant <- "ufp_pt_cm3"

p1 <- annual %>%
  filter(Pollutant == plot_pollutant) %>%
  colo.plot(x.variable = "site_only_uw", y.variable = "regression_s_tow2_tod5")

p2 <- annual %>%
  filter(Pollutant == plot_pollutant) %>%
  colo.plot(x.variable = "site_only_s", y.variable = "regression_s_tow2_tod5")

p3 <- annual %>%
  filter(Pollutant == plot_pollutant) %>%
  colo.plot(x.variable = "site_only_s_tow2", y.variable = "regression_s_tow2_tod5")

p4 <- annual %>%
  filter(Pollutant == plot_pollutant) %>%
  colo.plot(x.variable = "site_only_s_tow2_tod2", y.variable = "regression_s_tow2_tod5")

 ggarrange(p1, p2, p3, p4,  
           common.legend = T, legend = "bottom") %>%
  annotate_figure(fig.lab = paste0("UFP annual average site concentration estimates from desired regression estimation method and site-only averaging methods"))
 
```

- BC

```{r}
plot_pollutant <- "bc_ng_m3"

p1 <- annual %>%
  filter(Pollutant == plot_pollutant) %>%
  colo.plot(x.variable = "site_only_uw", y.variable = "regression_s_tow2_tod5")

p2 <- annual %>%
  filter(Pollutant == plot_pollutant) %>%
  colo.plot(x.variable = "site_only_s", y.variable = "regression_s_tow2_tod5")

p3 <- annual %>%
  filter(Pollutant == plot_pollutant) %>%
  colo.plot(x.variable = "site_only_s_tow2", y.variable = "regression_s_tow2_tod5")

p4 <- annual %>%
  filter(Pollutant == plot_pollutant) %>%
  colo.plot(x.variable = "site_only_s_tow2_tod2", y.variable = "regression_s_tow2_tod5")

 ggarrange(p1, p2, p3, p4,  
           common.legend = T, legend = "bottom") %>%
  annotate_figure(fig.lab = paste0("BC annual average site concentration estimates from desired regression estimation method and site-only averaging methods"))
 
```

## Method comparison plots.

### Comparison plots of all locations where sampling occurred every season, time of week and time of day (2 categories) combination

### ---> update UFP, BC labels here & below

```{r}
annual_subset_tod2 <- annual %>%
  select(-c(regression_s_day_tod5, regression_s_tow2_tod5)) %>%
  drop_na(site_only_s_tow2, site_only_s_tow2_tod2) %>%
  gather(method_weight, value, contains(c("site_only", "regression"))) %>%
  mutate(
    method = ifelse(grepl("site_only", method_weight), "site only", "regression"),
    weight = ifelse(grepl("site_only", method_weight), substr(method_weight, 11, nchar(method_weight)), substr(method_weight, 12, nchar(method_weight))),
    weight = factor(weight, levels = c("uw", "s", "s_tow2", "s_tow2_tod2" #"s_tow2_tod5", "s_day_tod5"
                                       )))

tod2_no_sites <- length(unique(annual_subset_tod2$site_id))

```

Annual average UFP and BC estimates are similar across averaging methods for sites with observations each time of day (2 categories), time of week (weekend vs. weekday) and season combination. 

```{r}
annual_subset_tod2 %>%
  ggplot(aes(x=factor(site_no), y=value, col=method, shape=weight)) + 
  geom_point(alpha=0.7) + 
  facet_wrap(~Pollutant, scales="free") +
  theme(legend.position = "bottom") +
  labs(title = "Annual average estimates at sites by averaging method and weight",
       subtitle = paste0("N = ", tod2_no_sites, " sites total"),
       #subtitle = paste0("N = ", length(unique()), " sites"),
       y = "Annual Average Concentration Estimate",
       x = "Site No."
       ) +
  coord_flip() 

#+ scale_x_continuous(breaks = seq(0, tow2_no_sites, by = 20))
#scale_x_continuous(breaks = scales::pretty_breaks(n = 20)) +

```

### Comparison plots of all locations where sampling occurred every season and time of week combination

```{r}
annual_subset_tow2 <- annual %>%
  select(-c(site_only_s_tow2_tod2,
            regression_s_day_tod5, regression_s_tow2_tod5, regression_s_tow2_tod2)) %>%
  drop_na(site_only_s_tow2) %>%
  gather(method_weight, value, contains(c("site_only", "regression"))) %>%
  mutate(
    method = ifelse(grepl("site_only", method_weight), "site only", "regression"),
    weight = ifelse(grepl("site_only", method_weight), substr(method_weight, 11, nchar(method_weight)), substr(method_weight, 12, nchar(method_weight))),
    weight = factor(weight, levels = c("uw", "s", "s_tow2" #"s_tow2_tod2", "s_tow2_tod5", "s_day_tod5"
                                       )))

tow2_no_sites <- length(unique(annual_subset_tow2$site_id))

```

```{r, fig.height=10}
annual_subset_tow2 %>%
  ggplot(aes(x=site_no, y=value, col=method, shape=weight)) + 
  geom_point(alpha=0.7) + 
  facet_wrap(~Pollutant, scales="free") +
  theme(legend.position = "bottom") +
  labs(title = "Annual average estimates at sites by averaging method and weight",
       subtitle = paste0("N = ", tow2_no_sites, " sites"),
       #subtitle = paste0("N = ", length(unique()), " sites"),
       y = "Annual Average Concentration Estimate",
       x = "Site No."
       ) +
  coord_flip() 

#+ scale_x_continuous(breaks = seq(0, tow2_no_sites, by = 20))
#scale_x_continuous(breaks = scales::pretty_breaks(n = 20)) +

```

Zoomed in plots highlight the small within-site variability of estimation methods.

```{r}
set.seed(1)
no_sites <- 20

annual_subset_tow2 %>%
  #select a random sample of sites (to try to get low/high concentrations from less correlated sites)
  filter(site_id %in% sample(site_id, size = no_sites, replace = F)) %>%
  ggplot(aes(x=factor(site_no), y=value, col=method, shape=weight)) + 
  geom_point(alpha=0.7) + 
  facet_wrap(~Pollutant, scales="free") +
  theme(legend.position = "bottom") +
  labs(title = "Annual average estimates by averaging method and weight for a random sample of sites",
       subtitle = paste0("N = ", no_sites, " sample sites"),
       y = "Annual Average Concentration Estimate",
       x = "Site No."
       )  +
  coord_flip()
  
```
 
# ANOVA for annual averages

annual concentration ~ method + site_id

- UFP

Almost all of the variation in UFP annual average concentration occurs between sites, with less than 1% occurring as a result of using different averaging (site-only vs regression) and weight (e.g., unweighted vs season) methods.

```{r}
# using all of the observations to characterize variability 
anovaVCA(value ~ method_weight + site_id, Data = as.data.frame(subset(annual.l, Pollutant == "ufp_pt_cm3")))$aov.tab %>%
  kable(caption = "Variance components analysis for annual average UFP",
        digits = 1) %>%
  kable_styling()

```

Though site ID and averaging method are both significantly associated with variation in annual average UFP concentrations.  

```{r}
ufp_annual_anova <- annual.l %>%
  filter(Pollutant == "ufp_pt_cm3") %>%
  lm(value ~ method_weight + site_id, data = .)

anova(ufp_annual_anova) %>%
  kable(caption = "ANOVA results for UFP annual average concentrations") %>%
  kable_styling()

```

The effect of estimation method and weight on the annual average is not scientifically meanigful, however. The table only shows effect estimate for a few sites.

```{r}
summary(ufp_annual_anova)$coef[1:20,] %>%
  kable(caption = "Least squares regression of annual average UFP based by site ID and averaging method",
        digits = 2) %>% 
  kable_styling()

```

- BC

Similar results as UFP.

```{r}
# using all of the observations to characterize variability 
anovaVCA(value ~ method_weight + site_id, Data = as.data.frame(subset(annual.l, Pollutant == "bc_ng_m3")))$aov.tab %>%
  kable(caption = "Variance components analysis for annual average BC",
        digits = 1) %>%
  kable_styling()

```

```{r}
bc_annual_anova <- annual.l %>%
  filter(Pollutant == "bc_ng_m3") %>%
  lm(value ~ method_weight + site_id, data = .)

anova(bc_annual_anova) %>%
  kable(caption = "ANOVA results for BC annual average concentrations") %>%
  kable_styling()

```

```{r}
summary(bc_annual_anova)$coef[1:20,] %>%
  kable(caption = "Least squares regression of annual average BC based by site ID and averaging method",
        digits = 2) %>% 
  kable_styling()

```

# Sensitivity Analyses

Estimate annual average for primary and sensitivity analyses using: 

a) linear regression: stop avg ~ site_id + season + time of week + time of day 
b) weighting time-specific results appropriately to estimate annual average

```{r}
data.frame(
  analysis_names = annual_ufp_names) %>%
  label_analysis(var = "analysis_names") %>%
  select(Analysis) %>%
  cbind(Description = c("Using stop medians; trimming 5% of each site's highest and lowest stop concentrations; using regression to estimate season-, TOW2- and TOD5-adjusted annual avg concentrations; modeling log-transformed concentrations and proximity covariates",
             "Like Primary analysis, but using stop means (vs medians) to estimate annual averages",
             "Like Primary analysis, but trimming 10% of each site's highest and lowest stop concentrations (vs 5%) before estimating annual averages",
             "Like Primary analysis, but Windsorizing each site's highest and lowest 5% stop concentrations (vs trimming) before estimating annual averages",
             "Like Primary analysis, but calculating unweighted annual averages for each site (vs regression estimates adjusted for season-, time-of-week- and time-of-day)"
             )) %>%
  kable(., caption = "Description of primary and sensitivity analyses") %>%
  kable_styling()


```



```{r}
predictors <- c("site_id", "season", "time_of_week", "tod5")

```

- UFP

```{r}
              # primary analysis
annual_ufp <- estimate_annual_avg(dt = stops, lm_x_names = predictors,
                                       var = "ufp_pt_cm3", estimate_label = "ufp_primary") %>%
  # stop means
  left_join(estimate_annual_avg(dt = stops, lm_x_names = predictors,
                                       var = "ptrak_mean_trim5", estimate_label = "ufp_stop_means")) %>%
  # Trim 10% observations
  left_join( estimate_annual_avg(dt = stops, lm_x_names = predictors,
                                       var = "ptrak_median_trim10", estimate_label = "ufp_trim10")) %>%
  # Windosrize extreme stop readings (top/bottom 5%)
  left_join(estimate_annual_avg(dt = stops, lm_x_names = predictors,
                                       var = "ptrak_median_windsorize", estimate_label = "ufp_windsorize")) %>%
  # unweighted annual averages
  left_join(estimate_annual_avg(dt = stops, lm_x_names = "site_id",
                                       var = "ufp_pt_cm3", estimate_label = "ufp_uw"))
 
```

- BC

```{r}
              # primary analysis
annual_bc <- estimate_annual_avg(dt = stops, lm_x_names = predictors,
                                       var = "bc_ng_m3", estimate_label = "bc_primary") %>%
  # stop means
  left_join(estimate_annual_avg(dt = stops, lm_x_names = predictors,
                                       var = "bc_mean_trim5", estimate_label = "bc_stop_means")) %>%
  # Trim 10% observations
  left_join( estimate_annual_avg(dt = stops, lm_x_names = predictors,
                                       var = "bc_median_trim10", estimate_label = "bc_trim10")) %>%
  # Windosrize extreme stop readings (top/bottom 5%)
  left_join(estimate_annual_avg(dt = stops, lm_x_names = predictors,
                                       var = "bc_median_windsorize", estimate_label = "bc_windsorize")) %>%
  # unweighted annual averages
  left_join(estimate_annual_avg(dt = stops, lm_x_names = "site_id",
                                       var = "bc_ng_m3", estimate_label = "bc_uw"))

```

```{r}
annual <- left_join(annual_ufp, annual_bc)

annual_ufp_names <- names(annual)[grepl("ufp", names(annual))]
annual_bc_names <- names(annual)[grepl("bc", names(annual))]

annual_l <- annual %>% gather("pollutant_analysis", "prediction", contains(c("ufp", "bc"))) %>%
  label_analysis(var = "pollutant_analysis")
  # mutate(
  #   pollutant = ifelse(grepl("ufp", pollutant_analysis), "UFP (pt/cm3)", "BC (ng/m3)"),
  #   analysis = ifelse(grepl("ufp", pollutant_analysis), substr(pollutant_analysis, 5, nchar(pollutant_analysis)), substr(pollutant_analysis, 4, nchar(pollutant_analysis))),
  #   analysis = relevel(factor(analysis), ref = "primary")) 
                                        
```

Distribution of annual average estimates for primary and sensitivity analyses

### --> table just for primary BC & UFP

```{r}
# table 
annual_l %>%
  group_by(Pollutant, Analysis) %>%
  distribution.table(var.string = "prediction") %>%
  kable(caption = "Distribution of annual average estimates for primary and sensitivity analyses") %>%
  kable_styling()

```

```{r}
# density plot
annual_l %>%
  ggplot(aes(x=prediction, fill = Analysis)) + 
  geom_density(alpha = 0.2) + 
  facet_wrap(~Pollutant, scales= "free") +
  labs(fill = "Analysis",
       x = "Prediction",
       title = "Distribution of annual average estimates for primary and sensitivity analyses") + 
  theme(legend.position = "bottom")
   
```

Scatterplots around 1-1 line

Preidctions are similar for primary and sensitivity analyses of annual average estimates of UFP and BC. 

- UFP

```{r}
max_plot <- max(annual_l$prediction[grepl("ufp", tolower(annual_l$Pollutant))])
min_plot <- min(annual_l$prediction[grepl("ufp", tolower(annual_l$Pollutant))])

annual %>%
  gather("pollutant_analysis", "prediction", contains(c("ufp")), -contains("primary")) %>%
  label_analysis(var = "pollutant_analysis") %>%
  ggplot(aes(x = ufp_primary, y = prediction, col = Analysis)) +
  geom_abline(intercept = 0, slope = 1) +
  geom_point(alpha = 0.2) + 
  geom_smooth() +
  xlim(min_plot, max_plot) + ylim(min_plot, max_plot) +
  labs(x = "Primary Analysis",
       y = "Sensitivity Analysis",
       title = "Comparison of annual average UFP estimates (pt/cm3) from primary and sensitivity analyses") +
  theme(legend.position = "bottom")
  
```

- BC

```{r}
max_plot <- max(annual_l$prediction[grepl("bc", tolower(annual_l$Pollutant))])
min_plot <- min(annual_l$prediction[grepl("bc", tolower(annual_l$Pollutant))])

annual %>%
  gather("pollutant_analysis", "prediction", contains(c("bc")), -contains("primary")) %>%
  label_analysis(var = "pollutant_analysis") %>%
  ggplot(aes(x = bc_primary, y = prediction, col = Analysis)) +
  geom_abline(intercept = 0, slope = 1) +
  geom_point(alpha = 0.2) + 
  geom_smooth() +
  xlim(min_plot, max_plot) + ylim(min_plot, max_plot) +
  labs(x = "Primary Analysis",
       y = "Sensitivity Analysis",
       title = "Comparison of annual average BC estimates (ng/m3) from primary and sensitivity analyses") +
  theme(legend.position = "bottom")
  
```

Maps

```{r}
# add lat/long
annual_lat_long <- annual %>% 
  left_join(site_locations) %>%
  # site MS601 has no lat/long
  drop_na()

```

- UFP 

```{r, fig.height=10}
# dot map
#list to store maps
annual_maps_ufp <-list()
annual_names <- annual_ufp_names #update for BC

# min and max difference of all estimates
plot_range <- annual %>%
  select(annual_names) %>%
  dplyr::summarize(min = min(.),
                   max = max(.)) %>%
  round()

for(i in seq_along(annual_names)) {
  #i=1
  mymap <- suppressMessages(
     annual_lat_long %>% map_fn(color_by = annual_names[i], outline_points = F,
                                   map_title = annual_names[i]) +
    scale_color_gradient(name = "pt/cm3", 
                        low = "yellow", high = "red",
                        #ensure that all plots on same scale
                        limits = c(plot_range$min, plot_range$max))
    )

  annual_maps_ufp[i] <- list(mymap)
  names(annual_maps_ufp)[i] <- substr(annual_names[i], 5, nchar(annual_names[i]))
}

```

Map of UFP predictions from primary analysis

```{r}
annual_maps_ufp$primary

```

Comparison maps of UFP predictions from primary and sensitivity analysis 

```{r, fig.height=15}

ggarrange(plotlist = annual_maps_ufp,
          ncol = 3, nrow = 2,
          common.legend = T, legend = "right") %>%
  annotate_figure(top = "Annual average UFP estimates from different methods" ) 
   
```

- BC 

```{r, fig.height=10}
# dot map
#list to store maps
annual_maps_bc <-list()
annual_names <- annual_bc_names 

# min and max difference of all estimates
plot_range <- annual %>%
  select(annual_names) %>%
  dplyr::summarize(min = min(.),
                   max = max(.)) %>%
  round()

for(i in seq_along(annual_names)) {
  #i=1
  mymap <- suppressMessages(
     annual_lat_long %>% map_fn(color_by = annual_names[i], outline_points = F,
                                   map_title = annual_names[i]) +
    scale_color_gradient(name = "pt/cm3", 
                        low = "yellow", high = "red",
                        #ensure that all plots on same scale
                        limits = c(plot_range$min, plot_range$max))
    )

  annual_maps_bc[i] <- list(mymap)
  names(annual_maps_bc)[i] <- substr(annual_names[i], 4, nchar(annual_names[i])) 
}

```

Map of BC predictions from primary analysis  

```{r}
annual_maps_bc$primary 

```

Comparison maps of BC predictions from primary and sensitivity analysis 

```{r, fig.height=15}

ggarrange(plotlist = annual_maps_bc,
          ncol = 3, nrow = 2,
          common.legend = T, legend = "right") %>%
  annotate_figure(top = "Annual average BC estimates from different methods" ) 
   
```





```{r}
# # save datasets. 
# ## annual estimates from primary and sensitivity analyses 
# saveRDS(annual, file.path("Data", "Aim 2", "Mobile Monitoring", "annual.rda"))
 
```
 