---
title: "Aim 2"
author: "Magali Blanco"
date: ' `r Sys.Date()` '
output:
  html_document:
    number_sections: yes
    df_print: paged
    toc: yes
    toc_depth: '3'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, cache=T, cache.comments = F, message = F, warning = F, tidy.opts=list(width.cutoff=60), tidy=TRUE)  

# Clear workspace of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
  res <- suppressWarnings(
    lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
      detach, character.only=TRUE, unload=TRUE, force=TRUE))
}

pacman::p_load(dplyr, tidyverse, knitr, Himsc, EnvStats, lubridate, glmnet, ggpubr, VCA)   
#Himsc: describe(); EnvStats: summaryFull(); ggpubr: ggarrange()

#set plot theme
#theme_set(theme_linedraw() + theme(legend.position="bottom")) 

source("A2.0.1_Var&Fns.R")

```

```{r}
#load stop average data 
mm <- readRDS(file.path("Data", "Aim 2", "Mobile Monitoring", "mm_191112.rda"))
mm.wide <- readRDS(file.path("Data", "Aim 2", "Mobile Monitoring", "mm.wide_191112.rda"))

mm.w.ptrak <- mm.wide %>% 
  select(
    site_id: site_lat, site_no, aqs_site:season,
    ufp_pt_noscreen_ct_cm3
  ) %>%
  #remove NAs
  drop_na(ufp_pt_noscreen_ct_cm3)

```

```{r simple avg for ACT symposium} 
# #estimate site-specific median pollutant concentrations up until now
# median.conc <- mm %>% 
#   #filter(instrument_id =="PMDISC_8") %>% 
#   group_by(site_id, site_lat, site_long, instrument_id) %>% 
#   rename(lat = site_lat, long = site_long) %>%
#   summarize(
#     median_conc = median(value)
#   )
# 
# ##estimates for specific pollutants from primary instruments
# ufp.conc <- median.conc %>%
#   filter(instrument_id == "PMDISC_8") %>%
#   rename(median_conc_ct_m3 = median_conc )
# 
# no2.conc <- median.conc %>%
#   filter(instrument_id == "NO2_2") %>%
#   rename(median_conc_ppb = median_conc )
# 
# # write.csv(ufp.conc, "ufp.conc.csv", row.names = F)
# # write.csv(no2.conc, "no2.conc.csv", row.names = F)

```

### -->	Combine 2 stops if they are “close”? We stopped sampling MS0398 and switched to MS0601 which is close

```{r}
geo <- read.csv(file.path("Data", "Aim 2", "Geocovariates", "dr0311_mobile_locations.txt")) %>%
  select("native_id", "latitude", "longitude", "m_to_a1", "m_to_a2", "m_to_coast", "m_to_l_port", "m_to_comm", "m_to_airp", "m_to_rr", "m_to_truck", "elev_elevation", "pop_s01000")
#write.csv(geo, file.path("Data", "Aim 2", "Geocovariates", "geo_few.csv"))

#"We stopped sampling MS0398 and switched to MS0601 which is close"
#t <- geo %>% filter(native_id %in% c("MS0398", "MS0601"))

```


### ? use wide format (uses avg when multiple readings exist from duplicate instruments)

# Available MM observations 
  
Lot of locations w/o observations during each season-time_of_week-time_of_day combination
 
```{r, include=F}

#counts at each location by quarter, DOW, hour bins - see how much missin data there are
#df w/ times that each stop Should have sampled
loc <- unique(mm.w.ptrak$site_id)
seasons <- unique(mm.w.ptrak$season)
dow <- unique(mm.w.ptrak$time_of_week)
hour <- unique(mm.w.ptrak$time_of_day)

loc.vec <- rep(loc, each = length(seasons)*length(dow)*length(hour))
seasons.vec <- rep(seasons, each = length(dow)*length(hour), times=length(loc))
dow.vec <- rep(dow, each = length(hour), times=length(loc)*length(seasons))
hour.vec <- rep(hour, times=length(loc)*length(seasons)*length(dow))
 
df <- data.frame(
  site_id = loc.vec,
  season = seasons.vec,
  time_of_week = dow.vec,
  time_of_day = hour.vec
)

#add unique stop variables
df <- mm.w.ptrak %>%
  select(site_id:site_no, aqs_site) %>%
  #drop_na() %>%
  unique()  %>%
  left_join(df)

#df has more rows now b/c some locations were sampled multiple times during same season-week-hour combo
avail_data <- left_join(df, mm.w.ptrak) %>%
  mutate(
    ufp_available = as.numeric(!is.na(ufp_pt_noscreen_ct_cm3))
  )

samples_per_stop <- avail_data %>% 
  group_by(route, site_id, season, time_of_week, time_of_day) %>%
  summarize(
    N = sum(ufp_available)
  )

samples_per_stop_season <- samples_per_stop %>%
    #total stops per season
    group_by(route, site_id, season) %>%
  summarize(
    N = sum(N)
  ) 

#season
samples_per_stop_season %>% 
  ggplot(aes(x=N, fill = (N==0))) + 
  geom_bar() + 
  labs(title= paste("Histograms of No. Samples per", paste0(names(samples_per_stop)[1], collapse = "-"), ""),
       x = paste0("No. Samples from stop locations (", length(unique(avail_data$site_id)), ")")
       ) + 
  facet_grid(~season) 


#season-week
samples_per_stop_season_wk <- samples_per_stop %>%
    #total stops per season
    group_by(route, site_id, season, time_of_week) %>%
  summarize(
    N = sum(N)
  ) 


# t2 <- samples_per_stop_season_wk %>%  filter(
#   season == "fall",  
#   N == 0
#   ) %>% 
#   arrange(time_of_week, route) 

#t2 %>%  write.csv("fall missing stops.csv", row.names = F)


samples_per_stop_season_wk %>% 
  ggplot(aes(x=N, fill = (N==0))) + 
  geom_bar() + 
  labs(title= paste("Histograms of No. Samples per", paste0(names(samples_per_stop)[1], collapse = "-"), ""),
       x = paste0("No. Samples from stop locations (", length(unique(mm.w.ptrak$site_id)), ")")) + 
  facet_grid(time_of_week~season) 
    
  
```

# Trim data    
### --> ?use windosirzed mean instead?  

```{r} 
untrimmed.plot <- mm.w.ptrak %>% 
  ggplot(aes(y=ufp_pt_noscreen_ct_cm3)) + 
  geom_boxplot() + #scale_y_log10() +
  labs(title = "untrimmed data")

#trip bottom and top 5% observations 
mm.w.ptrak <- mm.w.ptrak %>%
  group_by(site_id) %>%
  #trim high and low values
  filter(ufp_pt_noscreen_ct_cm3 <= quantile(ufp_pt_noscreen_ct_cm3, (1-trim_quantile), na.rm = T),
         ufp_pt_noscreen_ct_cm3 >= quantile(ufp_pt_noscreen_ct_cm3, (trim_quantile), na.rm = T))

trimmed.plot <- mm.w.ptrak %>%
  ggplot(aes(y=ufp_pt_noscreen_ct_cm3)) + 
  geom_boxplot() +
  labs(title = paste0("trimmed top and bottom ", trim_quantile*100, "% \nof data at each site" ))
  
ggarrange(untrimmed.plot, trimmed.plot ) 


# #windosrized alternative 
# mm.w.ptrak <- mm.w.ptrak %>%
#   group_by(site_id) %>%
#   mutate(
#     ufp_wind = ifelse(ufp_pt_noscreen_ct_cm3 > quantile(ufp_pt_noscreen_ct_cm3, (1-trim_quantile), na.rm = T), quantile(ufp_pt_noscreen_ct_cm3, (1-trim_quantile), na.rm = T), 
#                       ifelse(ufp_pt_noscreen_ct_cm3 < quantile(ufp_pt_noscreen_ct_cm3, (trim_quantile), na.rm = T), quantile(ufp_pt_noscreen_ct_cm3, (trim_quantile), na.rm = T), 
#                              ufp_pt_noscreen_ct_cm3)))

```


```{r example location w/ missing obs, eval=F}
## ERROR: changed data frame??? avail_data or mm.w.ptrak...?

#example location 
MC0002 <- avail_data %>%
  select(
    site_id,
    date:ufp_available
  ) %>%
  filter(site_id == "MC0002") %>%
  arrange(season, time_of_week, time_of_day)

#early_am and evening will be weighted more heavily b/c we never have sampling @ night
#


#test models
MC0002 %>%
  lm(ufp_pt_noscreen_ct_cm3 ~ time_of_day + time_of_week + season, data = .) %>%
  summary()

```

```{r lme code exp}
#mixed effecdts model
## see B540 L4 # ~57 

#can set covariance structure using nlme::lme()
#fit0 <-lme( fev1 ~ age0 + ageL + relevel(sex, ref="male")*ageL + relevel(f508, ref="none")*ageL,
#method = "ML", #best for inferences at pop/?indiv lvl 
#random = reStruct( ~ 1 + ageL | id, pdClass="pdSymm", REML=F), #random int & slope
#correlation = corAR1( form = ~ 1 | id ), ## within group corr structure
#data = cf.long )

#make predictions
#pred.fit1 <- predict(fit1)

# library(nlme)
# me1 <- mm.w.ptrak %>% 
#   #model won't run w/ missing Y's
#   drop_na(ufp_pt_noscreen_ct_cm3) %>%
#   mutate(
#     time_of_day = factor(time_of_day, ordered = F),
#     time_of_week = factor(time_of_week, ordered = F)
#     ) %>%
#   lme(ufp_pt_noscreen_ct_cm3 ~ time_of_day + time_of_week + season,
#       method = "ML", 
#       # --> add rand slope for other vars?      
#       random =  reStruct( ~ 1 + time_of_day | site_id,  #random int & slope for each site_id
#                                pdClass="pdSymm", REML=F),
#       # --> add? 
#       #correlation = corAR1( form = ~ 1 | site_id), ## within group corr structure
#             data = .) 
# 
# me1 %>% summary()
# 
# mm.w.ptrak$pred.me1 <- predict(me1, newdata = mm.w.ptrak)

#plot(residuals(me1) )
```

# Weighted Means   
? Assume temporal pattern is same across locations. Strong assumption, but can’t relax this very easily.  
  
a) calculate weighted annual avg (Mar - Oct) means using different methods to determine how sensitve estimates are to using these approaches: 
* weighted (various weights) vs unweighted
* binning hour differently 

```{r}
#drop winter values for now (drops Feb) since little data here & fewer stops meet min requirements
mm.w.ptrak <- mm.w.ptrak %>%
  filter(season != "winter")

# hist of unique times_of_day locations have sampled at 
mm.w.ptrak %>%
  ggplot(aes(x=hour)) +
  geom_bar(aes( )) + 
  labs(title = "hours sampled during mobile monitoring campaign")

#when are sites least likely to sample (inclue these gaps in other hours)
# mm.w.ptrak %>%
#   ggplot(aes(x=hour, y=site_id)) +
#   geom_point(alpha=0.05)
# 
# table(mm.w.ptrak$hour)

# New Hour Binning
mm.w.ptrak <- mm.w.ptrak %>%
  mutate(
     #? add tod w/ more categories?
    
    tod5 = factor(ifelse(hour %in% seq(3,8), "3_8",
                                       ifelse(hour %in% seq(9,11), "9_11", 
                                              ifelse(hour %in% seq(12,15), "12_15",
                                                     ifelse(hour %in% seq(16,20), "16_20", "21_2")))),
                         levels= c("3_8", "9_11", "12_15", "16_20", "21_2")),
  
    tod3 = factor(ifelse(hour %in% seq(0,8), "0_8",
                                       ifelse(hour %in% seq(9,15), "9_15", "16_23")),
                         levels= c("0_8", "9_15", "16_23")),
    tod2 = factor(ifelse(hour %in% seq(0,11), "0_11", "12_23"),
                         levels= c("0_11", "12_23"))
    )

```

### --> recalculate means @ individual level (don't group first). don't group_by() all temporal variables at once (inclde as long a site has a measurement during all seasons, TOW, TOD even if not necessarily together) 

#### -->  has Hank done this?
 
```{r}
#calc diff summary measures
mm.w.ptrak <- mm.w.ptrak %>%
  group_by(site_id) %>%
  #unweighted mean
  mutate(mean_uw = round(mean(ufp_pt_noscreen_ct_cm3)))









#means by seaason-wk-tod5 (5 tods)
   #there are no sites w/ sampling during all 30/40 unique times (5 tod x 2 tow x 3 or 4 seasons)
s_tow2_tod5 <- mm.w.ptrak %>%
  group_by(site_id, season, time_of_week, tod5) %>%
  dplyr::summarize(mean = mean(ufp_pt_noscreen_ct_cm3)) %>%
  ungroup() %>%
  unite("swh", season:tod5, remove = F) %>%
  group_by(site_id) %>%
  mutate(unique_times = n_distinct(swh)) 
rm(s_tow2_tod5)

#means by seaason-wk-tod3 (3 tods)
   #there are no sites w/ sampling during all 18/24 unique times (3 tod x 2 tow x 3/4 seasons)
s_tow2_tod3 <- mm.w.ptrak %>%
  group_by(site_id, season, time_of_week, tod3) %>%
  dplyr::summarize(mean = mean(ufp_pt_noscreen_ct_cm3)) %>%
  ungroup() %>%
  unite("swh", season:tod3, remove = F) %>%
  group_by(site_id) %>%
  mutate(unique_times = n_distinct(swh)) 
rm(s_tow2_tod3)

#means by seaason-wk-tod2 (2 tods)
   #8 sites w/ sampling during all 12 unique times (2 tod x 2 tow x 3 seasons)
   #none when looking at all 4 seasons
s_tow2_tod2 <- mm.w.ptrak %>%
  group_by(site_id, season, time_of_week, tod2) %>%
  dplyr::summarize(mean = mean(ufp_pt_noscreen_ct_cm3)) %>%
  ungroup() %>%
  unite("swh", season:tod2, remove = F) %>%
  #calc number of unique sampling times 
  group_by(site_id) %>%
  mutate(unique_times = n_distinct(swh)) %>%
  #only incude locations with every season, TOW, TOD
  filter(unique_times ==12)

#tod2_df %>% select(site_id) %>% n_distinct()

## using tod2, caclulate weighted mean for 8 sites w/ obs during all time combinations
s_tow2_tod2 <- s_tow2_tod2 %>%
  mutate(
    season.wt = 1/length(unique(season)),
    wk.wt = ifelse(time_of_week == "weekday", 5/7, 2/7),
    tod.wt = ifelse(tod2 == "0_11", 12/24, 12/24),
    wt = season.wt * wk.wt * tod.wt,
    wt_times_mean = wt*mean) %>% 

# #check that weights for all sites = 1. #looks good
# s_tow2_tod2 %>%
#   group_by(site_id) %>%
#   summarize(n = sum(wt))
  
  #calculate each site's weighted mean
  group_by(site_id) %>%
  dplyr::summarize(mean_wt = sum(wt_times_mean))
  

#means by season-wk7 (2 tods)
   #no sites w/ sampling during all 42/56 unique times (2 tod x 7 tow x 3/4 seasons)
s_tow7_tod2 <- mm.w.ptrak %>%
  group_by(site_id, season, day, tod2) %>%
  dplyr::summarize(mean = mean(ufp_pt_noscreen_ct_cm3)) %>%
  ungroup() %>%
  unite("swh", season:tod2, remove = F) %>%
  #calc number of unique sampling times 
  group_by(site_id) %>%
  mutate(unique_times = n_distinct(swh))  
  #only incude locations with every season, TOW 
rm(s_tow7_tod2)

#no tod
   # no site w/ 21/28 unique times (3/4 seasons x 7 days)
s_tow7 <- mm.w.ptrak %>%
  group_by(site_id, season, day) %>%
  dplyr::summarize(mean = mean(ufp_pt_noscreen_ct_cm3)) %>%
  ungroup() %>%
  unite("swh", season:day, remove = F) %>%
  #calc number of unique sampling times 
  group_by(site_id) %>%
  mutate(unique_times = n_distinct(swh))
rm(s_tow7)

   # 219 sites w/ sampling during all 6 unique times (2 tow x 3 seasons)
   # 65 sites w/ sampling 8 unique times (2 two x 4 seasons)
s_tow2 <- mm.w.ptrak %>%
  group_by(site_id, season, time_of_week) %>%
  dplyr::summarize(mean = mean(ufp_pt_noscreen_ct_cm3)) %>%
  ungroup() %>%
  unite("swh", season:time_of_week, remove = F) %>%
  #calc number of unique sampling times 
  group_by(site_id) %>%
  mutate(unique_times = n_distinct(swh)) %>%
  #only incude locations with every season, TOW, TOD
  filter(unique_times ==6) %>%
#no_tod_df %>% select(site_id) %>% n_distinct()
#  caclulate weighted mean for sites w/ obs during all time combinations
  mutate(
    season.wt = 1/length(unique(season)),
    wk.wt = ifelse(time_of_week == "weekday", 5/7, 2/7),
    wt = season.wt * wk.wt,
    wt_times_mean = wt*mean) %>%
  #calculate each site's weighted mean
  group_by(site_id) %>%
  dplyr::summarize(mean_wt = sum(wt_times_mean))


# month tow2
#    no sites w/ 18 unique times (9 mo x 2 tow)
m_tow2 <- mm.w.ptrak %>%
  group_by(site_id, month, time_of_week) %>%
  dplyr::summarize(mean = mean(ufp_pt_noscreen_ct_cm3)) %>%
  ungroup() %>%
  unite("swh", month:time_of_week, remove = F) %>%
  #calc number of unique sampling times 
  group_by(site_id) %>%
  mutate(unique_times = n_distinct(swh)) #%>%
rm(m_tow2)


#season
   # 305 sites w/ sampling during all 3 seasons
s <- mm.w.ptrak %>%
  group_by(site_id, season) %>%
  dplyr::summarize(mean = mean(ufp_pt_noscreen_ct_cm3)) %>%
  #calc number of unique sampling times 
  group_by(site_id) %>%
  mutate(unique_times = n_distinct(season)) %>%
  #only incude locations with every season, TOW, TOD
  filter(unique_times ==3) %>%
#no_tod_df %>% select(site_id) %>% n_distinct()
#  caclulate weighted mean for sites w/ obs during all time combinations
  mutate(
    season.wt = 1/3,
    wt_times_mean = season.wt*mean) %>%
  #calculate each site's weighted mean
  group_by(site_id) %>%
  dplyr::summarize(mean_wt = sum(wt_times_mean))

#month-weighted avg
   # 309 sites. some sites have more months sampled than others
m.diff_no_months <- mm.w.ptrak %>%
  group_by(site_id, month) %>%
  dplyr::summarize(mean = mean(ufp_pt_noscreen_ct_cm3)) %>%
  #calc number of unique sampling times 
  group_by(site_id) %>%
  mutate(unique_times = n_distinct(month)) %>% 
#  caclulate weighted mean for sites w/ obs during all time combinations
  mutate(
    wt_times_mean = mean /unique_times) %>%
  #calculate each site's weighted mean
  group_by(site_id) %>%
  dplyr::summarize(mean_wt = sum(wt_times_mean))
 
#month-weighted avg
   # 101 sites w/ all months sampled 

#locations w/ samples Mar - Nov
months.sampled <- month.abb[3:11]

m.same_months <- mm.w.ptrak %>%
  group_by(site_id, month) %>%
  dplyr::summarize(mean = mean(ufp_pt_noscreen_ct_cm3)) %>%
  filter(month %in% months.sampled) %>%
  #calc number of unique sampling times 
  group_by(site_id) %>%
  mutate(unique_times = n_distinct(month)) %>% 
  filter(unique_times == length(months.sampled)) %>%
#  caclulate weighted mean for sites w/ obs during all time combinations
  mutate(
    wt_times_mean = mean /length(months.sampled)) %>%
  #calculate each site's weighted mean
  group_by(site_id) %>%
  dplyr::summarize(mean_wt = sum(wt_times_mean))


```

## Plots

compare inter-method mean estimates 

```{r, include=F}
#join all estimates
annual <- mm.w.ptrak %>%
  select(site_id, route, mean_uw) %>%
  unique() %>%
  left_join(s_tow2_tod2) %>%
  rename(mean_sea_tow2_tod2 = mean_wt) %>%
  left_join(s_tow2) %>%
  rename(mean_sea_tow2 = mean_wt) %>%
  left_join(s) %>%
  rename(mean_sea = mean_wt) %>%
  # don't include these b/c these are fundamentally different? e.g., some sites have few months
  # left_join(m.diff_no_months) %>%
  # rename(mean_m.diff_no_months = mean_wt) %>%
  left_join(m.same_months) %>%
  rename(mean_mo = mean_wt)  

annual.l <- annual %>%
  gather(key = "method", value = "ufp", -site_id, -route) %>%
  drop_na()

#plot of number of locations that met criteria for estimating means 
annual.l %>%
  ggplot(aes(x=method)) + 
  geom_bar() + 
  labs(title = "no. sites with mean/median estimates using various methods")


```


```{r, fig.height = 8}
#estimates for 19 locations with all estimation methods
annual %>% ufp_by_method(dt = .)

  ## compare to a ref method
comp_to_tod2 <- annual %>%
  mutate(
    #look at difference in estimates from "best" estimate
    mean_uw = mean_uw - mean_sea_tow2_tod2,
    mean_sea_tow2 = mean_sea_tow2 - mean_sea_tow2_tod2,
    mean_sea = mean_sea - mean_sea_tow2_tod2,
    mean_mo = mean_mo - mean_sea_tow2_tod2,
  ) %>%
  select(-mean_sea_tow2_tod2) 

comp_to_tod2 %>% ufp_by_method(., 
                add.to.title = "relative to mean_sea_tow2_tod2")
  
 ## table of mean difference
# comp_to_tod2 %>%
#   gather("method", "value", -site_id, -route) %>%
#   group_by(method) %>%
#   summarize(
#     mean_diff = round(mean(value, na.rm=T)),
#     median_diff = round(median(value, na.rm=T))) %>%
#   arrange(desc(median_diff)) %>%
#   kable(caption = "Estimate difference relative to mean_sea_tow2_tod2")

##############
#estimates for locations w/ 5+ estimation methods (not considering tod)
annual %>% select(-mean_sea_tow2_tod2) %>%
  ufp_by_method(dt=.)
 
  ## compare to ref mean_sea_tow2
comp_to_tow2 <- annual %>%
  mutate(
    #look at difference in estimates from "best" estimate
    mean_uw = mean_uw - mean_sea_tow2,
    mean_sea = mean_sea - mean_sea_tow2,
    mean_mo = mean_mo - mean_sea_tow2,
  ) %>%
  select(-mean_sea_tow2_tod2, 
         -mean_sea_tow2,
         # -mean_uw,
         ) 

comp_to_tow2 %>% ufp_by_method(., add.to.title = "relative to mean_sea_tow2")

# comp_to_tow2 %>%
#   gather("method", "value", -site_id, -route) %>%
#   group_by(method) %>%
#   summarize(
#     mean_diff = round(mean(value, na.rm=T)),
#     median_diff = round(median(value, na.rm=T))) %>%
#   arrange(desc(median_diff)) %>%
#   kable(caption = "Estimate difference relative to mean_sea_tow2")


```


```{r}
# TOD2
tod2 <- annual %>%
  drop_na()  

tod2$min <- apply(tod2[,c(3:7)], 1, function(x)  range(x)[1])  
tod2$max <- apply(tod2[,c(3:7)], 1, function(x)  range(x)[2])  
tod2$diff <- apply(tod2[,c(3:7)], 1, function(x)  diff(range(x)))  

tod2 <- tod2 %>%
  left_join(unique(mm[c("site_id", "m_to_a1", "m_to_a2", "m_to_airp", "m_to_l_port", "m_to_rr", "m_to_truck", "elev_elevation", "pop_s01000")]))

tod2$m_to_a1_a2 <- apply(tod2[c("m_to_a1", "m_to_a2")], 1, min)

# tod2.lm1 <- tod2 %>% lm(diff ~ m_to_a1_a2 +
#        m_to_airp + #m_to_l_port + 
#        m_to_rr + #m_to_truck + 
#          elev_elevation + 
#        pop_s01000, 
#        data = .) 
# 
# tod2.lm1 %>% summary()
# #anova(tod2.lm1)  #almost identical to: summary.aov(movup.lm2)

# tod2 %>%
#     ggplot(aes(x=site_id, y= diff, col = elev_elevation)) + 
#     geom_point(aes()) + 
#     theme(axis.text.x = element_text(angle = 90))   


# TOW2
tow2 <- annual %>%
  select(-mean_sea_tow2_tod2) %>%
  drop_na()  

tow2$min <- apply(tow2[,c(3:ncol(tow2))], 1, function(x)  range(x)[1])  
tow2$max <- apply(tow2[,c(3:ncol(tow2))], 1, function(x)  range(x)[2])  
tow2$diff <- apply(tow2[,c(3:ncol(tow2))], 1, function(x)  diff(range(x)))  

tow2 <- tow2 %>%
  left_join(unique(mm[c("site_id", "m_to_a1", "m_to_a2", "m_to_airp", "m_to_l_port", "m_to_rr", "m_to_truck", "elev_elevation", "pop_s01000")]))

tow2$m_to_a1_a2 <- apply(tow2[c("m_to_a1", "m_to_a2")], 1, min)


```


## ANOVA & LS: method vs site effect
   
- most variation comes from site, tiny (but significant) amount from estimation method
- mean_mo and mean_sea estimates significantly lower than two2 and tow2_tod2
- 


```{r, include=T}
# text: "Anova for Sea_TOW2_TOD2"
 
#ANOVA for TOD2
tod2.anova <- tod2 %>%
  select(site_id:mean_mo) %>%
  gather("method", "value", -site_id, -route)  

anovaVCA(value ~ method + site_id, Data=as.data.frame(tod2.anova))

tod2.lm1a <- tod2.anova %>%                               #mean_sea_tow2_tod2
  mutate(method = relevel(factor(method, ordered = F), ref = "mean_uw")) %>% 
  lm(value ~ method + site_id, data = .)

anova(tod2.lm1a) %>% kable()
summary(tod2.lm1a)
#CI
confint(tod2.lm1a)[c(1:5),]


```

Anova for Sea_TOW2

```{r, eval=T}
#ANOVA for TOW2
tow2.anova <- tow2 %>%
  select(site_id:mean_mo) %>%
  gather("method", "value", -site_id, -route) %>%
  ungroup() %>%
  mutate(
    method = as.factor(method),
    site_id = as.factor(site_id)) %>%
  as.data.frame()

anovaVCA(value ~ method + site_id, Data = tow2.anova)


tow2.lm1a <- tow2.anova %>% #mean_sea_tow2
  mutate(method = relevel(factor(method, ordered = F), ref = "mean_uw")) %>% 
  lm(value ~ method + site_id, data = .)

anova(tow2.lm1a) %>% kable()
summary(tow2.lm1a)
#CI
confint(tow2.lm1a)[c(1:4),]

```


## Compare site with high vs low inter-method variability

See whic sites have large differences between diff estimation methods.      
- sites w/ high inter-method variabiitly have high extreme values, while those w/ low inter-method variability have either: a) no or b) both high and low extreme values

Compare sites w/ estimates that vary a lot vs those that vary little  
-those that vary more are closer to sources? 

```{r, include=T}
#plots looking at which sites have largest diff btwn estimates
extremes <- 0.25

tod.2.high <- tod2 %>%
  filter(diff > quantile(tod2$diff, (1-extremes)))

tod.2.low <- tod2 %>%
  filter(diff < quantile(tod2$diff, extremes))


#RAW values for high/low values - are there any extreme values? 
#high range of values
h <- mm.w.ptrak %>%
  filter(site_id %in% unique(tod.2.high$site_id)) %>% 
  mutate(diff_lvl = "high")
l <- mm.w.ptrak %>%
  filter(site_id %in% unique(tod.2.low$site_id)) %>% 
  mutate(diff_lvl = "low")
h.l <- rbind(h, l) %>%
  ungroup()

h.l %>%
  ggplot(aes(x=ufp_pt_noscreen_ct_cm3)) +
  geom_density(aes(fill = diff_lvl), alpha=0.5) + 
  labs(subtitle = paste("Sea_TOW2_TOD2, n =", length(unique(h.l$site_id))))


```

```{r, fig.height=8}
h.l %>%
  ggplot(aes(x=site_no, y= ufp_pt_noscreen_ct_cm3, fill=factor(diff_lvl),  col=route, group=site_no)) + 
  geom_boxplot() +
  scale_x_continuous(breaks=h.l$site_no, labels=h.l$site_id) + 
  theme(axis.text.x = element_text(angle = 90)) + 
  labs(title = "Sites with 'high' and 'low' inter-method variability. \nX-asis is arranged by stop order.", 
       subtitle = paste("Sea_TOW2_TOD2, n =", length(unique(h.l$site_id))))

```

```{r}
# tow2.lm1 <- tow2 %>% lm(diff ~ m_to_a1_a2 +
#        m_to_airp + #m_to_l_port + 
#        m_to_rr + m_to_truck + 
#          elev_elevation, #+ 
#        #pop_s01000, 
#        data = .) 
# 
# tow2.lm1 %>% summary()
# 
# anova(tow2.lm1)  #almost identical to: summary.aov(movup.lm2)

# tow2 %>%
#     ggplot(aes(x=site_id, y= diff, col = m_to_truck/100)) + 
#     geom_point(aes()) + 
#     theme(axis.text.x = element_text(angle = 90)) 

#sites w/ most/least variability in estimates
tow.2.high <- tow2 %>%
  filter(diff > quantile(tow2$diff, (1-extremes)))
tow.2.low <- tow2 %>%
  filter(diff < quantile(tow2$diff, extremes))



#RAW values for high/low values - are there any extreme values?
#high range of values
h.tow2 <- mm.w.ptrak %>%
  filter(site_id %in% unique(tow.2.high$site_id)) %>%
  mutate(diff_lvl = "high")
l.tow2 <- mm.w.ptrak %>%
  filter(site_id %in% unique(tow.2.low$site_id)) %>%
  mutate(diff_lvl = "low")
h.l.tow2 <- rbind(h.tow2, l.tow2)

#density/box plots for UFP  
h.l.tow2 %>%
  ggplot(aes(x=ufp_pt_noscreen_ct_cm3)) +
  geom_density(aes(fill = diff_lvl), alpha=0.5) +
  labs(subtitle = paste("Sea_TOW2, n =", length(unique(h.l.tow2$site_id))))


```


```{r, fig.height=8}
h.l.tow2 %>%
  ggplot(aes(x=site_no, y= ufp_pt_noscreen_ct_cm3, fill=factor(diff_lvl), group=site_no)) + 
  geom_boxplot() +
  scale_x_continuous(breaks=h.l.tow2$site_no, labels=h.l.tow2$site_id) + 
  theme(axis.text.x = element_text(angle = 90)) +
  facet_wrap(~route, scales="free_x") +
  labs(title = "Sites with 'high' and 'low' inter-method variability. \nX-asis is arranged by stop order.",
       subtitle = paste("Sea_TOW2, n =", length(unique(h.l.tow2$site_id))))

```

Density plots by geocovariates

```{r, include=T}
#tod
tod.2.high$diff_lvl <- "high"
tod.2.low$diff_lvl <- "low"
tod.2.high.low <- rbind(tod.2.high, tod.2.low) 

tod.2.high.low %>%
  gather("geocov", "value", m_to_airp:m_to_a1_a2) %>%
  ggplot(aes(x = value, fill = factor(diff_lvl))) +
  geom_density(alpha=0.5) +
  facet_wrap(~geocov, scales="free") +
  labs(subtitle = paste("Sea_TOW2_TOD2, n =", length(unique(tod.2.high.low$site_id))))

```

```{r}
#tow
tow.2.high$diff_lvl <- "high"
tow.2.low$diff_lvl <- "low"
tow.2.high.low <- rbind(tow.2.high, tow.2.low) 

tow.2.high.low %>%
  gather("geocov", "value", m_to_airp:m_to_a1_a2) %>%
  ggplot(aes(x = value, fill = factor(diff_lvl))) +
  geom_density(alpha=0.5) +
  facet_wrap(~geocov, scales="free") +
  labs(subtitle = paste("Sea_TOW2, n =", length(unique(tow.2.high.low$site_id))))
# #same but boxplots
# tow.2.high.low %>%
#   gather("geocov", "value", m_to_airp:m_to_a1_a2) %>%
#   ggplot(aes(y = value, x = factor(diff_lvl), fill= diff_lvl)) +
#   geom_boxplot() +
#   facet_wrap(~geocov, scales="free")

```


# ? Rank Order
 
?? "rank order" - are coefficients similar across models, at least in sign (+/-)?

? more varibility in UFP estimates at places w/ more direct sources? (Bossche 2015)

Models comparing various methods of estimating central tendency using sites w/ season-TOW2-TOD2 estimates.

```{r, include=T}
# # compare to tod2  
# comp_to_tod2 <- comp_to_tod2 %>%
#   drop_na() %>%
#   left_join(unique(mm[c("site_id", "m_to_a1", "m_to_a2", "m_to_airp", "m_to_l_port", "m_to_rr", "m_to_truck", "elev_elevation",  "pop_s01000")]))
# 
# comp_to_tod2$m_to_a1_a2 <- apply(comp_to_tod2[c("m_to_a1", "m_to_a2")], 1, min)

#mea_sea_tow2_tod2
 tod2 %>% lm(mean_sea_tow2_tod2 ~ m_to_a1_a2 +  
       m_to_airp + m_to_rr + elev_elevation + pop_s01000,
       data = .) %>%
  summary()
 
 #mea_sea_tow2
 tod2 %>% lm(mean_sea_tow2 ~ m_to_a1_a2 +  
       m_to_airp + m_to_rr + elev_elevation + pop_s01000,
       data = .) %>%
  summary()

#mean_mo
tod2 %>% lm(mean_mo ~ m_to_a1_a2 +  #m_to_truck + 
       m_to_airp + m_to_rr + elev_elevation + pop_s01000,
       data = .) %>%
  summary()

#mean_sea
tod2 %>% lm(mean_sea ~ m_to_a1_a2 +  #m_to_truck + 
       m_to_airp + m_to_rr + elev_elevation + pop_s01000,
       data = .) %>%
  summary()

#mean_uw
tod2 %>% lm(mean_uw ~ m_to_a1_a2 +  #m_to_truck + 
       m_to_airp + m_to_rr + elev_elevation + pop_s01000,
       data = .) %>%
  summary()

 
```

Models comparing various methods of estimating central tendency using sites w/ season and TOW2 estimates.

```{r}
# comp_to_tow2 <- comp_to_tow2 %>%
#   drop_na() %>%
#   left_join(unique(mm[c("site_id", "m_to_a1", "m_to_a2", "m_to_airp", "m_to_l_port", "m_to_rr", "m_to_truck", "elev_elevation",  "pop_s01000")]))
# 
# comp_to_tow2$m_to_a1_a2 <- apply(comp_to_tow2[c("m_to_a1", "m_to_a2")], 1, min)

 #mea_sea_tow2
 tow2 %>% lm(mean_sea_tow2 ~ m_to_a1_a2 +  
       m_to_airp + m_to_rr + elev_elevation + pop_s01000,
       data = .) %>%
  summary()

#mean_mo
tow2 %>% lm(mean_mo ~ m_to_a1_a2 +  #m_to_truck + 
       m_to_airp + m_to_rr + elev_elevation + pop_s01000,
       data = .) %>%
  summary()

#mean_sea
tow2 %>% lm(mean_sea ~ m_to_a1_a2 +  #m_to_truck + 
       m_to_airp + m_to_rr + elev_elevation + pop_s01000,
       data = .) %>%
  summary()

#mean_uw
tow2 %>% lm(mean_uw ~ m_to_a1_a2 +  #m_to_truck + 
       m_to_airp + m_to_rr + elev_elevation + pop_s01000,
       data = .) %>%
  summary()


```

### --> compare diff method model predictions at each site (who do the predictions vary?)
- use ~67 sites 
- make scaterplot: Y: predictions, x: ?sites
 - ?? look at R2, RMSE ??
 
```{r}

```



# Temporal effects on mean estimates

### --> 
How do the seasonal/TOW/TOD effects impact annual mean UFP estimates relative to the method effects (~100-200 pt/cm3)
-do this on 19 sites  [repeate what I’ve done before] using the individual level data (not the avg data)
- Y ~ season + tow + tod + site_id 
 
- if temporal effects are larger than effect of method, we need to weigh by that variable. If there’s not big differences by season, we don’t need to worry as much (What we’re really worried about is TOD)

```{r}

```



 
# Compare trimmed means at AQS sites  
if have 6 months of data, compare to the 6-mo estimate at AQS sites

```{r}
# repeat above w/ BC & compare to AQS site readings? is this data on server? 

```

