---
title: "Aim 2: UK Models using PLS"
author: "Magali Blanco"
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: yes
    df_print: paged
    toc: yes
    toc_depth: '3'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: console
---

```{r}
# --> TO DO

### -->[EDIT LATER] KEEPING pop_ FOR NOW UNTIL RECEIVE pop10_ from amanda

# --> ?add new variables from Aim 3 (e.g., emission estimates)? 
## --> ? see ultra UFPs & size distribution?
# ? --> switch from geoR to ___ 

```

# Summary of Script

**Approach**    

1. Split up the data (~ 308 locations) into a validation (10%) and a training/test (90%) set.

2. Conduct cross-validation using the training/test set to select the number of PLS components and variogram plotting distance for UK.

3. Fit a semi-final model to all of the training and test set data with the selected parameters. Use this model to estimate the out-of-sample model performance on the validation set.

4. Fit a final model to all of the data & Predict at ACT participant locations
* plot PLS component loadings to characterize the covariates and buffer sizes most heavily weighted in the PLS scores
* compared distribution of PLS scores between the monitoring locations and various ACT locations within monitoring, “study” and spatiotemporal modeling area, as well as nationwide    
* decompose the UK predictions into the LUR vs UK piece

6. Repeate for various sensitivity analyses.

7. Map predictions in study area using a grid

8. Additional analyses

* Lasso regression to identify a few covariates most associated w/ pollutants

# Analyses  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, 
                      cache=T, cache.comments = F, 
                      message = F, warning = F, 
                      tidy.opts=list(width.cutoff=60), tidy=TRUE,
                      fig.height = 5, fig.width = 8
                      )  

# Clear workspace of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
  res <- suppressWarnings(
    lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
      detach, character.only=TRUE, unload=TRUE, force=TRUE))
}

pacman::p_load(knitr, kableExtra, 
               #descriptive statistics
               Hmisc, EnvStats, 
               # modeling
               pls, geoR, #gstat - alternative for UK
               akima, # interp() - interpolate predictions on map
               ggpubr, tidyverse  
               )    
#Himsc: describe(); EnvStats: summaryFull(); ggpubr: ggarrange()

set.seed(1)

options(knitr.kable.NA = '')
source("0.Global_Fns.R")
source("A2.0.1_Var&Fns.R")

# act geocovariates
cov_act <- readRDS(file = file.path("Data", "Aim 2", "Geocovariates", "cov_act_preprocessed.rda"))

# all annual estimates
annual0 <- readRDS(file.path("Data", "Aim 2", "Mobile Monitoring", "annual_2020-03-17.rda")) %>%
  # filter for now since don't have covariates for this site yet
  filter(site_id != "MS0601")

#covariates
### -->[EDIT LATER] KEEPING pop_ FOR NOW UNTIL RECEIVE pop10_ from amanda
cov_mm <- readRDS(file.path("Data", "Aim 2", "Geocovariates", "cov_mm_preprocessed.rda")) %>%
  select(#-contains("pop_"), 
         -contains("pop90_"))

site_loc_vars <- cov_mm %>%select(site_id:lambert_y) %>% names()

#variable names in log and native scale
non_proximity_vars <- names(cov_mm)[!grepl("m_to_", names(cov_mm)) & !names(cov_mm) %in% site_loc_vars]
proximity_vars_log <- names(cov_mm)[grepl("m_to_", names(cov_mm))]
proximity_vars_native <- str_replace(string = proximity_vars_log, pattern = "log_", replacement = "")
cov_names_log <- append(non_proximity_vars, proximity_vars_log)
cov_names_native <- append(non_proximity_vars, proximity_vars_native)

proximity_vars_native <- cov_mm %>%
  select(site_id, proximity_vars_log) %>%
  mutate_at(proximity_vars_log, ~exp(.)) %>%
  rename_at(proximity_vars_log, ~sub(x = ., "log_", ""))

annual <- annual0 %>%
  #convert to log
  mutate_at(vars(contains(c("ufp", "bc"))), ~log(.)) %>%
  mutate(
    ufp_native_scale = exp(ufp_primary),
    bc_native_scale = exp(bc_primary)) %>%
  left_join(cov_mm) %>%
  # add native scale proximity variables
  left_join(proximity_vars_native)

ufp_names <- names(annual)[grepl("ufp", names(annual))]
bc_names <- names(annual)[grepl("bc", names(annual))]
analysis_names <- c(ufp_names, bc_names)

# add native proximity variables to act
proximity_vars_native_act <- cov_act %>%
  select(site_id, proximity_vars_log) %>%
  mutate_at(proximity_vars_log, ~exp(.)) %>%
  rename_at(proximity_vars_log, ~sub(x = ., "log_", ""))

cov_act_all <- left_join(cov_act, proximity_vars_native_act)

# group ACT locations by area
monitoring_ids <- cov_act_all$site_id[grepl("monitoring", cov_act_all$site_location)] 

## index for sites outside monitoring area but within: study, ST, US
outside_monitoring_in_study_ids <- cov_act_all$site_id[grepl("study", cov_act_all$site_location)] 
outside_monitoring_in_st_ids <- cov_act_all$site_id[grepl("study|st", cov_act_all$site_location)]
outside_monitoring_ids <-  cov_act_all$site_id[!grepl("monitoring", cov_act_all$site_location)]

study_ids <- append(monitoring_ids, outside_monitoring_in_study_ids)
st_ids <- append(monitoring_ids, outside_monitoring_in_st_ids)


## ACT cov for primary analysis
cov_act <- cov_act_all %>% filter(site_id %in% study_ids)

## ACT cov for sensitivity analyses 
#cov_act_monitoring <- cov_act_all %>% filter(site_id %in% monitoring_ids)
#cov_act_st <- cov_act_all %>% filter(site_id %in% st_ids)

##########################
# create validation index
validation_idx <- sample(c(TRUE, FALSE), replace = T,  
                         size = nrow(annual), 
                         prob = c(.1, .9))

```

```{r}
# grid in study area (from GIS) 
grid_in_study <- read.csv(file.path("..", "GIS", "Shapefiles", "Study area", "grid", "grid_mm.csv")) %>%
  filter(study) %>%
  select(native_id)  

grid_in_study <- grid_in_study$native_id

# grid cov
grid_covars <- readRDS(file = file.path("Data", "Aim 2", "Geocovariates", "cov_grid_preprocessed.rda")) %>%
  # only keep points in study area-land (grid isn't large enough for st area)
  filter(site_id %in% grid_in_study)
  
```

Description of analyses 

### --> add ACT locations in study area sensitivity analysis

```{r}
as.data.frame(
  analysis_names) %>%
  label_analysis(var = "analysis_names") %>%
  select(Analysis) %>%
  unique() %>%
  cbind(Description = c("Using stop medians; trimming 5% of each site's highest and lowest stop concentrations; using regression to estimate season-, TOW2- and TOD5-adjusted annual avg concentrations; modeling log-transformed concentrations and proximity covariates (e.g., distance to...)",
             "Like Primary analysis, but using stop means (vs medians) to estimate annual averages",
             "Like Primary analysis, but trimming 10% of each site's highest and lowest stop concentrations (vs 5%) before estimating annual averages",
             "Like Primary analysis, but Windsorizing each site's highest and lowest 5% stop concentrations (vs trimming) before estimating annual averages",
             "Like Primary analysis, but calculating unweighted annual averages for each site (vs regression estimates adjusted for season-, time-of-week- and time-of-day)",
             "Like Primary analysis, but modeling annual average concentrations and proximity covariates on the native scale (vs log-transformed)"
             )) %>%
  kable(., caption = "Description of primary and sensitivity analyses") %>%
  kable_styling()

```

Cross-validation parameters considered.

```{r, echo = T}
fast <- T

if (fast == FALSE) {
    k <- 10
    pls_comps. <- c(1:5)  
    dist_fract. <- c(0.05, seq(0.1, 0.4, by=0.1))
  } else {
    k <- 2
    pls_comps. <- c(1:2)
    dist_fract. <- c(seq(0.1, 0.2, by=0.1))
  }

```

```{r}
data.frame(
  Parameter = c("PLS Components",
        "Variogram Distance Fraction"),
  Options_Considered = c(paste0(1, "-", max(pls_comps.)),
                         paste0(dist_fract., collapse = ", "))) %>% 
  kable(caption = "UK model parameters selected through CV") %>%
  kable_styling()

```
 
# CV 

PLS components and variogram distance fraction selected via cross-validation on the train/test set (90% of the data).

```{r, results="hide"}
cv_each_combo <- data.frame()

for (i in seq_along(analysis_names)) {
  #i=12
  # non-nataive scale analyses
  if(!grepl("native_scale", analysis_names[i])) {
    df_cv <-  pls_uk_cv_eval(dt2 = annual[!validation_idx,],
                   pls_comps = pls_comps.,
                   dist_fract = dist_fract., 
                   y_name.. = analysis_names[i],
                   k. = k,
                   # diff than if statement below
                   cov_names.. = cov_names_log, 
                   exponentiate_obs_and_pred = T)
    
    # save individual PLS-variogram results
    each_combo <- df_cv$cv_table %>%
      mutate(Analysis = analysis_names[i])
    
    cv_each_combo <- rbind(cv_each_combo, each_combo)
  }
  
  #native scale analyses
  if(grepl("native_scale", analysis_names[i])) {
    df_cv <-  pls_uk_cv_eval(dt2 = annual[!validation_idx,],
                   pls_comps = pls_comps.,
                   dist_fract = dist_fract., 
                   y_name.. = analysis_names[i],
                   k. = k,
                   # diff than if statement above
                   cov_names.. = cov_names_native,
                   exponentiate_obs_and_pred = F)
    
    # save individual PLS-variogram results
    each_combo <- df_cv$cv_table %>%
      mutate(Analysis = analysis_names[i])
    
    cv_each_combo <- rbind(cv_each_combo, each_combo)
    }
}

### --> ? replace cv_each_combo above w/ cv_results?
cv_results <- cv_each_combo

```


```{r}
# cv_results %>%
#   # relable analysis variable
#   label_analysis(var = "Analysis") %>%
#   kable(caption = "PLS components and variogram parameters selected via cross-validation for primary and sensitivity analyses", 
#         col.names = c("Pollutant", "Analysis", "PLS Components", "Variogram Plotting Max Dist Fraction", "Variogram Plotting Dist (m)", "CV RMSE", "CV R2"),
#         digits = 2) %>%
#   kable_styling() %>%
#   add_footnote("MSE-based R2")

```

```{r, results = "hide", eval=F}
# don't include this for now to simplify analyses 

### Using the same PLS components & distance fractions as primary analysis

cv_primary_pls_comp_ufp <- cv_results$PLS_Components[grepl("ufp_primary", cv_results$Analysis)]
cv_primary_dist_frac_ufp <- cv_results$Variogram_Distance_Fraction[grepl("ufp_primary", cv_results$Analysis)]

cv_primary_pls_comp_bc <- cv_results$PLS_Components[grepl("bc_primary", cv_results$Analysis)]
cv_primary_dist_frac_bc <- cv_results$Variogram_Distance_Fraction[grepl("bc_primary", cv_results$Analysis)]

#no need to change anything below for other pollutants
cv_each_combo <- data.frame()

for (i in seq_along(analysis_names)) {
  #i=7
  
  # use CV-selected PLS & variogram parameters for each pollutant
  if(grepl("ufp", analysis_names[i])) {
    cv_primary_pls_comp <- cv_primary_pls_comp_ufp
    cv_primary_dist_frac <- cv_primary_dist_frac_ufp
  }
  if(grepl("bc", analysis_names[i])) {
    cv_primary_pls_comp <- cv_primary_pls_comp_bc
    cv_primary_dist_frac <- cv_primary_dist_frac_bc
  }
  
  # non-nataive scale analyses
  if(!grepl("native_scale", analysis_names[i])) {
    df_cv <-  pls_uk_cv_eval(dt2 = annual[!validation_idx,],
                   pls_comps = cv_primary_pls_comp,
                   dist_fract = cv_primary_dist_frac, 
                   y_name.. = analysis_names[i],
                   k. = k,
                   # diff than if statement below
                   cov_names.. = cov_names_log, 
                   exponentiate_obs_and_pred = T)
    
    # save individual PLS-variogram results
    each_combo <- df_cv$cv_table %>%
      mutate(Analysis = analysis_names[i])
    
    cv_each_combo <- rbind(cv_each_combo, each_combo)
  }
  
  #native scale analyses
  if(grepl("native_scale", analysis_names[i])) {
    df_cv <-  pls_uk_cv_eval(dt2 = annual[!validation_idx,],
                   pls_comps = cv_primary_pls_comp,
                   dist_fract = cv_primary_dist_frac, 
                   y_name.. = analysis_names[i],
                   k. = k,
                   # diff than if statement above
                   cov_names.. = cov_names_native,
                   exponentiate_obs_and_pred = F)
    
    # save individual PLS-variogram results
    each_combo <- df_cv$cv_table %>%
      mutate(Analysis = analysis_names[i])
    
    cv_each_combo <- rbind(cv_each_combo, each_combo)
    }
}

cv_alt <- cv_each_combo

```

```{r, eval=F}
cv_alt %>%
  label_analysis(var = "Analysis") %>%
  kable(caption = "CV RMSE and R2 for analyses using the same PLS components and variogram parametesr as the primary analysis", 
        col.names = c("Pollutant", "Analysis", "PLS Components", "Variogram Dist Fraction", "Variogram Plotting Dist (m)", "RMSE", "R2"),
        digits = 2) %>%
  kable_styling() %>%
  add_footnote("MSE-based R2") 

```

## Out of sample model performance (using validation set)

calculate the out-of-sample R2 and RMSE for the UK model using the CV-selected parameters.

### --> need to use the variogram paramters selected through CV (e.g., nugget, partial sill, range) here and in all further analyses?

```{r, results = "hide"}
out_of_sample_valid <- data.frame(Analysis = analysis_names,
                                  RMSE = NA,
                                  R2 = NA, 
                                  stringsAsFactors = F)

for (i in seq_along(analysis_names)) {
  #i=1
  # get validation results
  pls_components <- cv_results$PLS_Components[i]
  pls_variogram_dist <- cv_results$Variogram_Distance_Fraction[i]
  
  if(!grepl("native_scale", analysis_names[i])) {
    
    df <-  uk_predictions(dt = annual[!validation_idx,],
                     cov_loc_new = annual[validation_idx,],
                      y_name = analysis_names[i],
                      cov_names. = cov_names_log,
                      pls_comp = pls_components, 
                      variogram_dist_fract = pls_variogram_dist)
    
    obs <- annual[validation_idx, analysis_names[i]] %>% exp() %>% pull()
    uk_pred <- df$dt$uk_pred %>% exp()
  
    }
  
  #native scale analyses
  #i=6
    if(grepl("native_scale", analysis_names[i])) {
      
      df <-  uk_predictions(dt = annual[!validation_idx,],
                     cov_loc_new = annual[validation_idx,],
                      y_name = analysis_names[i],
                      cov_names. = cov_names_native,
                      pls_comp = pls_components, 
                      variogram_dist_fract = pls_variogram_dist
                     )
    
    obs <- annual[validation_idx, analysis_names[i]] %>% pull()
    uk_pred <- df$dt$uk_pred  
  
    }
  
  out_of_sample_valid$RMSE[i] <- rmse(obs = obs, pred = uk_pred) %>% round()  
  out_of_sample_valid$R2[i] <- r2_mse_based(obs = obs, pred = uk_pred) %>% round(2)
  
}

```

Table of modeling parameters selected via CV and the out-of sample model performance.

A slightly different number of PLS components and variogram parameters were selected via cross-validation for both UFP and BC. CV RMSE and R2 (MSE-based) estimates varied slightly.

For UFP, the primary and unweighted annual average analysis performed best (RMSE: __ , R2: __ ), while the analyses using stop means and windsorized observtaions perfomred worst (RMSE: __ , R2: __ ). 

For BC, the primary and unweighted annual average analysis performed best (RMSE: __ , R2: __ ), while the analyses using the native scale and windsorized observtaions perfomred worst (RMSE: __ , R2: __ ). 

```{r}
cv_results %>%
  rename(CV_RMSE = RMSE,
         CV_R2 = R2) %>% 
  left_join(out_of_sample_valid)  %>%
  rename(OOS_RMSE = RMSE,
         OOS_R2 = R2) %>%
  label_analysis(var = "Analysis") %>%
  
  kable(caption = "PLS components and variogram parameters selected via cross-validation for primary and sensitivity analyses, as well as out-of-sample (OOS) model performances", 
        col.names = c("Pollutant", "Analysis", "PLS Components", "Variogram Plotting Max Dist Fraction", "Variogram Plotting Dist (m)", "CV RMSE", "CV R2", "OOS RMSE", "OOS R2"),
        digits = 2) %>%
    kable_styling() %>%
  add_footnote("MSE-based R2") 


# out_of_sample_valid %>%
#   label_analysis(var = "Analysis") %>%
#   kable(caption = "Out-of-sample RMSE and R2 using model parameters from CV (calculated on validation set).") %>%
#   kable_styling() %>%
#   add_footnote("MSE-based R2") 

```
 

```{r, results = "hide", eval=F}
#Using same PLS component number and variogram distance fraction as primary analysis. 

out_of_sample_valid_alt <- data.frame(ufp_names,
                                  RMSE = NA,
                                  R2 = NA)

for (i in seq_along(ufp_names)) {
  #i=1
  # get validation results
  pls_components <- cv_primary_pls_comp
  pls_variogram_dist <- cv_primary_dist_frac
  
  if(!grepl("native_scale", ufp_names[i])) {
    
    df <-  uk_predictions(dt = annual[!validation_idx,],
                     cov_loc_new = annual[validation_idx,],
                      y_name = ufp_names[i],
                      cov_names. = cov_names_log,
                      pls_comp = pls_components, 
                      variogram_dist_fract = pls_variogram_dist
                     )
    
    obs <- annual[validation_idx, ufp_names[i]] %>% exp()
    uk_pred <- df$dt$uk_pred %>% exp()
    
    }
  
  #native scale analyses
  #i=6
    if(grepl("native_scale", ufp_names[i])) {
      
      df <-  uk_predictions(dt = annual[!validation_idx,],
                     cov_loc_new = annual[validation_idx,],
                      y_name = ufp_names[i],
                      cov_names. = cov_names_native,
                      pls_comp = pls_components, 
                      variogram_dist_fract = pls_variogram_dist
                     )
    
    obs <- annual[validation_idx, ufp_names[i]]  
    uk_pred <- df$dt$uk_pred  
  
    }
  
  out_of_sample_valid_alt$RMSE[i] <- rmse(obs = obs, pred = uk_pred)
  out_of_sample_valid_alt$R2[i] <- r2_mse_based(obs = obs, pred = uk_pred)
  
  
} 

```

```{r, eval=F}
out_of_sample_valid_alt %>%
    filter(!grepl("primary", ufp_names)) %>%
  mutate(RMSE = round(RMSE),
         Analysis = recode_factor(ufp_names,
                                  "primary_ufp" = "Primary", 
                                  "stop_means_ufp" = "Stop Means",
                                  "trim10_ufp" = "Trim 10%",
                                  "windsorize_ufp" = "Windsorize",
                                   "uw_ufp" = "Unweighted Annual Avg",
                                  "native_scale_ufp" = "Native Scale")) %>%
  select(Analysis, RMSE, R2) %>%
  kable(caption = "Out-of-sample RMSE and R2 using model parameters similar to primary analysis  (calculated on validation set).",
        digits = 2) %>%
  kable_styling()

```

# Fit UK model to all data and predict at ACT locations 

```{r, variogram plots}
# variogram plots 
# variograms are for the non-validation set (90% of the data) of the primary analysis 

set.seed(1)
my_pollutant <- c("ufp_primary", "bc_primary")

# create 1 pdf for each pollutant
for (p in seq_along(my_pollutant)) {

  pdf(file.path("Output", "Aim 2", "Images", "3. UK", paste0(my_pollutant[p], "_variograms.pdf")))
  
  print("variograms are for the non-validation set (90% of the data) of the primary analysis")
  
  dt <- annual %>%
    rename(log_ufp = my_pollutant[p]) %>%
    filter(!validation_idx)
  
  use_n_scores <- 3
  
  dist_fractions <- c(0.05, seq(0.1, 0.4, by=0.1))
  
  par(mfrow = c(3, 2))
  
  for(i in seq_len(use_n_scores)) {
    #i=1
    score_n_names <- paste0("Comp", 1:i)
    
    pls_train_test <- plsr(log_ufp ~.,
                 data=dt[,c("log_ufp", cov_names_log)], 
                 ncomp = i,
                 scale=T
                 )
    
    # extract scores for UK
    scores_train_test <- scores(pls_train_test)[,c(1:i)] %>%
      as.data.frame()
    
    # take out spaces in names
    names(scores_train_test) <- score_n_names
    
    # dataset w/ UFP measurements, geocovariates, location
    pls_df_train_test <- cbind(dt, scores_train_test)  
  
    ################################ UK ################################
     geo_train_test <- as.geodata(pls_df_train_test, 
                          coords.col = c("lambert_x", "lambert_y"), 
                          data.col = "log_ufp", 
                          covar.col = score_n_names)
  
    ##trend
    cov_trend <-  as.formula(paste0("~ ", paste0(score_n_names, collapse = " + " )))
    
    #plotting distances
    max.dist <- summary(geo_train_test)$distances.summary[["max"]]
    ## plot nearby locations more finely - improves variogram model fit?
    by1_pt <- 300
    brk_pt <- 1000
    by2_pt <- 1000
    
    ############################ model residuals ######################################
    for(j in seq_along(dist_fractions)) {
      #j=1
      max.plot.dist <- max.dist*dist_fractions[j]
  
    ##Empirical Variogram
    variog_train_test <- variog(geo_train_test,
                           #create equally spaced bins for all distances plotted
                          uvec =c(seq(0, brk_pt, by = by1_pt), seq((brk_pt + by2_pt), max.plot.dist, by= by2_pt)),
                          #UK
                          trend = cov_trend, 
                          messages = F  
                          )
  
    #plot(variog_train)
   
    wls_ests_train_test <- variofit(variog_train_test, cov.model = "exp",
                                                messages = F)
    
    resid_model_train_test <- variofit(vario = variog_train_test, 
                        ini = wls_ests_train_test, 
                        cov.model = "exp",
                        #weights = "equal") #ols
                        weights = "npairs",
                        messages = F
                        ) #wls
    
     plot(variog_train_test, 
         main = paste0("Comp: ", i, ", Dist fract: ", dist_fractions[j]), 
         cex.main=0.8
           )
    lines(variog_train_test)
    lines(resid_model_train_test, col=2)
  
    }
  }
  dev.off()
}

```


```{r, results = "hide"}
set.seed(1)

uk_names <- paste0(analysis_names, "_uk")

# empty columns to save predictions
cov_act_all[,uk_names] <- NA
residual_model_param <- data.frame()  
pls_models <- list()
empirical_variograms <- list()
residual_models <- list()
uk_betas <- data.frame() #list()

for (i in seq_along(analysis_names)) {
  #i=1
  # validation results
  pls_components <- cv_results$PLS_Components[cv_results$Analysis == analysis_names[i]]  
  pls_variogram_dist <- cv_results$Variogram_Distance_Fraction[cv_results$Analysis == analysis_names[i]]  
  
  if(!grepl("native_scale", analysis_names[i])) {
    
    df <-  uk_predictions(dt = annual,
                     cov_loc_new = cov_act_all,
                      y_name = analysis_names[i],
                      cov_names. = cov_names_log,
                      pls_comp = pls_components, 
                      variogram_dist_fract = pls_variogram_dist)
    
    # save predictions in native scale
    cov_act_all[uk_names[i]] <- exp(df$dt$uk_pred)
    }

  #native scale analyses
  #i=6
    if(grepl("native_scale", analysis_names[i])) {
      
      df <-  uk_predictions(dt = annual,
                     cov_loc_new = cov_act_all,
                      y_name = analysis_names[i],
                      cov_names. = cov_names_native,
                      pls_comp = pls_components, 
                      variogram_dist_fract = pls_variogram_dist)
      
      cov_act_all[uk_names[i]] <- df$dt$uk_pred
    }
  
    # save final residual model parameters
    residual_model_param <- rbind(residual_model_param, df$residual_model_table)
    
    # save geodataset
    # geodatasets[i] <- list(df$geo_dataset)
    # names(geodatasets)[i] <- uk_names[i]
    
    #pls_models
    pls_models[i] <- list(df$pls_model)
    names(pls_models)[i] <- uk_names[i]
    
    # variograms/residual models
    empirical_variograms[i] <- list(df$empirical_variogram)
    names(empirical_variograms)[i] <- uk_names[i]
    
    residual_models[i] <- list(df$residual_model)
    names(residual_models)[i] <- uk_names[i]
    
    # UK betas
    #uk_betas[i] <- df$betas
    uk_betas1 <- data.frame(df$betas) %>%
      rownames_to_column(var = "beta") %>% 
      rename(est = df.betas) %>%
      mutate(Analysis = uk_names[i])
    
    uk_betas <- rbind(uk_betas, uk_betas1)
   
}

```

### --> compare my results form primary analysis (3 PLS, 10% plotting distance) to using likfit()

```{r}
# PLS
scores(pls_models$ufp_primary_uk)

 
```

```{r}

  dt = annual
  y_name = "ufp_primary"
  cov_names. = cov_names_log
  #CV folds
  k = 3
  # max PLS components to evaluate
  use_n_scores. = 3
   
  score_n_names <- paste0("Comp", 1:use_n_scores.)
  
  dt <- dt %>% rename(y_name = y_name) %>%
    drop_na() %>%
    #create folds for test/train set
    mutate(set = sample(c(1:k), size = nrow(.), replace = T),
           cv_prediction = NA)
 
  for(f in seq_len(k)) {
    #f=1
    train_grp <- dt$set != f
    
    dt_train <- dt %>% filter(train_grp)  
    
    dt_test <- dt %>% filter(!train_grp)   
    
    #fit PLS to training data
    pls_train <- plsr(y_name ~.,
                      data=dt_train[,c("y_name", cov_names.)], 
                      ncomp = use_n_scores.,
                      scale=T)
    
    # extract scores for UK
    scores_train <- scores(pls_train)[,c(1:use_n_scores.)] %>% 
      as.data.frame()
    scores_test <- predict(object = pls_train,
                           newdata = dt_test,
                           ncomp = 1:use_n_scores.,
                           type = "score") %>%
      as.data.frame()
    
    # take out spaces in names
    names(scores_train) <- score_n_names
    names(scores_test) <- score_n_names
    
    # dataset w/ UFP measurements, geocovariates & location info
    pls_df_train <- cbind(dt_train, scores_train)  
    
    pls_df_test <- cbind(dt_test, scores_test)  
    
    ################################ UK ################################
    geo_train <- as.geodata(pls_df_train, 
                            coords.col = c("lambert_x", "lambert_y"), 
                            data.col = "y_name", 
                            covar.col = score_n_names)
    
    # --> ? don't need this now?
    geo_test <- as.geodata(pls_df_test, 
                           coords.col = c("lambert_x", "lambert_y"), 
                           data.col = "y_name", 
                           covar.col = score_n_names)
    
    ##trend
    cov_trend <-  as.formula(paste0("~ ", paste0(score_n_names,  collapse = " + " )))
    
    # # issue: still have to tell it a plotting distance 
    # variog_train <- variog(geo_train,
    #                         uvec=c(seq(0, 1000, by = 300), seq((1000 + 1000),  by= 1000)))
    
    
    # can run variog() w/o plotting maximum, but range is very large ~ 10k
    #variog_train <- variofit(variog(geo_train), cov.model = "exp" ) 
     
    #plot(variog(geo_train))
set.seed(1)
lf1 <- likfit(geodata = geo_train, 
       trend = cov_trend,
       #sig squared (partial sill), phi/theta (range). manually estimate these by looking at variogram plots
       
       #ini.cov.pars = c(0.025, 4000),  # Dr. Sampson suggested a range of 5000 ##variog_train
       
       # ? or use a matrix
       ini.cov.pars = as.matrix(cbind(seq(0, 1, l=4), seq(1000, 5000, l=4)) ) , 
        
       
       #ini.cov.pars = variog_train,

       # ? helps? is this like using a matrix of values for ini.cov.pars?
       limits = pars.limits(sigmasq=c(.01, .9), phi=c(300, 10000)),
       
       fix.nugget = FALSE,
       cov.model = "exponential",
       lik.method = "ML"
       )

# doesn't work? #use summary.likGRF() to pring summary of fitted model. e.g., see $parameters.summary    
lf1$parameters.summary


### --> ?? how do u make predictions? 
predict(lf1, newdata = geo_test) 
    
     
    
  }
  
    #save CV predictions
    dt$cv_prediction[!train_grp] <- kc_cv$predict
    
    
  #   max.dist <- summary(geo_train)$distances.summary[["max"]]
  #   
  #   # --> ? select this variogram parameter through CV??
  #   max.plot.dist <- max.dist*dist_fract. #[dist_fract_index] 
  #   
  #   ############################ model residuals ###################################### 
  #   ##Empirical Variogram
  #   brk_pt <- 1000
  #   by1_pt <- 300
  #   by2_pt <- 1000
  #   
  #   variog_train <- variog(geo_train,
  #                          uvec=c(seq(0, brk_pt, by = by1_pt), seq((brk_pt + by2_pt), max.plot.dist, by= by2_pt)),
  #                          #UK
  #                          trend = cov_trend, 
  #                          messages = F)
  #   
  #   #use geoR try to estimate intitial range & sill values. using WLS and an exponential fit
  #   wls_ests_train <- variofit(variog_train, cov.model = "exp", 
  #                              messages = F)
  #   
  #   # --> ? select this variogram parameter through CV??
  #   #don't need initial values above since estimates seem to be the same w/ or w/o ini = wls_ests_train (based on small sample)?
  #   resid_model_train <- variofit(vario = variog_train, 
  #                                 ini = wls_ests_train, 
  #                                 cov.model = "exp",
  #                                 #weights = "equal", #ols
  #                                 weights = "npairs",#wls
  #                                 #messages = F
  #                                 ) 
  #   
  #   #trend
  #   train_trend <- trend.spatial(trend = cov_trend, geo_train)
  #   test_trend <- trend.spatial(trend = cov_trend, geo_test)
  #   
  #   ############################# Predict #############################
  #   kc_cv <- krige.conv(coords = geo_train$coords,
  #                       data = geo_train$data,
  #                       locations = geo_test$coords,
  #                       krige = krige.control(type = "ok",
  #                                             obj.model = resid_model_train, 
  #                                             trend.d = train_trend,
  #                                             trend.l = test_trend))
  #   
  #   #save CV predictions
  #   dt$cv_prediction[!train_grp] <- kc_cv$predict
  # 
  # }
  # 
  # 
  # result <- list(dt = dt,
  #                max_plot_dist = max.plot.dist,
  #                max_dist = max.dist)
  # 
  # return(result)
  # #return(dt)
 

```


## PLS results 

### PLS component loadings for primary analysis

- UFP 

The PLS component loadings indicated that the covariates most negatively associated with both UFP and BC concentrations included: NDVI (with smaller buffers having stronger negative associations), distance to port and rail yard. The covariates most positively associated with pollutant concentrations included: highly developed land use, imperviousness, major road length within a buffer, the number of intersections within a buffer, and population density (with smaller buffers generally having stronger positive associations).

```{r, fig.height=12}
my.alpha=0.3

pls_loadings <- pls_models[["ufp_primary_uk"]]$loadings[] %>%
  as.data.frame() %>%
  rownames_to_column(var = "cov") %>%
  # rename variables if buffers
  split_cov_name(cov = "cov") %>%
  #make long format for faceting
  gather(key = "Component", value = "Loading", contains("Comp")) %>%
  mutate(Component = as.numeric(substr(Component, 6, nchar(Component))))   

pls_loadings  %>%
  #buffered covariates
  drop_na(buffer) %>%
  ggplot(aes(x = Loading, y = cov)) +
  geom_point(aes(size=buffer),
             shape=1,
             alpha=my.alpha) +
  scale_size(breaks = c(min(pls_loadings$buffer, na.rm = T),
                        max(pls_loadings$buffer, na.rm = T)
                        )) + #500, 5000, 10000,
  #non-buffered covariates
  geom_point(data = pls_loadings[is.na(pls_loadings$buffer),],
           alpha=my.alpha,
           aes(shape="")) +
  geom_vline(xintercept=0,
             linetype="solid",
             alpha=my.alpha) +
    facet_wrap(~Component,
               labeller = "label_both",
               nrow = 1) +
  labs(y = "Geocovariate",
       shape= "non-buffer", #"proximity,\nelevation",
       title = "PLS Geocovariate Component Loadings \nfor Annual Average UFP Concentration") +
  theme(legend.position = "bottom")


```

- BC 

```{r, fig.height=12}

pls_loadings <- pls_models[["bc_primary_uk"]]$loadings[] %>%
  as.data.frame() %>%
  rownames_to_column(var = "cov") %>%
  # rename variables if buffers
  split_cov_name(cov = "cov") %>%
  #make long format for faceting
  gather(key = "Component", value = "Loading", contains("Comp")) %>%
  mutate(Component = as.numeric(substr(Component, 6, nchar(Component))))

pls_loadings  %>%
  #buffered covariates
  drop_na(buffer) %>%
  ggplot(aes(x = Loading, y = cov)) +
  geom_point(aes(size=buffer),
             shape=1,
             alpha=my.alpha) +
  scale_size(breaks = c(min(pls_loadings$buffer, na.rm = T),
                        max(pls_loadings$buffer, na.rm = T)
                        )) + #500, 5000, 10000,
  #non-buffered covariates
  geom_point(data = pls_loadings[is.na(pls_loadings$buffer),],
           alpha=my.alpha,
           aes(shape="")) +
  geom_vline(xintercept=0,
             linetype="solid",
             alpha=my.alpha) +
    facet_wrap(~Component,
               labeller = "label_both",
               nrow = 1) +
  labs(y = "Geocovariate",
       shape= "non-buffer", #"proximity,\nelevation",
       title = "PLS Geocovariate Component Loadings \nfor Annual Average BC Concentration") +
  theme(legend.position = "bottom")

```

### Distribution of PLS component scores for mobile monitoring stops and ACT locations. 

Checking that the distribution of PLS values are not different between monitoring stops and ACT locations – this suggests extrapolation.  

- UFP 

Mobile monitoring stops and ACT cohort locations within the study area have similar PLS scores, though cohort locations appera to have slightly PLS scores.

```{r}
# for all ACT locations within study area
compare_pls_scores(my_pls_model = pls_models[["ufp_primary_uk"]],
                        new_prediction_sites = cov_act, #cov_act_all[cov_act_all$site_id %in% study_ids,],
                        my_title = "Cohort locations within the study area")$plot
```

The PLS scores of ACT cohort locations within the monitoring area are similar to the mobile monitoring stops PLS scores.

```{r, fig.height=4}
compare_pls_scores(my_pls_model = pls_models[["ufp_primary_uk"]],
                        new_prediction_sites = cov_act_all[cov_act_all$site_id %in% monitoring_ids,],
                        my_title = "Cohort locations in the monitoring area")$plot

```

ACT cohort locations outside the monitoring area but still within the study area, however, have PLS scores that are slightly lower but still within range of the mobile monitoring stop PLS scores. 

```{r}
# in study but outside monitoring area
compare_pls_scores(my_pls_model = pls_models[["ufp_primary_uk"]],
                        new_prediction_sites = cov_act_all[cov_act_all$site_id %in% outside_monitoring_in_study_ids,], 
                        my_title = "Cohort locations outside the monitoring but within the study area")$plot

# # for all ACT locations within study area 
# compare_pls_scores(my_pls_model = pls_models[["ufp_primary_uk"]],
#                         new_prediction_sites = cov_act_all[cov_act_all$site_id %in% study_ids,],
#                         my_title = "Cohort locations within the study area")$plot


```


```{r} 
### --> ? change these to ousdie study are if arguing for not predicting outside study area? 


# ACT cohort locations outside the monitoring area but still within the ST modeling area have a slightly lower PLS scores than mobile monitoring stops.

# # in ST but outside monitoring area
# compare_pls_scores(my_pls_model = pls_models[["ufp_primary_uk"]],
#                         new_prediction_sites = cov_act_all[cov_act_all$site_id %in% outside_monitoring_in_st_ids,],
#                         my_title = "Cohort locations outside the monitoring but within the ST model area")$plot

```

```{r} 
# # outside monitoring area
# compare_pls_scores(my_pls_model = pls_models[["ufp_primary_uk"]],
#                         new_prediction_sites = cov_act_all[cov_act_all$site_id %in% outside_monitoring_ids,],
#                         my_title = "Cohort locations outside the monitoring area")$plot
```

```{r}
# for later?
## all ACT locations
primary_scores_ufp_all_loc <- compare_pls_scores(my_pls_model = pls_models[["ufp_primary_uk"]],
                        new_prediction_sites = cov_act_all,
                        my_title = "All Cohort locations")

```

- BC 

The same is true for BC.

```{r}
# for all ACT locations within study area
compare_pls_scores(my_pls_model = pls_models[["bc_primary_uk"]],
                        new_prediction_sites = cov_act,  
                        my_title = "Cohort locations within the study area")$plot
```

```{r, fig.height=4}
compare_pls_scores(my_pls_model = pls_models[["bc_primary_uk"]],
                        new_prediction_sites = cov_act_all[cov_act_all$site_id %in% monitoring_ids,],
                        my_title = "Cohort locations in the monitoring area")$plot

```

```{r}
# in study but outside monitoring area
compare_pls_scores(my_pls_model = pls_models[["bc_primary_uk"]],
                        new_prediction_sites = cov_act_all[cov_act_all$site_id %in% outside_monitoring_in_study_ids,], 
                        my_title = "Cohort locations outside the monitoring but within the study area")$plot

# # for all ACT locations within study area 
# compare_pls_scores(my_pls_model = pls_models[["bc_primary_uk"]],
#                         new_prediction_sites = cov_act_all[cov_act_all$site_id %in% study_ids,],
#                         my_title = "Cohort locations within the study area")$plot


```

```{r}
# # in ST but outside monitoring area
# compare_pls_scores(my_pls_model = pls_models[["bc_primary_uk"]],
#                         new_prediction_sites = cov_act_all[cov_act_all$site_id %in% outside_monitoring_in_st_ids,],
#                         my_title = "Cohort locations outside the monitoring but within the ST model area")$plot

```

```{r}
# # outside monitoring area
# compare_pls_scores(my_pls_model = pls_models[["bc_primary_uk"]],
#                         new_prediction_sites = cov_act_all[cov_act_all$site_id %in% outside_monitoring_ids,],
#                         my_title = "Cohort locations outside the monitoring area")$plot

```

```{r}
# for later?
## all ACT locations
primary_scores_bc_all_loc <- compare_pls_scores(my_pls_model = pls_models[["bc_primary_uk"]],
                        new_prediction_sites = cov_act_all,
                        my_title = "All Cohort locations")

```

## Residual UK Model parameters

```{r}

cbind(Analysis = uk_names, residual_model_param) %>%
  mutate(Range_m = round(Range_m)) %>% 
    label_analysis(var = "Analysis", end_character = 3) %>%
  mutate(Pollutant = ifelse(!grepl("native", tolower(Analysis)), paste0("log ", Pollutant), Pollutant)) %>%
  rename("Pollutant Modelled" = Pollutant) %>%
  kable(caption = "UK residual model parameters for primary and sensitivity analyses", 
        digits = 3) %>%
  kable_styling()

```

Variogram for primary analyses. Modeled variograms are fit as exponential functions using weighted least squares.

- UFP 

```{r}
plot_pollutant <- "ufp"

plot_variogram <- empirical_variograms[[paste0(plot_pollutant, "_primary_uk")]]
plot_residual_model <- residual_models[[paste0(plot_pollutant, "_primary_uk")]]

plot(plot_variogram,
     main = paste0("Binned empirical and modeled variogram for primary ", toupper(plot_pollutant), " analysis"),
     xlab = "Distance (m)")

lines(plot_variogram, lty=1)
lines(plot_residual_model, lty=2, col=2)
legend("bottomright",
       legend = c("Empirical", paste0("Residual Model")),
       lty=c(1:2), col = c(1:2))

```

- BC 

```{r}
plot_pollutant <- "bc"

plot_variogram <- empirical_variograms[[paste0(plot_pollutant, "_primary_uk")]]
plot_residual_model <- residual_models[[paste0(plot_pollutant, "_primary_uk")]]

plot(plot_variogram,
     main = paste0("Binned empirical and modeled variogram for primary ", toupper(plot_pollutant), " analysis"),
     xlab = "Distance (m)")
lines(plot_variogram, lty=1)
lines(plot_residual_model, lty=2, col=2)
legend("bottomright",
       legend = c("Empirical", paste0("Residual Model")),
       lty=c(1:2), col = c(1:2))
```

## LUR vs Kriging 

UK Yhat = LUR + kriging 

How much does  kriging vs LUR (the mean part of the model) contribute to the final UK model prediction? If not much (indicated by paired points closer to the one-to-one line), we are less worried about using observations from 2019 to smooth observations back in time since (Aim 3). 

The plots below are colored to indicate the increasing distance of ACT cohort locations from the monitoring area. Locations in the "study" are those outside the monitoring area, but inside the study area. Locations in the "ST" are those outside the study area, but inside the ST modeling area. Locations in the "U.S." are those outside the ST modeling area, but within the U.S. (i.e., all other available locations).

- UFP 

Locations further away from the monitoring area tend to be close to the one-to-one line, indicating that little kriging is being done to the LUR prediction because of their distance from the monitoring sites.

In the study area, the LUR piece of UK explains about __ 64% __ of the variation in the overall UK predictions.

### --> plot primary UFP & BC plot together 

```{r, fig.height=8}
my_analysis <- "ufp_primary_uk"

# UK betas
betas1 <- uk_betas %>% filter(Analysis == my_analysis)

beta_names <- betas1$beta
                              # subtract beta0
max_beta <- length(beta_names) - 1

                  # --> change here for new datasets  
new_score_values <- primary_scores_ufp_all_loc$scores_new_locs 

uk_decompose <- cov_act_all[my_analysis] 

#  yhat = alpha + ß1*X1
uk_decompose$regression_prediction <- betas1$est[betas1$beta=="beta0"] + betas1$est[betas1$beta=="beta1"]*new_score_values$Comp1

## update regression prediction if more than 1 component
if(max_beta > 1) {
  for(i in c(2:max_beta)) {

    beta_no <- paste0("beta", i)
    comp_no <- paste0("Comp", i)

      uk_decompose$regression_prediction <- uk_decompose$regression_prediction + betas1$est[betas1$beta==beta_no]*new_score_values[[comp_no]]
  }
}

uk_decompose <- uk_decompose %>% 
  mutate(
    # transform predictions to native scale before plotting
    regression_prediction = exp(regression_prediction),
    krige_and_error = uk_decompose[[my_analysis]] - regression_prediction)

# add id info for plotting purposes
uk_decompose <- cbind(cov_act_all[c("site_id", "site_location", "latitude", "longitude")], 
                      uk_decompose) %>% 
  # add location columns
  mutate(
    site_location = as.character(site_location),
    site_location = ifelse(is.na(site_location), "U.S.", site_location),
    monitoring_area = ifelse(site_id %in% monitoring_ids, TRUE, NA),
    study_area = ifelse(site_id %in% study_ids, TRUE, NA),
    st_area = ifelse(site_id %in% st_ids, TRUE, NA),
    all_area = TRUE)

p_monitoring <- uk_decompose %>%
    filter(monitoring_area) %>%
  colo.plot(y.variable = my_analysis, y.label = "UK",
          x.variable = "regression_prediction", x.label = "LUR", 
          mytitle = "ACT locations in the monitoring area",
          col.by = "site_location")  

p_study <- uk_decompose %>%
    filter(study_area) %>%
  colo.plot(y.variable = my_analysis, y.label = "UK",
          x.variable = "regression_prediction", x.label = "LUR", 
          mytitle = "ACT locations in the study area", 
          col.by = "site_location")  
p_study_ufp <- p_study

p_st <- uk_decompose %>%
    filter(st_area) %>%
  colo.plot(y.variable = my_analysis, y.label = "UK",
          x.variable = "regression_prediction", x.label = "LUR", 
          mytitle = "ACT locations in the Spatiotemporal model area", 
          col.by = "site_location")  

p_all <- uk_decompose %>%
  colo.plot(y.variable = my_analysis, y.label = "LUR + Kriging",
          x.variable = "regression_prediction", x.label = "LUR", 
          mytitle = "All ACT locations in the U.S.", 
          col.by = "site_location") 

 

# other areas
ggarrange(p_monitoring, p_study, p_st, p_all) %>%
  annotate_figure(top = "UK vs regression UFP predictions (pt/cm3) from the primary analysis for ACT locations")

```

Map of the degree of kriging occurring at ACT locations within the study area.  

Locations near the Port of Seattle and northeast of the airport are krigged the most.   
- Higher kriging near the Port of Seattle and the airport indicate that these are locations where the LUR piece of UK is  characterizing concentrations less well (based on geocovariates alone).

### --> make bubbles bigger or jitter lat/long of ACT locations. Or map to grid locations within the study area   

```{r}
uk_decompose %>%
  filter(study_area) %>%
  map_fn(color_by = "krige_and_error", 
         color_units = "UFP (pt/cm3)",
         map_title = "Degree of Kriging in the UFP UK Predictions")

```

```{r}
# # Proportion of UK prediction explained by LUR 
# uk_decompose %>%
#   filter(st_area) %>%
#   #filter(study_area) %>%
#   dplyr::summarize(var = var(regression_prediction)/var(ufp_primary_uk))

```

- BC 

In the study area, the LUR piece of UK explains about __ 51% __ of the variation in the overall UK predictions.

```{r, fig.height=8}
my_analysis <- "bc_primary_uk"

# UK betas
betas1 <- uk_betas %>% filter(Analysis == my_analysis)

beta_names <- betas1$beta
                              # subtract beta0
max_beta <- length(beta_names) - 1

                  # --> change here for new datasets  
new_score_values <- primary_scores_bc_all_loc$scores_new_locs 

uk_decompose <- cov_act_all[my_analysis] 

#  yhat = alpha + ß1*X1
uk_decompose$regression_prediction <- betas1$est[betas1$beta=="beta0"] + betas1$est[betas1$beta=="beta1"]*new_score_values$Comp1

## update regression prediction if more than 1 component
if(max_beta > 1) {
  for(i in c(2:max_beta)) {

    beta_no <- paste0("beta", i)
    comp_no <- paste0("Comp", i)

      uk_decompose$regression_prediction <- uk_decompose$regression_prediction + betas1$est[betas1$beta==beta_no]*new_score_values[[comp_no]]
  }
}

uk_decompose <- uk_decompose %>% 
  mutate(
    # transform predictions to native scale before plotting
    regression_prediction = exp(regression_prediction),
    krige_and_error = uk_decompose[[my_analysis]] - regression_prediction)

# add id info for plotting purposes
uk_decompose <- cbind(cov_act_all[c("site_id", "site_location", "latitude", "longitude")], 
                      uk_decompose) %>% 
  # add location columns
  mutate(
    site_location = as.character(site_location),
    site_location = ifelse(is.na(site_location), "U.S.", site_location),
    monitoring_area = ifelse(site_id %in% monitoring_ids, TRUE, NA),
    study_area = ifelse(site_id %in% study_ids, TRUE, NA),
    st_area = ifelse(site_id %in% st_ids, TRUE, NA),
    all_area = TRUE)

p_monitoring <- uk_decompose %>%
    filter(monitoring_area) %>%
  colo.plot(y.variable = my_analysis, y.label = "UK",
          x.variable = "regression_prediction", x.label = "LUR", 
          mytitle = "ACT locations in the monitoring area",
          col.by = "site_location")  

p_study <- uk_decompose %>%
    filter(study_area) %>%
  colo.plot(y.variable = my_analysis, y.label = "UK",
          x.variable = "regression_prediction", x.label = "LUR", 
          mytitle = "ACT locations in the study area", 
          col.by = "site_location")  
p_study_bc <- p_study

p_st <- uk_decompose %>%
    filter(st_area) %>%
  colo.plot(y.variable = my_analysis, y.label = "UK",
          x.variable = "regression_prediction", x.label = "LUR", 
          mytitle = "ACT locations in the Spatiotemporal model area", 
          col.by = "site_location")  

p_all <- uk_decompose %>%
  colo.plot(y.variable = my_analysis, y.label = "UK",
          x.variable = "regression_prediction", x.label = "LUR", 
          mytitle = "All ACT locations in the U.S.", 
          col.by = "site_location") 

ggarrange(p_monitoring, p_study, p_st, p_all) %>%
  annotate_figure(top = "UK vs regression BC predictions (ng/m3) from the primary analysis for ACT locations")

```

Compare UFP vs BC 

```{r}
ggarrange(p_study_ufp, p_study_bc) %>%
  annotate_figure(top = "UK vs regression UFP (pt/cm3) & BC predictions (ng/m3) from the primary analysis for ACT locations")

```

Map of the degree of kriging occurring at ACT locations within the study area.  

Locations near the Port of Seattle and northeast of the airport are krigged the most.   
- Higher kriging near the Port of Seattle and I-5 indicate that these are locations where the LUR piece of UK is  characterizing concentrations less well (based on geocovariates alone).

```{r}
uk_decompose %>%
  filter(study_area) %>%
  map_fn(color_by = "krige_and_error", 
         color_units = "BC (ng/m3)",
         map_title = "Degree of Kriging in the BC UK Predictions")

```

## Predictions for ACT locations in the study area

```{r}
# combine all results 
uk_predictions_df <- cov_act_all %>%
  filter(site_id %in% study_ids) %>%
  select(site_id, latitude, longitude, uk_names)

uk_predictions_df_l <- uk_predictions_df %>% gather("Analysis", "prediction", contains("uk")) %>%
  mutate(Analysis = str_replace(Analysis, "_uk", ""),
         #Analysis = factor(Analysis, levels = c("primary", "stop_means", "trim10", "windsorize", "uw", "native_scale"))
         )

```

### --> add ACT locations in study area sensitivity analysis

Predictions are overall similar for primary and sensitivity analyses of both annual average BC and UFP concentrations. 

- Similar results across these analyses indicate that model predictions are robust and simply an artifact of our modeling decisions.

```{r}
# table 
uk_predictions_df_l %>%
  label_analysis(var = "Analysis") %>%
  group_by(Pollutant, Analysis) %>%
  distribution.table(var.string = "prediction") %>%
  kable(caption = "Distribution of UK predictions for ACT locations in the study area from primary and sensitivity analyses") %>%
  kable_styling()

```

```{r}
# density plot
uk_predictions_df_l %>%
  label_analysis(var = "Analysis") %>%
  ggplot(aes(x=prediction, fill = Analysis)) + 
  geom_density(alpha = 0.2) + 
  facet_wrap(~Pollutant, scales= "free") +
  labs(title = "Distribution of UK predictions for ACT locations in the study area \nfrom primary and sensitivity analyses",
       x = "UK Prediction") + 
  theme(legend.position = "bottom")
   
```

- UFP 

Scatterplots around 1-1 line show similar predictions for the primary analysis and sensitivity analysis. Predictions from the windsorized analysis were generally higher, while predictions from the 10% trimmed analysis were generally lower than the primary analysis. Some low concentration predictions from the primary analysis were much lower from the native scale analysis.

```{r}
my_pollutant <- "ufp"
max_ufp_plot <- max(uk_predictions_df_l$prediction[grepl(my_pollutant, uk_predictions_df_l$Analysis)])
min_ufp_plot <- min(uk_predictions_df_l$prediction[grepl(my_pollutant, uk_predictions_df_l$Analysis)])
  
uk_predictions_df %>%
  gather("Analysis", "prediction", contains(my_pollutant), -contains("primary")) %>%
  mutate(Analysis = str_replace(Analysis, "_uk", ""),
         # Pollutant = ifelse(grepl("ufp", Analysis), "UFP (pt/cm3)", "BC (ng/m3)" ),
         # Analysis = ifelse(grepl("ufp", Analysis), substr(Analysis, 5, nchar(Analysis)), substr(Analysis, 4, nchar(Analysis))),
         
         ) %>%
    label_analysis(var = "Analysis") %>%
  
                # update var for other pollutants here
  ggplot(aes(x = ufp_primary_uk, y = prediction, col = Analysis)) + 
  geom_abline(intercept = 0, slope = 1) + 
  geom_point(alpha = 0.1) + 
  geom_smooth() +
  xlim(min_ufp_plot, max_ufp_plot) +
  ylim(min_ufp_plot, max_ufp_plot) +
  labs(x = "Primary Analysis",
       y = "Sensitivity Analysis",
       title = "UFP predictions (pt/cm3) from different UK models") 
  
```

- BC

Similarly, the windsorized analysis resulted in some higher predictions than the primary analysis, while the opposite was true for the native scale analysis.

```{r}
my_pollutant <- "bc"
max_ufp_plot <- max(uk_predictions_df_l$prediction[grepl(my_pollutant, uk_predictions_df_l$Analysis)])
min_ufp_plot <- min(uk_predictions_df_l$prediction[grepl(my_pollutant, uk_predictions_df_l$Analysis)])
  
uk_predictions_df %>%
  gather("Analysis", "prediction", contains(my_pollutant), -contains("primary")) %>%
  mutate(Analysis = str_replace(Analysis, "_uk", ""),
         # Pollutant = ifelse(grepl("ufp", Analysis), "UFP (pt/cm3)", "BC (ng/m3)" ),
         # Analysis = ifelse(grepl("ufp", Analysis), substr(Analysis, 5, nchar(Analysis)), substr(Analysis, 4, nchar(Analysis))),
         
         ) %>%
    label_analysis(var = "Analysis") %>%
                # update var for other pollutants here
  ggplot(aes(x = bc_primary_uk, y = prediction, col = Analysis)) + 
  geom_abline(intercept = 0, slope = 1) + 
  geom_point(alpha = 0.1) + 
  geom_smooth() +
  xlim(min_ufp_plot, max_ufp_plot) +
  ylim(min_ufp_plot, max_ufp_plot) +
  labs(x = "Primary Analysis",
       y = "Sensitivity Analysis",
       title = "BC predictions (ng/m3) from different UK models") 
  
```

# UK Predictions on a grid

```{r, results = "hide"}
# make predictions on the grid from all analyses 

 # empty columns to save predictions
grid_covars[,uk_names] <- NA
 
for (i in seq_along(analysis_names)) {
  #i=1
  # validation results
  pls_components <- cv_results$PLS_Components[cv_results$Analysis==analysis_names[i]]
  pls_variogram_dist <- cv_results$Variogram_Distance_Fraction[cv_results$Analysis==analysis_names[i]]
  
  if(!grepl("native_scale", analysis_names[i])) {
    
    df <-  uk_predictions(dt = annual,
                     cov_loc_new = grid_covars,
                      y_name = analysis_names[i],
                      cov_names. = cov_names_log,
                      pls_comp = pls_components, 
                      variogram_dist_fract = pls_variogram_dist)
    
    # save predictions in native scale
    grid_covars[uk_names[i]] <- exp(df$dt$uk_pred)
    }

  #native scale analyses
    if(grepl("native_scale", analysis_names[i])) {
      
      df <-  uk_predictions(dt = annual,
                     cov_loc_new = grid_covars,
                      y_name = analysis_names[i],
                      cov_names. = cov_names_native,
                      pls_comp = pls_components, 
                      variogram_dist_fract = pls_variogram_dist)
      
      grid_covars[uk_names[i]] <- df$dt$uk_pred
    }
}

```

## Predictions

- UFP 

We see higher predicted UFP concentrations between downtown and the airport as well as along major highways. Some possible explanations for these hotspots are:

* elevated concentrations are seen in Seattle's industrial district where many industrial operations exist, including cargo handling and storage, ship and boat manufacturing, concrete manufacturing, and paper and metal fabrications. It is bounded by, among other features, the Duwamish Waterway, I-5, railroads from the two largest freight-hauling railroads in the word (BNSF Railway and Union Pacific Railroad) and the International District, all of which contain large emission sources. I-5, for example, has busy truck routes in this area (e.g., FGTS T-1 class roads - carry more tonage) (Schulte 2015 DEEDS study)

* Elevated concentrations between downtoan and northwest of the airport may also be due to predominant winds from the south and southwest as well as airport landing pattern (MOV-UP report Fig 11).

### --> map primary UFP & BC together 
### --> ? add north arrow & scale? 

```{r,fig.height=10}
# dot map
my_pollutant <- "ufp"
pollutant_uk_names <- uk_names[grepl(my_pollutant, uk_names)]

dot_maps <-list()# min and max difference of all estimates

# min and max difference of all estimates
plot_range <- grid_covars %>%
  select(pollutant_uk_names) %>%
  dplyr::summarize(min = min(.),
                   max = max(.)) %>%
  round()

for(i in seq_along(pollutant_uk_names)) {
  #i=1    #used to be: uk_predictions
   mymap <- suppressMessages(
     grid_covars %>% map_fn(color_by = pollutant_uk_names[i], outline_points = F,
                                   map_title = pollutant_uk_names[i]) +
    scale_color_gradient(name = "UFP (pt/cm3)", 
                        low = "yellow", high = "red",
                        #ensure that all plots on same scale
                        limits = c(plot_range$min, plot_range$max)
                        ))
   
   dot_maps[i] <- list(mymap)
   names(dot_maps)[i] <- pollutant_uk_names[i]
  }

ggarrange(plotlist = dot_maps,
          ncol = 3, nrow = 2,
          common.legend = T, legend = "right") %>%
  annotate_figure(top = "Annual average UFP grid predictions from different UK models" ) 
   
```

- BC 

We see elevated predicted BC concentrations between the Port of Seattle and the SEA-TAC airport as well as along major highways. The contrasts betwen high and low concentration areas appear to be somewhat clearer for BC than for UFP. 

```{r,fig.height=10}
# dot map
my_pollutant <- "bc"
pollutant_uk_names <- uk_names[grepl(my_pollutant, uk_names)]

dot_maps <-list()# min and max difference of all estimates

# min and max difference of all estimates
plot_range <- grid_covars %>%
  select(pollutant_uk_names) %>%
  dplyr::summarize(min = min(.),
                   max = max(.)) %>%
  round()

for(i in seq_along(pollutant_uk_names)) {
  #i=1    #used to be: uk_predictions
   mymap <- suppressMessages(
     grid_covars %>% map_fn(color_by = pollutant_uk_names[i], outline_points = F,
                                   map_title = pollutant_uk_names[i]) +
    scale_color_gradient(name = "BC (ng/m3)", 
                        low = "yellow", high = "red",
                        #ensure that all plots on same scale
                        limits = c(plot_range$min, plot_range$max)
                        ))
   
   dot_maps[i] <- list(mymap)
   names(dot_maps)[i] <- pollutant_uk_names[i]
  }

ggarrange(plotlist = dot_maps,
          ncol = 3, nrow = 2,
          common.legend = T, legend = "right") %>%
  annotate_figure(top = "Annual average BC grid predictions from different UK models" ) 
   
```



## Prediction differences 

### Prediction differences for ACT cohort locations in the study area 

```{r}
# calculate difference between sensitivity & primary estimates
pred_differences <- uk_predictions_df %>%
  mutate_at(vars(contains("ufp"), -contains("primary")), ~.-ufp_primary_uk) %>%
  mutate_at(vars(contains("bc"), -contains("primary")), ~.-bc_primary_uk) %>% 
  select(-contains("primary"))

```

Compared to predictions from the primary analysis, predictions from the windsorized and stop means analysis tend to be higher, while predictions from the 10% trimmed analysis tend to be lower for both UFPs and BC. 

-Annual average predictions for both UFP and BC tend to be higher for analyses that keep higher stop concentrations (e.g., windsorized analyses) and lower for those that drop high stop concentraions (e.g., 10% trimmed analysis).

```{r}
#density plot
pred_differences %>% 
  gather("Analysis", "prediction_diff", contains("uk")) %>%
  label_analysis(var = "Analysis", end_character = 3) %>%
  ggplot(aes(x = prediction_diff, fill = Analysis)) +
  geom_density(alpha = 0.3) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  facet_wrap(~Pollutant, scales="free") +
  labs(x = "Prediction difference",
       title = "Difference in annual average predictions relative to the primary analysis"
       ) +
  theme(legend.position = "bottom")

```

```{r}
# distribution table
pred_differences %>% gather("Analysis", "prediction_diff", contains("uk")) %>%
    label_analysis(var = "Analysis", end_character = 3) %>%
  group_by(Pollutant, Analysis) %>%
  distribution.table(var.string = "prediction_diff") %>%
  kable(caption = "Difference in annual average pollutant predictions relative to primary UK model") %>%
  kable_styling()

```

### Prediction differences on a grid

```{r}
# grid: calculate difference between sensitivity & primary estimates
pred_differences_grid <- grid_covars %>%
  select(site_id, latitude, longitude, contains(analysis_names)) %>%
    mutate_at(vars(contains("ufp"), -contains("primary")), ~.-ufp_primary_uk) %>%
  mutate_at(vars(contains("bc"), -contains("primary")), ~.-bc_primary_uk) %>% 
  select(-contains("primary"))

```

- UFP

Compared to UFP predictions from the primary analysis, predictions from the stop means analysis are slightly higher, generally along I-5. 

The opposite is true for the 10% trimmed analysis. 

Windosrized predictions tend to be higher throughout the study area, with a special emphasis near the airport. Windosorized predictiosn are lower near I-5 on the southern end of the study area. 

Unweighted average stop predictions are ___________

Native scale predictions are generally higher along major highways and lower on the east side of the study area where concentration predictions from the primary analysis were already low.

### --> relabel maps, e.g., "10% trimmed mean" 

```{r, fig.height=8}
# maps 
my_pollutant <- "ufp"

# min and max difference of all estimates
diff_range <- pred_differences_grid %>%
  select(contains(my_pollutant)) %>%
  dplyr::summarize(min = min(.),
                   max = max(.)) %>%
  round()

uk_names_diff <- names(pred_differences_grid)[grepl(my_pollutant, names(pred_differences_grid))]

difference_maps <-list()

for(i in seq_along(uk_names_diff)) {
  #i=2
  mymap <- suppressMessages(
     pred_differences_grid %>% map_fn(color_by = uk_names_diff[i], outline_points = F,
                                   map_title = uk_names_diff[i]) +
       scale_color_gradient2(name = "UFP (pt/cm3)", 
                        low = "black", mid= "white", high = "red",
                        midpoint = 0, 
                        limits = c(diff_range$min, diff_range$max))  
     
  )
  
  difference_maps[i] <- list(mymap)
  names(difference_maps)[i] <- uk_names_diff[i]
}

ggarrange(plotlist = difference_maps,
          ncol = 3, nrow = 2,
          common.legend = T, legend = "right") %>%
  annotate_figure(top = "Difference in annual average UFP predictions relative to primary UK model" ) 
 
```

- BC

Compared to BC predictions from the primary analysis, predictions from the stop means analysis are slightly higher near the water, but lower along major highways.

Predictions from the the 10% trimmed analysis were somewhat lower. 

Windosrized predictions were higher throughout the study area, particulalry in the Seattle area and south of the city along I-5.

Unweighted average stop predictions were similar. 

Native scale predictions were more extreme, with both higher and lower predictions throughout the study area.

```{r, fig.height=8}
# maps 
my_pollutant <- "bc"

# min and max difference of all estimates
diff_range <- pred_differences_grid %>%
  select(contains(my_pollutant)) %>%
  dplyr::summarize(min = min(.),
                   max = max(.)) %>%
  round()

uk_names_diff <- names(pred_differences_grid)[grepl(my_pollutant, names(pred_differences_grid))]

difference_maps <-list()

for(i in seq_along(uk_names_diff)) {
  #i=2
  mymap <- suppressMessages(
     pred_differences_grid %>% map_fn(color_by = uk_names_diff[i], outline_points = F,
                                   map_title = uk_names_diff[i]) +
       scale_color_gradient2(name = "BC (ng/m3)", 
                        low = "black", mid= "white", high = "red",
                        midpoint = 0, 
                        limits = c(diff_range$min, diff_range$max))  
     
  )
  
  difference_maps[i] <- list(mymap)
  names(difference_maps)[i] <- uk_names_diff[i]
}

ggarrange(plotlist = difference_maps,
          ncol = 3, nrow = 2,
          common.legend = T, legend = "right") %>%
  annotate_figure(top = "Difference in annual average BC predictions relative to primary UK model" ) 
 
```








# Additional   
## Covariates most associated with UFP 

Using Lasso regression to select the covarites most associated with annual average mobile monitoring estimates from the primary analysis.

- UFP

```{r, fig.height=8}
# find covariates associated with annual average UFP from mobile monitoring observations
act_cov_lasso <- lasso_fn(dt = annual, x_names = cov_names_log, y_name = "ufp_primary", 
              lambda. = .01
              )

selected_cov <- act_cov_lasso$results$cov
  
# plot 
annual %>%
  gather("cov", "value", selected_cov) %>%
  ggplot(aes(x=value, y=ufp_primary)) + 
  geom_point(aes(col=cov), alpha=0.5) +
  geom_smooth() +
  facet_wrap(~cov, scales = "free_x") + 
  theme(legend.position = "none") + 
  labs(x = "",
       y = "Estimated annual average UFP (pt/cm3)",
       title = "Annual average mobile monitoring estimates of UFP and associated geocovariates"
       ) 
```
 
- BC

```{r, fig.height=8}
# find covariates associated with annual average UFP from mobile monitoring observations
act_cov_lasso <- lasso_fn(dt = annual, x_names = cov_names_log, y_name = "bc_primary", 
              lambda. = .01
              )

selected_cov <- act_cov_lasso$results$cov
  
# plot 
annual %>%
  gather("cov", "value", selected_cov) %>%
  ggplot(aes(x=value, y=ufp_primary)) + 
  geom_point(aes(col=cov), alpha=0.5) +
  geom_smooth() +
  facet_wrap(~cov, scales = "free_x") + 
  theme(legend.position = "none") + 
  labs(x = "",
       y = "Estimated annual average BC (ng/m3)",
       title = "Annual average mobile monitoring estimates of BC and associated geocovariates"
)
```






```{r}
# # save datasets.

# # UK predictions from primary and sensitivity analyses 
# ## for ACT cohort locations in the study area 
# saveRDS(uk_predictions_df, file.path("Data", "Aim 2", "Predictions", "uk_predictions.rda"))
# saveRDS(pred_differences, file.path("Data", "Aim 2", "Predictions", "uk_prediction_diffs.rda"))
# 
# ## on a grid
# saveRDS(grid_covars[, c("site_id", "latitude", "longitude", uk_names)], file.path("Data", "Aim 2", "Predictions", "grid_uk_predictions.rda"))
# saveRDS(pred_differences_grid, file.path("Data", "Aim 2", "Predictions", "grid_uk_prediction_diffs.rda"))

```

 