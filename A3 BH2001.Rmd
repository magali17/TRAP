---
title: "Beacon Hill 2001 UFP Data"
author: "Magali Blanco"
date: "8/26/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---
 ## ? use 99% of data?


#Notes
* If there is no "P" in the name, the particle diameter is 0.__ µm.
V05 is the volume of .05 micrometer particles per cc. V1 through V7 (columns L-R) are for 0.1-0.7 µm particles   
*  What are columns S:AH, which have about 5 numbers after the “V”, and some have additional letters (e.g., ‘V83546, V1P0368)? - 0.835 microns and 1.0368 microns  (the P stands for “point”- I didn’t make that one up!)   
*  Particle size (e.g., 0.05 µm) is the lowest size limit of the bin 

Kim et al. 2004:
* The sampling height was 4 m above ground (this is lower than our samples).
* Range: 20 - ____ nm
* ?? are bins counts within that bin (?Yes); or counts greater than that size?

Mobile Monitoring particle counter ranges
* PTRAK: 20 nm -  1 µm, screened: 50 nm - 1 µm
* DiscMini: 10-700 nm
* Nanoscan: 10-420 nm

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, cache=T, cache.comments = F, message = F, warning = F, tidy.opts=list(width.cutoff=60), tidy=TRUE, fig.height = 8)  

# Clear workspace of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
  res <- suppressWarnings(
    lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
      detach, character.only=TRUE, unload=TRUE, force=TRUE))
}

pacman::p_load(readxl, dplyr, tidyverse, chron, knitr)  #chronn: is.holiday, is.weekend

#set plot theme
theme_set(theme_linedraw() + theme(legend.position="bottom")) 

```

```{r}
#source common variables (e.g., percentil, time of day)
source("A2-3_Var&Fns.R")

#2001 seasons 
winter1 <- as.Date("2000-12-20")
winter2 <- as.Date("2001-12-21")
spring <- as.Date("2001-03-20")
summer <- as.Date("2001-06-21")
fall <- as.Date("2001-09-22")
 

bh <- read_excel("~/Everything/School/PhD_UW/Dissertation/Write Up/1. Proposal/Aim 3. Hx UFP/Hx Data/Tim Larson/Beacon Hill size data.xls") %>%
  #only keep 2001 data; too little 2000 and 2002 data to calculate annual avg
  filter(format(date, "%Y") == "2001") %>%
  mutate(#month = as.numeric(format(date, "%m"))
         time_of_day = factor(ifelse(hour %in% early_am, "early_am",
                 ifelse(hour %in% am, "am",
                        ifelse(hour %in% noon, "noon",
                               ifelse(hour %in% evening, "evening", "night")))),
                 levels= c("early_am", "am", "noon", "evening", "night")),
    day = factor(format(date, "%a"), 
                 levels= c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")),
    time_of_week = factor(ifelse(day =="Sat" | day == "Sun", "weekend", "weekday")),
    season = factor(ifelse((date >= winter1 & date < spring) | date >= winter2, "winter",
                    ifelse(date >= spring & date < summer, "spring",
                           ifelse(date >= summer & date < fall, "summer", "fall"))),
                    levels = c("winter", "spring", "summer", "fall")),
    # assign temporal weights
    # #upweigh surrounding months of missing times (no Jul or Dec data)
    # month.wt = ifelse(month == 01 | month == 11 | month == 06 | month == 08, 1.5/12, 1/12),
    # #upweight hr 1 and 23 since no hour 24
    # hour.wt = ifelse(hour == 01 | hour == 23, 1.5/24, 1/24),
    # month.hour.wt = month.wt*hour.wt
    season.wt = 1/4,
    day_of_week.wt = ifelse(time_of_week == "weekday", 5/7, 2/7),
    time_of_day.wt = ifelse(time_of_day == "early_am", length(early_am)/24,
                            ifelse(time_of_day == "am", length(am)/24,
                                   ifelse(time_of_day == "noon", length(noon)/24,
                                          ifelse(time_of_day == "evening", length(evening)/24, length(night)/24)))),
    season_week_hour.wt = season.wt*day_of_week.wt*time_of_day.wt
    
    ) 
        



bh <- bh %>%
  mutate(
   
  )  


# #check that sum of weights should be 1. # it is
# weights <- bh %>% group_by(season, time_of_week, time_of_day) %>%
#   select(season, time_of_week, time_of_day, season_week_hour.wt) %>%
#   unique() %>%
#   ungroup() %>%
#   summarize(
#     sum = sum(season_week_hour.wt)
#   )

```

```{r}
#how many hourly values do we have? 
##only have data for 10 months & 23 hours
# unique(bh$month) #no July or December
# unique(bh$hour) #no midnight

##old: No data for July or December, or Midnight. Little data for months 1, 10, 11; more data for hour 23 than the rest. Thus, values need to be reweighted.

# bh %>%
#   ggplot(aes(x=hour, fill=time_of)) +  #fill= hour
#   geom_bar() + 
#   facet_wrap(~month, labeller = "label_both")

```

```{r}
bh %>%
  ggplot(aes(x=time_of_day, fill= time_of_week)) +  #fill= hour
  geom_bar() + 
  facet_wrap(~season, labeller = "label_both")

```


 
```{r}
#convert vol conc (µm3/cm3 air) to num conc (particles/cm3 air)
##make long format
bh.long <-bh %>%
  gather(V02:V2P4579, key = "diam_um_lower", value = "vol_conc_um3_cm3")

bins <- unique(bh.long$diam_um_lower) 

bh.long <- bh.long %>% 
            #rename bin column names
    mutate(diam_um_lower = as.numeric(ifelse(diam_um_lower %in% bins[1:19], 
                    paste0("0.", substr(diam_um_lower, 2,7)),
                    paste0(substr(diam_um_lower, 2,2), ".", substr(diam_um_lower, 4,7))))) 

#Calculate mean diameter for each bin (bin sizes are for lower size cut)
diam <- unique(bh.long$diam_um_lower)
bh.long$diam_um_upper <- NA 

for (i in 1:length(diam)) {
  bh.long$diam_um_upper[bh.long$diam_um_lower == diam[i]] = diam[i+1]
}

bh.long$diam_um_center <- rowMeans(bh.long[c("diam_um_lower", "diam_um_upper")])
 
 bh.long <- bh.long %>%
   mutate(
     #calculate particle volume per bin      
     particle_vol_um3_particle = 4/3*pi*(diam_um_center/2)^3,
    # calculate number concentration
    num_conc_particles_cm3 = vol_conc_um3_cm3 / particle_vol_um3_particle
    ) 

## get a total particle conc for a specific size range (# counts are for particles ">" __ um) & date
bh.long <- bh.long %>%
    # only keep bin counts for particle sizes similar to what we are collecting in mobile monitoring (PTRAK: 20 nm - 1µm; DiscMini: 10-700 nm; Nanoscan: 10-420 nm). Note: few particles are large, so this doens't make a large difference in the annual avg estimate.
  ## counts similar to PTRAK
  filter(diam_um_lower < 1.03680) %>%
  #calculate avg total PNC for each hour
  group_by(date, hour, season, time_of_week, time_of_day, season_week_hour.wt) %>%
  summarize(
            #total particle count for each day and hour
            pnc_particles_cm3 = sum(num_conc_particles_cm3))

```


```{r}
# #look to see if there are any extreme values. tehre are
# bh.long %>%
#   ggplot(aes(x=pnc_particles_cm3)) + 
#   geom_histogram()  

```

```{r}
#drop high hourly readings (e.g., new years). this is similar to what will be done with MM data.
quant_limit <- as.numeric(quantile(bh.long$pnc_particles_cm3, myquantile))

pnc <- bh.long %>% 
  mutate(pnc_particles_cm3 = ifelse(pnc_particles_cm3 < quant_limit, pnc_particles_cm3, NA))

# pnc %>%
#   ggplot(aes(x=pnc_particles_cm3)) + 
#   geom_histogram() 

```

```{r}


# take avg reading for each season-week-hour combination  
  pnc <- pnc %>% 
    group_by(season, time_of_week, time_of_day, season_week_hour.wt) %>%
    summarize(
      # number of observations per month-hour combination 
      unique_hour_samples = n(),
      # use na.rm=T b/c some values are missing when exclude extremely high values
      avg_pnc_particles_cm3 = mean(pnc_particles_cm3, na.rm = T))

#check that weights add up to 1. They do
#sum(pnc$season_week_hour.wt)
  
# when there is only 1 value for each season-week-hour combination, multiply its respective weight; sum all values to estimate annual avg for total PNC
(pnc_annual_avg_particles_cm3 <- round(sum(pnc$avg_pnc_particles_cm3 * pnc$season_week_hour.wt))) 

#annaul estimates
## 96,479: using center cut bin size and without  extreme values > 99%: 
## 102,534: using center cut bin size with all values included
## 146,514: using lower cut bin size (vol/particle is smaller than using center cut --> vol conc is divided by smaller # --> larger PNC)

```


#Compare to MM observations at Beacon Hill
 
```{r}
mm.wide <- readRDS(file.path("Data", "MobileMonitoring", "mm.wide_190806.rda"))

bh.mm <- mm.wide %>%
  filter(aqs_location == "Beacon Hill") %>%
  select(arrival_time, date:season, ufp_pt_noscreen_ct_cm3)  

round(median(bh.mm$ufp_pt_noscreen_ct_cm3)) 

bh.mm %>%
  ggplot(aes(x=ufp_pt_noscreen_ct_cm3)) + 
  geom_density() 

# 4929 estimate for Beacon Hill through 7/20/19 from PTRAK no screen

```

  