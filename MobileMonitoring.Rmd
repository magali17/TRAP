---
title: "Mobile Monitoring Data Review"
author: "Magali Blanco"
date: " `r Sys.Date()` "
output: 
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
editor_options: 
  chunk_output_type: console
  
---

```{r setup, include=FALSE}  
knitr::opts_chunk$set(echo = F, cache=T, cache.comments = F, message = F, warning = F, tidy.opts=list(width.cutoff=60), tidy=TRUE, fig.height = 8)  

# Clear workspace of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
  res <- suppressWarnings(
    lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
      detach, character.only=TRUE, unload=TRUE, force=TRUE))
}

pacman::p_load(dplyr, tidyverse, chron, knitr)  #chronn: is.holiday, is.weekend

#set plot theme
theme_set(theme_linedraw() + theme(legend.position="bottom")) 
 
```

```{r high temporal resolution data}  
#read in data

# mm_full <- readRDS("Data/MobileMonitoring/stop_data_190222_190806.rda") %>% 
#   #drop unwanted variable values to reduce data size
#   filter(!variable %in% c("gps_lat",
#                           "gps_long",
#                           #"ufp_pt_screen_ct_cm3",
#                           "ufp_disc_med_size_nm",
#                           "bc_uv375nm_ng_m3" #this is not total BC
#                          ) 
#          )
# 
# #give each site unique number ID, based on time when stop was first sampled 
# site_no <- mm_full %>%  
#   arrange(route, time) %>%
#   select(site_id) %>% unique() %>% 
#   mutate(site_no = seq(1:length(site_id))) 
# 
# mm_full <- mm_full %>% left_join(site_no)  
# 
# #relabel instruments that were incorrectly labeled 
# mm_full <- mm_full %>%
#   mutate(instrument_id = ifelse(instrument_id == "BC_0063", "BC_63",
#          ifelse(instrument_id == "CO_2", "CO_3", 
#                 ifelse(instrument_id == "PMSCAN_1", "PMSCAN_3", 
#                        instrument_id)))
#          )
# 
# #remove top 1% of values for each pollutant and instrument before taking avg
# myquantile <- 0.99
# 
# mm_full <- mm_full %>% 
#   group_by(variable, instrument_id) %>%
#   mutate(value = ifelse(value < quantile(value, myquantile, na.rm = T), value, NA)) %>%
#   #drop rows w/ NA "values"
#   drop_na(value) %>%
#   ungroup()
# 
# #take avg of each stop to REDUCE FILE SIZE
# mm <- mm_full %>%
#   group_by(runname, site_id) %>%  #, instrument_id, variable
#   #set time to arrival time, in case a stop elapsed e.g., 2 diff hours
#   mutate(arrival_time = min(time)) %>%
#   select(-time) %>%
#   
#   #take avg of each unique site stop for each instrument
#   group_by(runname, route, site_id, aqs_id, aqs_location, site_long, site_lat, duration_sec, arrival_time, instrument_id, variable, site_no) %>%  
#   summarize(value = mean(value, na.rm = T)) %>% 
#   ungroup()
#    
# 
# #give each driving day a unique ID
# run_no <- mm %>% 
#   arrange(runname) %>%
#   select(runname) %>% 
#   unique() %>%
#   mutate(run_no = seq(1:length(runname)))
# 
# mm <- mm %>% left_join(run_no)  
# 
# #number of times each site has been visited
# site_id_visit_no <- mm %>%
#   group_by(site_id) %>%
#   select(site_id, runname) %>%
#   unique() %>%
#   #group_by(site_id) %>%
#   mutate(
#     site_id_visit_no = seq(1:n())
#     )
# 
# mm <- mm %>% left_join(site_id_visit_no)  
# 
# #ID if stops are AQS sites
# mm <- mm %>% 
#   mutate(aqs_site = ifelse(is.na(aqs_id), 0, 1))
# 
# #create temporal variables
# ##seasons
# winter1 <- as.Date("2018-12-21")
# winter2 <- as.Date("2019-12-21")
# spring <- as.Date("2019-03-20")
# summer <- as.Date("2019-06-21")
# fall <- as.Date("2019-09-23")  
# 
# ##time of day
# early_am <- seq(5,8)
# am <- seq(9,11)
# noon <- seq(12,15)
# evening <- seq(16,20)
# night <- c(seq(21,23), seq(0,4)) #? 0-4 in "night"?
# 
# mm <- mm %>% mutate(
#     #arrival_time = as.POSIXct(arrival_time),
#     date = as.Date(substr(arrival_time, 1,10)),   
#     hour = as.numeric(format(arrival_time, "%H")),   
#     time_of_day = factor(ifelse(hour %in% early_am, "early_am",
#                  ifelse(hour %in% am, "am",
#                         ifelse(hour %in% noon, "noon",
#                                ifelse(hour %in% evening, "evening", "night")))),
#                  levels= c("early_am", "am", "noon", "evening", "night")
#                  ),
#     day = factor(format(arrival_time, "%a"), levels= c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")),
#     weekend = factor(ifelse(day =="Sat" | day == "Sun", "weekend", "weekday")),
#     month = factor(format(arrival_time, "%b"), levels= c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")),
#     season = factor(ifelse((date >= winter1 & date < spring) | date >= winter2, "winter", 
#                     ifelse(date >= spring & date < summer, "spring",
#                            ifelse(date >= summer & date < fall, "summer", "fall"))),
#                     levels = c("winter", "spring", "summer", "fall"))
#     )
# 
# #saveRDS(mm, file.path("Data", "MobileMonitoring", "summary_data_190222_190806.rda"))

```

```{r average stop data}

mm <- readRDS(file.path("Data", "MobileMonitoring", "summary_data_190222_190806.rda"))

```

### see Qs in code
 
```{r mm.wide} 
#make wide format. 
#note: dataframe does NOT include instrument_ID - takes avg reading if 2 instruments were collocated
mm.wide <- mm %>% 
  #?? don't care whate instrument took measurement, as long as we have a measurement?
  select(-instrument_id) %>%
  # ??? HOW do you account for completely missed stops for which we have no data?
  #group_by arrival_time first to order by time
  group_by(arrival_time, runname, site_id, variable, 
           #variables not immediately necessary
           route, aqs_id, aqs_location, site_long, site_lat, duration_sec, site_no, run_no, site_id_visit_no, aqs_site, date, hour, time_of_day, day, weekend, month, season) %>% 
  #spread() fn has issues when have dupliate instruments taking readings at same time - so take avg of both the readings
  summarize(value = mean(value)) %>%
  ungroup() %>%
  spread(variable, value) 
  
```


```{r}
#on what days have instruments been used?
instrument.use <- mm %>% group_by(instrument_id) %>%
  summarize(
    no_runs = length(unique(runname))
  )
 
```

```{r ufp variable names} 
#UFP instrument variable names 
ufp <- c(#"bc_ir880nm_ng_m3", 
          #     "neph_bscat_per_m", 
               "ufp_disc_ct_cm3", 
               "ufp_pt_noscreen_ct_cm3", 
               "ufp_pt_screen_ct_cm3", 
               "ufp_scan_ct_cm3")

```

Data used in this report are those less than the `r myquantile` quantile.

```{r sites in each route}  
# #sites  in each route
# mm %>%  
#   select(site_no, route) %>%   
#   unique() %>%
#   #all sites
#   ggplot(aes(x=site_no, y=route)) + 
#   geom_point() + 
#   labs(title = paste("Sites in each route")) 

```

#Data Collection Over Time  

## --> spread figure over 2 pgs?

```{r}
#instrument used each day
mm %>%
  #1 record per variable combination - to reduce file size
  select(date, instrument_id, variable) %>% 
  unique() %>%
  ggplot(aes(x=date, y=instrument_id, colour = instrument_id)) + 
  geom_point() + 
  facet_wrap(~variable, scales="free") + 
  theme(legend.position = "none") + 
  labs(title = "Instruments used over time")

```

```{r}
#stops over time 
start.date = min(mm$date)
end.date = max(mm$date)

mm %>%  
  #1 record per date-site_no to reduce file size
  select(date, site_no, route, aqs_id) %>%   
  unique() %>%
  #all sites
  ggplot(aes(x=date, y=site_no, colour=route)) + 
  geom_point() + 
  #aqs sites 
  geom_point(aes(shape=aqs_id), colour="black") + 
  labs(title = paste("Sites visited over time", subtitle= paste(start.date, "-", end.date))) 
  
```

```{r}
#stops by season/day of week/time of day/hour 
##stops by season
mm %>%  
  select(runname, site_no, season, site_id) %>%   
  unique() %>%
  ggplot(aes(x=site_no, fill=season)) + 
  geom_bar() + 
  labs(title = "Number of visits to each site by season", subtitle= paste(start.date, "-", end.date)) 
  
 
```

```{r}
##stops by time of week
mm %>%  
  select(runname, site_no, weekend) %>%   
  unique() %>%
  #all sites
  ggplot(aes(x=site_no, fill=weekend)) + 
  geom_bar() + 
  labs(title = "Number of visits to each site by time of week", subtitle= paste(start.date, "-", end.date)) 

```

```{r}
##stops by day of the week
mm %>%  
  select(runname, site_no, day) %>%   
  unique() %>%
  #all sites
  ggplot(aes(x=site_no, fill=day)) + 
  geom_bar() + 
  labs(title = "Number of visits to each site by week day", subtitle= paste(start.date, "-", end.date)) 

```

```{r}
##stops by time of day
mm %>%  
  select(runname, site_no, time_of_day) %>%   
  unique() %>%
  #all sites
  ggplot(aes(x=site_no, fill=time_of_day)) + 
  geom_bar() + 
  labs(title = "Number of visits to each site by time of day", subtitle= paste(start.date, "-", end.date)) 

```

## Data Completeness 
## --> ask Amanda: why are my % estimates so much higher? 

```{r}
total_site_visits <- nrow(mm.wide)

instrument_readings <- mm.wide %>%
  select(bc_ir880nm_ng_m3 : ufp_scan_ct_cm3)  

total_stops <- instrument_readings %>% nrow()

complete_instrument_readings <- instrument_readings %>%
  drop_na() %>% nrow()
   
  
data_completeness <- data.frame(variable = names(instrument_readings),
                 stop_count = NA,
                 percent_complete = NA)

for(i in 1:nrow(data_completeness)) {
  data_completeness$stop_count[i] <- nrow(drop_na(instrument_readings[i]))
  data_completeness$percent_complete[i] <- data_completeness$stop_count[i] / total_site_visits *100  
  }

data_completeness <- data_completeness %>%
  arrange(desc(percent_complete))
  
total_df <- data.frame(variable = c("total stops", "all instruments running"),
                       stop_count = c(total_stops, complete_instrument_readings),
                       percent_complete = c(NA, complete_instrument_readings/total_stops))

data_completeness <- rbind(total_df, data_completeness)

data_completeness <- data_completeness %>% 
  mutate(percent_complete = round(percent_complete, 1)) 
   
#error: "package ‘kable’ is not available (for R version 3.5.1)"
#library("kable") 

 
data_completeness

```

 
Percent complete based on total sites visited: `r total_site_visits`

## --> kable() ??

```{r}

```




\newpage
#Data Summary
##Density Plots

```{r}
#density plots of concentrations for each pollutant & instrument
mm %>% 
  ggplot(aes(x=value, fill = instrument_id)) +  
  geom_density( alpha=0.3) + 
  facet_wrap(~variable, scales = "free") + 
  labs(title = "Density plots of Pollutant Concentrations by Instrument",
       subtitle = paste0(start.date, " - ", end.date))

```

```{r}
#density plots of UFP instrument concentrations
mm %>% 
  filter(variable %in% ufp) %>%
  ggplot(aes(x=value, fill = variable)) +  
  geom_density(alpha=0.3) +
  scale_x_log10() +
  labs(title = "Density plots of UFP Concentrations (#/cm3)",
        subtitle = paste0(start.date, " - ", end.date,
                          "\nlog x scale"))

```

### --> compare PM2.5/neph to UFPs. convert PNC to PMC? density plot? scatterplot w/ 1-1 line?

```{r}

```


##Concentrations Over Time

```{r}
#concentrations by time & season 
mm %>%
  ggplot(aes(x=month, y=value, fill=season)) + 
  geom_boxplot(notch=T) + 
  facet_wrap(~variable, scales="free") + 
  labs(title= "Concentrations over time",
       subtitle = paste0(start.date, " - ", end.date))  

```

```{r}
#concentrations by week day
mm %>%
  ggplot(aes(x=day, y=value, fill=weekend)) + 
  geom_boxplot(notch=T) + 
  facet_wrap(~variable, scales="free") + 
  labs(title= "Concentrations by week day",
       subtitle = paste0(start.date, " - ", end.date))  
 
```

# --> does this plot look diff? using plot(p)

```{r}
#concentrations by hour and time of day
p <- mm %>%
  ggplot(aes(x=hour, y=value, fill=time_of_day, group=hour)) + 
  geom_boxplot(notch=T) + 
  facet_wrap(~variable, scales="free") + 
  labs(title= "Concentrations by hour",
       subtitle = paste0(start.date, " - ", end.date))  

print(p)
 
```





\newpage
#Instrument Collocations - In Field

##UFP

comparing duplicate DiscMini readings

```{r} 
#make wide format to compare both DiscMini instruments 

discmini.wide <- mm %>% 
  #select only values from discminis
  filter(variable == "ufp_disc_ct_cm3") %>%
  #make wide format
  spread(instrument_id, value) %>% 
  #only look at rows where have observations for both discminis
  drop_na(PMDISC_3, PMDISC_8) %>%
  #calculate percent difference in estimates
  mutate(pct.diff = (PMDISC_8 - PMDISC_3)/PMDISC_8*100)

lm.disc <- lm(PMDISC_8 ~ PMDISC_3, data = discmini.wide)

#percent difference between instruments
pct.diff.median <- round(median(discmini.wide$pct.diff, na.rm = T), 1)

# #RMSE
# rmse <- discmini.wide %>% summarize(
#   round(sqrt(mean((PMDISC_8 - PMDISC_3)^2)))
# )

#compare primary & secondary instrument agreement 
discmini.wide %>% 
  ggplot(aes(x=PMDISC_3, y= PMDISC_8)) + 
  geom_point(alpha=0.3, aes(colour = route)) + 
  geom_abline(intercept = 0, slope = 1) +
  geom_smooth(method = "lm", aes(fill="lm")) + 
  labs(fill="", 
       title = paste0(discmini.wide$variable[1]),
       subtitle = paste0("y = ", round(coef(lm.disc)[1], 2), " + ", round(coef(lm.disc)[2], 2), 
                        "x \nR2 = ", round(summary(lm.disc)$r.squared, 2), 
                        #"\nRMSE = ", rmse,
                        "\nmedian percent diff = ", pct.diff.median, "%",
                        "\nno. pairs = ", nrow(discmini.wide)
                        )
       )


```


```{r}
#estimate site-specific median pollutant concentrations up until now
median.conc <- mm %>% 
  #filter(instrument_id =="PMDISC_8") %>% 
  group_by(site_id, site_lat, site_long, instrument_id) %>% 
  rename(lat = site_lat, long = site_long) %>%
  summarize(
    median_conc = median(value)
  )

##estimates for specific pollutants from primary instruments
ufp.conc <- median.conc %>%
  filter(instrument_id == "PMDISC_8") %>%
  rename(median_conc_ct_m3 = median_conc )

no2.conc <- median.conc %>%
  filter(instrument_id == "NO2_2") %>%
  rename(median_conc_ppb = median_conc )

# write.csv(ufp.conc, "ufp.conc.csv", row.names = F)
# write.csv(no2.conc, "no2.conc.csv", row.names = F)
 

```


## --> plots comparing other duplicate instruments

## Nephelometers


##PTRAK with Screen

##CO

##CO2

#NO2

##Temperature


##Relative Humidity


### --> schedule call w/ Edmund about calibrating back up instrument values to what would have been read from a primary instrument…? 


## Instrument Collocations - Lab/Garage

? see data in database? 

```{r}

```



\newpage
##Trimmed, weighted mean concentrations 
-per location 
??? how to do this??

```{r}
#overall








#by season



```



```{r}
#table of obsevations over time before/after weighing (e.g., % samples during day before/after weighting)


```



















 